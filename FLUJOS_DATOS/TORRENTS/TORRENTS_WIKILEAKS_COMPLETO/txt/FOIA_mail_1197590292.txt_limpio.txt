from ben santer santer1llnlgov to carl mears mearsremsscom subject re fwd sorry to take your time up but really do need scrub of this singerchristyetc effort date thu 13 dec 2007 185812 0800 replyto santer1llnlgov cc sherwood steven stevensherwoodyaleedu tom wigley wigleycgducaredu frank wentz frankwentzremsscom philip d jones pjonesueaacuk karl taylor taylor13llnlgov steve klein klein21mailllnlgov john lanzante johnlanzantenoaagov thorne peter peterthornemetofficegovuk dian j seidel dianseidelnoaagov melissa free melissafreenoaagov leopold haimberger leopoldhaimbergerunivieacat francis w zwiers franciszwiersecgcca michael c maccracken mmaccraccomcastnet thomas r karl thomasrkarlnoaagov tim osborn tosbornueaacuk david c bader bader2llnlgov susan solomon ssolomonalnoaagov xflowed dear folks ive been doing some calculations to address one of the statistical issues raised by the douglass et paper in the international journal of climatology here are some of my results recall that douglass et calculated synthetic t2lt and t2 temperatures from the cmip3 archive of 20th century simulations 20c3m runs they used total of 67 20c3m realizations performed with 22 different models in calculating the statistical uncertainty of the model trends they introduced sigmase an estimate of the uncertainty of the mean of the predictions of the trends they defined sigmase as follows sigmase sigma sqrtn 1 where n 22 is the number of independent models as weve discussed in our previous correspondence this definition has serious problems see comments from carl and steve below and allows douglass et to reach the erroneous conclusion that modeled t2lt and t2 trends are significantly different from the observed t2lt and t2 trends in both the rss and uah datasets this comparison of simulated and observed t2lt and t2 trends is given in table iii of douglass et as an amusing aside i note that the rss datasets are referred to as rss in this table while uah results are designated as msu i guess theres only one true msu dataset i decided to take quick look at the issue of the statistical significance of differences between simulated and observed tropospheric temperature trends my first cut at this quick look involves only uah and rss observational data i have not yet done any tests with radiosonde datas umd t2 data or satellite results from zou et i operated on the same 49 realizations of the 20c3m experiment that we used in chapter 5 of ccsp 11 as in our previous work all model results are synthetic t2lt and t2 temperatures that i calculated using static weighting function approach i have not yet implemented carls more sophisticated method of estimating synthetic msu temperatures from model data which accounts for effects of topography and landocean differences however for the current application the simple static weighting function approach is more than adequate since we are focusing on t2lt and t2 changes over tropical oceans only so topographic and landocean differences are unimportant note that i still need to calculate synthetic msu temperatures from about 1820 20c3m realizations which were not in the cmip3 database at the time we were working on the ccsp report for the full response to douglass et we should use the same 67 20c3m realizations that they employed for each of the 49 realizations that i processed i first masked out all tropical land areas and then calculated the spatial averages of monthlymean gridded t2lt and t2 data over tropical oceans 20n20s all model and observational results are for the common 252month period from january 1979 to december 1999 the longest period of overlap between the rss and uah msu data and the bulk of the 20c3m runs the simulated trends given by douglass et are calculated over the same 1979 to 1999 period however they use longer period 1979 to 2004 for calculating observational trends so there is an inconsistency between their model and observational analysis periods which they do not explain this difference in analysis periods is little puzzling given that we are dealing with relatively short observational record lengths resulting in some sensitivity to endpoint effects i then calculated anomalies of the spatiallyaveraged t2lt and t2 data wrt climatological monthlymeans over 19791999 and fit leastsquares linear trends to model and observational time series the standard errors of the trends were adjusted for temporal autocorrelation of the regression residuals as described in santer et 2000 statistical significance of trends and trend differences in layeraverage atmospheric temperature time series jgr 105 73377356 consider first panel of the attached plot this shows the simulated and observed t2lt trends over 1979 to 1999 again over 20n20s oceans only with their adjusted 1sigma confidence intervals for the uah and rss data it was possible to check against the adjusted confidence intervals independently calculated by dian during the course of work on the ccsp report our adjusted confidence intervals are in good agreement the grey shaded envelope in panel denotes the 1sigma standard error for the rss t2lt trend there are 49 pairs of uahminusmodel trend differences and 49 pairs of rssminusmodel trend differences we can therefore test for each model and each 20c3m realization whether there is statistically significant difference between the observed and simulated trends let bx and by represent any single pair of modeled and observed trends with adjusted standard errors sbx and sby as in our previous work and as in related work by john lanzante we define the normalized trend difference d as d bx by sqrt sbx2 sby2 under the assumption that d is normally distributed values of d 196 or 196 indicate observedminusmodel trend differences that are significant at the 5 level we are performing twotailed test here since we have information priori about the direction of the model trend ie whether we expect the simulated trend to be significantly larger or smaller than observed panel c shows values of the normalized trend difference for t2lt trends the grey shaded area spans the range 196 to 196 and identifies the region where we fail to reject the null hypothesis h0 of significant difference between observed and simulated trends consider the solid symbols first which give results for tests involving rss data we would reject h0 in only one out of 49 cases for the cccmacgcm31t47 model the open symbols indicate results for tests involving uah data somewhat surprisingly we get the same qualitative outcome that we obtained for tests involving rss data only one of the uahmodel trend pairs yields difference that is statistically significant at the 5 level panels b and d provide results for t2 trends results are very similar to those achieved with t2lt trends irrespective of whether rss or uah t2 data are used significant trend differences occur in only one of 49 cases bottom line douglass et claim that in all cases uah and rss satellite trends are inconsistent with model trends page 6 lines 6162 this claim is categorically wrong in fact based on our results one could justifiably claim that there is only one case in which model t2lt and t2 trends are inconsistent with uah and rss results these guys screwed up big time sensitivity tests question 1 some of the modeldata trend comparisons made by douglass et used temperatures averaged over 30n30s rather than 20n20s what happens if we repeat our simple trend significance analysis using t2lt and t2 data averaged over ocean areas between 30n30s answer 1 very little the results described above for oceans areas between 20n20s are virtually unchanged question 2 even though its clearly inappropriate to estimate the standard errors of the linear trends without accounting for temporal autocorrelation effects the 252 time sample are clearly not independent effective sample sizes typically range from 6 to 56 someone is bound to ask what the outcome is when one repeats the paired trend tests with nonadjusted standard errors so here are the results t2lt tests rss observational data 19 out of 49 trend differences are significant at the 5 level t2lt tests uah observational data 34 out of 49 trend differences are significant at the 5 level t2 tests rss observational data 16 out of 49 trend differences are significant at the 5 level t2 tests uah observational data 35 out of 49 trend differences are significant at the 5 level so even under the naive and incorrect assumption that each model and observational time series contains 252 independent time samples we still find support for douglass et als assertion that in all cases uah and rss satellite trends are inconsistent with model trends qed if leo is agreeable im hopeful that well be able to perform similar trend comparison using synthetic msu t2lt and t2 temperatures calculated from the raobcore radiosonde data all versions not just v12 as you can see from the email list ive expanded our focus group little bit since number of you have written to about this issue i am leaving for miami on monday dec 17th my mom is having cataract surgery and id like to be around to provide her with moral and practical support im not exactly sure when ill be returning to pcmdi although i hope i wont be gone longer than week as soon as i get back ill try to make some more progress with this stuff any suggestions or comments on what ive done so far would be greatly appreciated and for the time being i think we should not alert douglass et to our results with best regards and happy holidays may all your singers be carol singers and not of the s fred variety ben ps i noticed one unfortunate typo in table ii of douglass et the miroc32 medres model is referred to as miroc32_merdes carl mears wrote hi steve id say its the equivalent of rolling 6sided die hundred times and finding mean value of 35 and standard deviation of 17 and calculating the standard error of the mean to be 017 so far so good an then rolling the die one more time getting 2 and claiming that the die is longer 6 sided because the new measurement is more than 2 standard errors from the mean in my view this problem trumps the other problems in the paper i cant believe douglas is fellow of the american physical society carl at 0207 am 1262007 you wrote if i understand correctly what douglass et did makes the stronger assumption that unforced variability is insignificant their statistical test is logically equivalent to falsifying climate model because it did not consistently predict particular storm on particular day two years from now dr carl mears remote sensing systems 438 first street suite 200 santa rosa ca 95401 mearsremsscom 7075452904 x21 7075452906 fax benjamin d santer program for climate model diagnosis and intercomparison lawrence livermore national laboratory po box 808 mail stop l103 livermore ca 94550 usa tel 925 4222486 fax 925 4227675 email santer1llnlgov xflowed attachment converted ceudoraattachdouglass_reply1pdf