read for harrys work on the cru ts2130 datasets 20062009 1 two main filesystems relevant to the work crudpe1af014 crutyn1f014 both systems copied in their entirety to crucruts nearly 11000 files and about dozen assorted read files addressing individual issues the most useful being fromdpe1adatastnmondocoldmethodf90_read_metxt fromdpe1acodelinuxcruts_read_metxt fromdpe1acodeidlproreadme_griddingtxt yes they all have different name formats and yes one does begin _ 2 after considerable searching identified the latest database files for tmean fromdpe1adatacrutsdatabasenormtmp0311051552dtb fromdpe1adatacrutsdatabasenormtmp0311051552dts yes that is directory beginning with 3 successfully ran anomdtbf90 to produce anomaly files as per item 7 in the _read_metxt file had to make some changes to allow for the move back to alphas different field length from the wc l command 4 successfully ran the idl regridding routine quick_interp_tdmpro why idl why not f90 to produce glo files 5 currently trying to convert glo files to grim files so that we can compare with previous output however the progam suite headed by globulkf90 is not playing nicely problems with it expecting defunct file system all path widths were 80ch have been globally changed to 160ch and also guidance on which reference files to choose it also doesnt seem to like files being in any directory other than the current one 6 temporarily abandoned 5 getting closer but theres always another problem to be evaded instead will try using rawtogrimf90 to convert straight to grim this will include nonland cells but for comparison purposes that shouldnt be big problem edit noo thats not gonna work either it asks for template grim filepath idea what it wants as usual and serach for files with grim or template in them does not bear useful fruit as per usual giving up on this approach altogether 7 removed 4line header from couple of glo files and loaded them into matlab reshaped to 360r x 720c and plotted looks ok for global temp anomalies data deduce that glo files after the header contain data taken rowbyrow starting with the northernmost and presented as 8e124 the grid is from 180 to 180 rather than 0 to 360 this should allow us to deduce the meaning of the coordinate pairs used to describe each cell in grim file we know the first number is the lon or column the second the lat or row but which way up are the latitudes and where do the longitudes break there is another problem the values are anomalies wheras the public grim files are actual values so tims explanations in _read_metxt are incorrect 8 had hunt and found an identicallynamed temperature database file which did include normals lines at the start of every station how handy naming two different files with exactly the same name and relying on their location to differentiate aaarrgghh reran anomdtb crua6crucrutsrerun1datacrutsrerun1work anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required tmp select the cts or dtb file to load tmp0311051552dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 8 select the generic txt file to save yymmauto rr2txt select the firstlast years ad to save 19012002 operating failed to find file enter the file with suffix dts tmp0311051552dts values loaded 1255171542 stations 12155 normals mean percent stdev percent dtb 5910325 866 cts 575661 84 6485986 950 process decision percent ofchk latlon 12043 02 02 normal 335741 49 49 outofrange 31951 05 05 duplicated 341323 50 53 accepted 6107721 894 dumping years 19012002 to txt files crua6crucrutsrerun1datacrutsrerun1work 9 ran the idl function idl quick_interp_tdm219012002rr2glofilesrr2grid1200gs05dumpglodumpglopts_prefixrr2txtfilesrr2 compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1902 etc 2002 idl this produces anomoly files even when given normalsadded database doesnt create the climatology however we do have it both in the normals directory of the user data directory and in the dpe1a cru_cl_10 folder the relevant file is clim6190lantmp obviously this is for land only 10 trying to compare glo and grim wrote several programs to assist with this process tried creating anomalies from the grim files using the published climatology then tried to compare with the glo files id produced this is all for 19611970 couldnt get sensible grid layout for the glo files eventually resorted to visualisation looks like the glo files are regular grid format after all longitudes change fastest dont understand why the comparison program had so much trouble getting matched cells 11 decided to concentrate on norwich tim m uses norwich as the example on the website so we know its at 363286 wrote prog to extract the relevant 19611970 series from the published output the generated glo files and the published climatology prog is norwichtestfor prog also creates anomalies from the published data and raw data from the generated glo data then matlab prog plotnorwichm plots the data to allow comparisons first result works perfectly except that the glo data is all zeros this means i still dont understand the structure of the glo files argh 12 trying something else will write prog to convert the 19611970 glo files to single file with 120 columns and row for each nonzero cell it will be slow it is nuisance because the site power off this weekend and its friday afternoon so i will get it running at home program is glo2vecfor and yup it is slow started second copy on uealogin1 and its showing signs of overtaking the crua6 version that started on friday its tuesday now im about halfway through and the best correlation so far as tested by norwichcorrfor is 039 at 170135 lonlat 13 success i would crack open bottle of bubbly but its only 1125am the program norwichcorrfor found correlation for the norwich series at 363 286 of 100 so we have found the published norwich series in the grids i produced palpable sense of relief pervades the office its also the grid reference given by tim for norwich so how did i miss it earlier 14 wrote program glo2grimfor to do what i cannot get tims raw2grimf90 ie convert glo files to grim format its slow but sure in parallel quick prog called grimcmpfor which compares two grimformat files it produces brief stats at time of writing just over 4000 cells have been converted and the output of grimcmp is uealogin1crucrutsrerun1datacrutsrerun1work grimcmp welcome to the grim comparer please enter the first grim file must be complete cru_ts_2_1019611970tmp please enter the second grim file may be incomplete glo2grim1out file glo2grim1out terminated prematurely after 4037 records summary from grimcmp files compared 1 cru_ts_2_1019611970tmp 2 glo2grim1out total cells compared 4037 total 100 matches 0 cells with corr 100 0 00 cells with 090corr099 3858 956 cells with 080corr089 119 29 cells with 070corr079 25 06 which is good news not brilliant because the data should be identical but good because the correlations are so high this could be result of my missetting of the parameters on tims programs although i have followed his recommendations wherever possible or it could be result of tim using the beowulf 1 cluster for the f90 work beowulf 1 is now integrated in to the latest beowulf cluster so it may not be practical to test that theory 15 all change my glo2grim1 program was presciently named as its now up to v3 my attempt to speed up early iterations by only reading as much of each glo file as was needed was really stupidly coded and hence the poor results actually theyre worryingly good as the data was effectively random 0 we are now onbeam and initial results are very very promising uealogin1crucrutsrerun1datacrutsrerun1work grimcmp3x file glo2grim3out terminated prematurely after 143 records summary from grimcmp files compared 1 cru_ts_2_1019611970tmp 2 glo2grim3out total cells compared 143 total 100 matches 12 cells with corr 100 12 84 cells with 096corr099 130 909 cells with 090corr095 1 07 cells with 080corr089 0 00 cells with 070corr079 0 00 so all correlations are 09 and all but one are 096 with 12 complete 100 identical matches i think we can safely say we are producing the data tim produced the variations can be accounted for as rounding errors due to different hardware and compilers i reckon 16 so it seemed like good time to start precip run with bit of luck this would go as smoothly as the temperature run ho ho ho the first problem was that anomdtb kept crashing crua6crucrutsrerun1datacrutsrerun2work anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required pre will calculate percentage anomalies select the cts or dtb file to load pre0312031600dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 8 select the generic txt file to save yymmauto rr2pretxt select the firstlast years ad to save 19012002 operating values loaded 1258818288 stations 12732 normals mean percent stdev percent dtb 2635549 296 forrtl error 75 floating point exception iot trap core dumped crua6crucrutsrerun1datacrutsrerun2work not good tried recompiling for uealogin1 aargghhh tims code is not good enough for bloody sun pages of warnings and 27 errors full results in anomdtbuealogin1compileresults 17 inserted debug statements into anomdtbf90 discovered that sumofsquared variable is becoming very very negative key output from the debug statements open 1600 optotsq 414218200 optot 712600 dataa val 93 optotsq 864900 dataa val 172 optotsq 3823300 dataa val 950 optotsq 94073300 dataa val 797 optotsq 157594200 dataa val 293 optotsq 166179100 dataa val 83 optotsq 166868000 dataa val 860 optotsq 240828000 dataa val 222 optotsq 245756400 dataa val 452 optotsq 266186800 dataa val 561 optotsq 297658900 dataa val 49920 optotsq179998425600 dataa val 547 optotsq179968499200 dataa val 672 optotsq179923340800 dataa val 710 optotsq179872934400 dataa val 211 optotsq179868480000 dataa val 403 optotsq179852236800 open 1600 optotsq179852236800 optot5694600 forrtl error 75 floating point exception iot trap core dumped so the data value is unbfeasibly large but why does the sumofsquares parameter optotsq go negative probable answer the high value is pushing beyond the single precision default for fortran reals value located in pre0312031600dtb 400002 3513 3672 309 hama syria 1985 2002 999 999 6190 842 479 3485 339 170 135 106 0 9 243 387 737 1985 887 582 93 16 17 0 0 0 0 352 221 627 1986 899 252 172 527 173 30 0 0 0 84 496 570 1987 578 349 950 191 4 0 0 0 0 343 462 929 1988 1044 769 797 399 11 903 218 0 0 163 517 1181 1989 269 62 293 3 13 0 0 0 0 101 292 342 1990 328 276 83 135 224 0 0 0 0 87 343 230 1991 1297 292 860 320 70 0 0 0 0 206 298 835 1992 712 1130 222 39 339 301 0 0 0 0 909 351 1993 726 609 452 82 672 3 0 0 0 34 183 351 1994 625 661 561 41 155 0 0 0 22 345 953 1072 1995 48899999999 1829999 09999 0 0 0 7549999 19969999 409499209999 82 09999 0 36 414 112 312 19979999 339 5479999 5619999 0 0 54 155 265 962 1998 1148 289 672 4969999 0 09999 9 219999 1206 1999 343 379 710 111 0 0 0999999999999 132 285 2000 1518 399 211 354 27 09999 0 27 269 316 1057 2001 37099999999 273 452 0999999999999 290 3569999 2002 871 329 403 111 2339999 0 099999999 377 1287 value is for march 1996 action value replaced with 9999 and file renamed pre0312031600hdtb to indicate ive fixed it dts file also renamed for consistency anomdtb then runs fine producing the usual txt files 18 ran the idl gridding routine for the precip files quick_interp_tdm219012002rr2preglofilesrr2pregrid450gs05dumpglodumpglopts_prefixrr2pretxtfilesrr2pre and this is where it gets crazy instead of running normally this time i get idl quick_interp_tdm219011910rr2glofiles2rr2grid1200gs05dumpglodumpglopts_prefixrr2txtfilesrr2 limitglimitall sets limit to global field syntax error at crucrutsfromdpe1acodeidlproquick_interp_tdm2pro line 38 limglimitall syntax error at crucrutsfromdpe1acodeidlproquick_interp_tdm2pro line 122 rarea_gridpts2n1pts2n0pts2n2gs20boundsdistangularangular syntax error at crucrutsfromdpe1acodeidlproquick_interp_tdm2pro line 183 compiled module quick_interp_tdm2 attempt to call undefined procedurefunction quick_interp_tdm2 execution halted at main idl what now its not precompiling its functions for some reason whats more i cannot find the glimit function anywhere eventually the following day i found glimit and area_grid they are in mark news folder cruu2f080idl since this is in idl_path i have idea why theyre not compiling i manually compiled them with compile and the errors vanished though not for long idl compile cruu2f080idlglimitpro compiled module glimit idl compile cruu2f080idlarea_gridpro compiled module area_grid idl quick_interp_tdm219011910rr2glofiles2rr2grid1200gs05dumpglodumpglopts_prefixrr2txtfilesrr2 compiled module quick_interp_tdm2 defaults set 1901 compiled module map_set compiled module crossp variable is undefined strip execution halted at quick_interp_tdm2 215 crucrutsfromdpe1acodeidlproquick_interp_tdm2pro main idl was this similar problem unfortunately not idl compile cruu2f080idlstrippro compiled module strip idl quick_interp_tdm219011910rr2glofiles2rr2grid1200gs05dumpglodumpglopts_prefixrr2txtfilesrr2 defaults set 1901 variable is undefined strip execution halted at quick_interp_tdm2 215 crucrutsfromdpe1acodeidlproquick_interp_tdm2pro quick_interp_tdm2 215 crucrutsfromdpe1acodeidlproquick_interp_tdm2pro main idl so it looks like path problem i wondered if the nfs errors that have been plagueing crua6 work for some time now might have prevented idl from adding the correct directories to the path after all the help file does mention that idl discards any path entries that are inaccessible so if the timeout is few seconds that would explain it so i restarted idl and presto it worked i then tried the precip veriosn and it worked too idl quick_interp_tdm219012002rr2preglofilesrr2pregrid450gs05dumpglodumpglopts_prefixrr2pretxtfilesrr2pre compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1902 etc 2001 2002 idl i then ran glo2grim4for to convert from percentage anomalies to real 10ths of mm values initial results are not as good as temperature but mainly above 096 so obviously on the right track however 19 here is little puzzle if the latest precipitation database file contained fatal data error see 17 above then surely it has been altered since tim last used it to produce the precipitation grids but if thats the case why is it dated so early here are the dates crudpe1af014datacrutsdatabasenormpre0312031600dtb directory date is 23 dec 2003 crutyn1f014ftpfudgedatacru_ts_210data_deccru_ts_2_1019611970prez directory date is 22 jan 2004 original date not preserved in zipped file internal header date is also 22012004 at 1757 so whats going on i dont see how the final precip file can have been produced from the final precipitation database even though the dates imply that the obvious conclusion is that the precip file must have been produced before 23 dec 2003 and then redated to match others in jan 04 20 secondary variables eeeeeek yes the time has come to attack what even tim seems to have been unhappy about reading between the lines to assist i have 12 lines in the gridding readme file so par for the course almost immediately i hit that familiar feeling of ambiguity the text suggests using the following three idl programs frs_gts_tdmpro rd0_gts_tdmpro vap_gts_anompro so when i look in the codeidlpro folder what do i find well 3447 jan 22 2004 fromdpe1acodeidlprofrs_gts_anompro 2774 jun 12 2002 fromdpe1acodeidlprofrs_gts_tdmpro 2917 jan 8 2004 fromdpe1acodeidlprord0_gts_anompro 2355 jun 12 2002 fromdpe1acodeidlprord0_gts_tdmpro 5880 jan 8 2004 fromdpe1acodeidlprovap_gts_anompro in other words the anompro scripts are much more recent than the tdm scripts there is way of knowing which tim used to produce the current public files the scripts differ internally but you guessed it the descriptions at the start are identical what is going on given that the readme_griddingtxt file is dated mar 30 2004 we will have to assume that the originallystated scripts must be used to begin with we need binary output from quick_interp_tdm2 so its run again for tmp and pre and for the first time for dtr this time the command line looks like this for tmp idl quick_interp_tdm219012002idlbinoutidlbin1200gs25dumpbindumpbinpts_prefixtmp_txt_4idltmp this gives screen output for each year typically 1991 grid 1991 nonzero 09605 20878 21849 cells 27048 and produces output files in in this case idlbinout like this rw 1 f098 cru 248832 sep 21 1220 idlbin_tmpidlbin_tmp1991 at this point did some logical renaming so txt files preidl are typically tmp190101txt in tmp_txt_4idl binary files postidl are typically idlbin_tmp1991 in idlbin_tmp these changes rolled back to the quoted command lines to avoid confusion next precip command line idl quick_interp_tdm219012002idlbin_preidlbin_pre450gs25dumpbindumpbinpts_prefixpre_txt_4idlpre note new filenaming schema this gives example screen output 1991 grid 1991 nonzero 48533 362155 510738 cells 51060 and produces output files like rw 1 f098 cru 248832 sep 21 1250 idlbin_preidlbin_pre1991 finally for the primaries the first stab at dtr ran anomdtb with the database file dtr0312221128dtb and the standardrecommended responses screen output normals mean percent stdev percent dtb 0 00 cts 3375441 841 3375441 841 process decision percent ofchk latlon 3088 01 01 normal 638538 159 159 outofrange 70225 17 21 duplicated 135457 34 41 accepted 3167636 789 dumping years 19012002 to txt files then for the gridding idl quick_interp_tdm219012002idlbin_dtridlbin_dtr750gs25dumpbindumpbinpts_prefixdtr_txt_4idldtr giving screen output 1991 grid 1991 nonzero 03378 16587 17496 cells 3546 and files such as rw 1 f098 cru 248832 sep 21 1339 idlbin_dtridlbin_dtr1991 and at this point i read the readme file properly i should be gridding at 25 degrees not 05 degrees for some reason secondary variables are not derived from the 05 degree grids redid all three generations the sample command lines and outputs above have been altered to reflect this to avoid confusion so to the generation of the synthetic grids tried running frs_gts_tdm but it complained it couldnt find the normals file idl frs_gts_tdmdtr_prefixidlbin_dtridlbin_dtrtmp_prefixidlbin_tmpidlbin_tmp19012002outprefixsyngrid_frssyngrid_frs compiled module frs_gts_tdm attempt to call undefined procedurefunction frs_gts_tdm execution halted at main idl frs_gtsdtr_prefixidlbin_dtridlbin_dtrtmp_prefixidlbin_tmpidlbin_tmp19012002outprefixsyngrid_frssyngrid_frs compiled module rdbin compiled module strip ls homecruf098m1gtsfrsgloglofrsnorm not found ls homecruf098m1gtsfrsgloglofrsnormz not found ls homecruf098m1gtsfrsgloglofrsnormgz not found readf end of file encountered unit 99 file foo execution halted at rdbin 25 cruu2f080idlrdbinpro frs_gts 18 crucrutsfromdpe1acodeidlprofrs_gts_tdmpro main idl however when i eventually found what i hope is the normals file crucrutsfromdpe1adatagridtwohalfglo25frs6190 and altered the idl prog to read it same error turns out its preferring to pick up mark ns version so tried explicitly compiling compile xxxxxxpro that worked in that the error changed idl frs_gtsdtr_prefixidlbin_dtridlbin_dtrtmp_prefixidlbin_tmpidlbin_tmp19012002outprefixsyngrid_frssyngrid_frs compiled module rdbin compiled module strip yes variable is undefined nf execution halted at rdbin 68 cruu2f080idlrdbinpro frs_gts 21 crucrutsfromdpe1acodeidlprofrs_gts_tdmpro main idl so what is this mysterious variable nf that isnt being set well strangely its in mark ns rdbinpro i say strangely because this is generic prog thats used all over the place nonetheless it does have what certainly looks like bug 38 if keyword_setgridsize eq 0 then begin 39 infofstatlun 40 if keyword_setseas then infosizeinfosize20 41 if keyword_setann then infosizeinfosize120 42 nlatsqrtinfosize480 43 gridsize1800nlat 44 if keyword_setquiet eq 0 then printfilesizeinfosize 45 if keyword_setquiet eq 0 then printgridsizegridsize 46 endif 47 if keyword_sethad then had1 else had0 48 if keyword_setecham then echam1 else echam0 49 if keyword_setgfdl then gfdl1 else gfdl0 50 if keyword_setccm then ccm1 else ccm0 51 if keyword_setcsiro then csiro1 else csiro0 52 create array to read data into 53 if keyword_setseas then nf6 else nf12 54 if keyword_setann then nf1 55 defxyzlonlatgridsizegridgridnfnfhadhadechamechamgfdlgfdlccmccmcsirocsiro 56 if keyword_setquiet eq 0 then helpgrid 57 gridfixgrid 58 read data 59 readulungrid 60 closelun 61 spawnstringrm f fff 62 endif else begin 63 openrlunfname 64 check file size and work out grid spacing if gridsize isnt set 65 if keyword_setgridsize eq 0 then begin 66 infofstatlun 67 if keyword_setquiet eq 0 then printyes 68 nlatsqrtinfosizenf40 69 gridsize1800nlat 70 if keyword_setquiet eq 0 then printfilesizeinfosize 71 if keyword_setquiet eq 0 then printgridsizegridsize 72 endif 73 if keyword_setseas then nf60 else nf120 74 if keyword_setann then nf1 in other words nf is set in the first conditional set of statements but in the alternative starting on 62 it is only set after its used set 7374 used 68 so i shifted 73 and 74 to between 64 and 65 and with precompiling to pick up the local version of rdbin too it worked er perhaps lots of screen output and lots of files set of synthetic grids in syngrid_frs as requested typically rw 1 f098 cru 20816 sep 17 2210 syngrid_frssyngrid_frs1991z but also set of some binariy files in the working directory they look like this rw 1 f098 cru 51542 sep 17 2210 glofrs1991z having read the program it looks as though the latter files are absolutes whereas the former are anomalies with this in mind they are renamed glofrs1991 glofrsabs1991 and put into folder syngrid_frs_abs then real setback looked for database file for frost nothing is this real secondary parameter answer yes further digging revealed that quick_interp_tdm2pro has nostn command line option its undocumented as usual but it does seem to avoid the use of the pts_prefix option so i set it and it at least ran for the full term though very slow compared to primary variables idl quick_interp_tdm219012002glo_frs_gridsfrsgrid750gs05dumpglodumpglonostn1synth_prefixsyngrid_frssyngrid_frs it does produce output grids without converting to absolutes with the normals file its hard to know if theyre realistic then i moved on to rd0 wetday frequency this time when i searched for the normals files required gloprenorm and glord0norm i could not as before find exact matches the difference this time is that the program checks that the normals file supplied is 05degree grid so glo25pre6190 failed this implies to that my approach to frs above was wrong as well where is the documenatation to explain all this finally breakthrough search of mark news old directory hierarchy revealed what look like the required files crua6crumark1f080 find name glonorm gtscldgloglocldnormz gtsdtrglo_oldglodtrnormz gtsfrsglofrsnormz gtsfrsgloglofrsnormz find cannot open gtsfrsglo_txt gtspreglo_quick_absgloprenormz gtspreglo_quick_loggloprenormz gtspreglo_splgloprenormz find cannot open gtspre_percstation_list gtsradglogloradnormz gtsrd0gloglord0normz gtsrd0glo_oldglord0normz gtssunpgloglosunpnorm gtssunpmeansglosunpnormz gtstmpgloglotmpnormz gtstmpglo_oldglotmpnormz find cannot open gtstmpstation_list gtsvapgloglovapnormz gtswndgloglowndnormz listing of crumark1f080gts gives drwxrx 2 f080 cru 1024 sep 12 2005 cdrom drwxrx 10 f080 cru 57344 nov 1 2001 cld drwxrxrx 19 f080 cru 24576 feb 27 2001 dtr drwxrx 2 f080 cru 8192 feb 25 1998 elev drwxrx 2 f080 cru 8192 jun 8 1998 euroclivar rwr 1 f080 cru 0 aug 3 1999 foo drwxrx 6 f080 cru 8192 aug 6 2002 frs rwrx 1 f080 cru 438 may 12 1998 gtserrors rwr 1 f080 cru 10 jul 21 1999 in drwxrx 5 f080 cru 8192 jan 6 1999 jiang drwxrx 2 f080 cru 8192 apr 7 1998 landsea rwr 1 f080 cru 240 may 12 1998 normalerrors drwxrx 5 f080 cru 8192 aug 6 2002 plots drwxrxrx 12 f080 cru 106496 may 22 2000 pre drwxrx 9 f080 cru 114688 aug 6 2002 pre_perc drwxrx 4 f080 cru 1024 jan 6 1999 rad drwxrxx 6 f080 cru 8192 nov 1 2001 rd0 rwxrxr 1 f080 cru 1779 dec 5 1997 readmetxt drwxrx 8 f080 cru 1024 apr 5 2000 reg_series drwxrx 3 f080 cru 1024 oct 18 1999 reh drwxrx 2 f080 cru 8192 jan 19 2000 scengen drwxrx 5 f080 cru 24576 nov 5 1998 sunp drwxrx 2 f080 cru 1024 aug 6 2002 test drwxrx 4 f080 cru 1024 aug 3 1999 tmn drwxrxrx 20 f080 cru 122880 mar 19 2002 tmp drwxrx 4 f080 cru 1024 aug 3 1999 tmx drwxrx 6 f080 cru 1024 jul 8 1998 ukcip drwxrx 5 f080 cru 8192 nov 5 2001 vap drwxrx 4 f080 cru 1024 jul 2 1998 wnd and listing of for example the frs directory drwxrx 2 f080 cru 16384 jul 18 2002 glo rwrx 1 f080 cru 433393 aug 12 1998 glofrs1961z rwrx 1 f080 cru 321185 aug 12 1998 glofrsano1961z rwrx 1 f080 cru 740431 aug 12 1998 glofrsnormz drwxrxrx 2 f080 cru 16384 jul 27 1999 glo25 drwx 2 f080 cru 8192 jul 18 2002 glo_txt drwxrxrx 2 f080 cru 8192 aug 28 1998 means so the following were copied to the working area cp crumark1f080gtsfrsglofrsnormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtscldgloglocldnormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtsdtrglo_oldglodtrnormz crucrutsrerun1datacrutsrerun_synth precip looked like it might be problem 3 matching files see above but on investigation they were found to be identical wonderful cp crumark1f080gtspreglo_quick_loggloprenormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtsradglogloradnormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtsrd0gloglord0normz crucrutsrerun1datacrutsrerun_synth there were two sunp norm files but one was 0 bytes in length cp crumark1f080gtssunpmeansglosunpnormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtstmpgloglotmpnormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtsvapgloglovapnormz crucrutsrerun1datacrutsrerun_synth cp crumark1f080gtswndgloglowndnormz crucrutsrerun1datacrutsrerun_synth the synthetics generation was then rerun for frs records above have been modified to reflect this next rd0 synthetics generated ok idl rd0_gts1901200219611990outprefixsyngrid_rd0syngrid_rd0pre_prefixidlbin_preidlbin_pre until the end 2001 yes filesize 248832 gridsize 250000 2002 yes filesize 248832 gridsize 250000 program caused arithmetic error floating divide by 0 program caused arithmetic error floating illegal operand idl however all synthetic grids appear to have been written ok including 2002 grid generation proceeded without error idl quick_interp_tdm219012002glo_rd0_gridsrd0grid450gs05dumpglodumpglonostn1synth_prefixsyngrid_rd0syngrid_rd0 onto vapour pressure and the crunch for here the recommended program for synthetic grid production is vap_gts_anompro in fact there is sign of vap_gts_tdmpro and in the program notes it reads required inputs are vapour pressure and temperature normals on 25deg grid these come readysupplied for 196190 normal period temp and dtr monthly anomalies on 25deg grid including normal period so we face situation where some synthetics are built with 05degree normals and others are built with 25degree normals i can find documentation of this there are _anompro versions of the frs and rd0 programs both of which use 25degree normals however they are dated jan 2004 and tims read_me which refers to the _tdmpro 05degree versions is dated end march 2004 so we have to assume these are his best suggestions the 25 normals are found here ls l crucrutsfromdpe1adatagridtwohalf total 1248 rwxrxrx 1 f098 cru 248832 jan 9 2004 glo25frs6190 rwxrxrx 1 f098 cru 248832 jan 8 2004 glo25pre6190 rwxrxrx 1 f098 cru 248832 jan 8 2004 glo25rd06190 rwxrxrx 1 f098 cru 248832 jan 7 2004 glo25tmp6190 rwxrxrx 1 f098 cru 248832 jan 6 2004 glo25vap6190 rwxrxrx 1 f098 cru 86 feb 25 2004 readmetxt readmetxt 25deg climatology files tim mitchell 25204 these are in mark news binary format end set up the required inputs and ran it idl vap_gts_anomdtr_prefixidlbin_dtridlbin_dtrtmp_prefixidlbin_tmpidlbin_tmp19012002outprefixsyngrid_vapsyngrid_vapdumpbin1 producing screen output like this 1991 vap xs2 0000493031 0000742087 00595093 186497 and output files like this rw 1 f098 cru 248832 sep 22 1056 syngrid_vapsyngrid_vap1991 on without further ado to the gridding for this secondary there are database files so the nostn option is not used and anomdtbf is wheeled out again to construct txt files for the run crua6crucrutsrerun1datacrutsrerun_vap anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required vap select the cts or dtb file to load vap0311181410dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 8 select the generic txt file to save yymmauto vaptxt select the firstlast years ad to save 19012002 operating values loaded 1239868112 stations 7691 normals mean percent stdev percent dtb 887754 469 cts 34175 18 921929 487 process decision percent ofchk latlon 105 00 00 normal 969384 513 513 outofrange 2661 01 03 duplicated 25557 14 28 accepted 893711 473 dumping years 19012002 to txt files crua6crucrutsrerun1datacrutsrerun_vap moved straight onto the gridding which of course failed idl quick_interp_tdm219012002glo_vap_gridsvapgrid1000gs05dumpglodumpglosynth_prefixsyngrid_vapsyngrid_vappts_prefixrerun_vapvap_txt_4idlvap defaults set 1901 1902 array dimensions must be greater than 0 execution halted at quick_interp_tdm2 88 crucrutsfromdpe1acodeidlproquick_interp_tdm2pro quick_interp_tdm2 88 crucrutsfromdpe1acodeidlproquick_interp_tdm2pro main idl this turns out to be because of the sparcity of vap station measurements in the early years the program cannot handle anom files of 0 length even though it checks the length bizarre the culprit is vap190203txt the only month to have station reading at all 45 months have only 1 however i decided to mod the program to use the nostn option if the length is 0 hope thats right the synthetics are read in first and the station data is added to that grid so this should be ok and it looks ok idl quick_interp_tdm219012002vapgrid1000gs05dumpglodumpglosynth_prefixsyngrid_vapsyngrid_vappts_prefixrerun_vapvap_txt_4idlvap compiled module glimit defaults set 1901 1902 stations found in rerun_vapvap_txt_4idlvap190203txt 1903 etc pause for reflection the list of cru_ts_21 parameters is as follows pre primary done tmp primary done tmx derived not done tmn derived not done dtr primary done vap secondary done cldspc secondary not done wet secondary done frs secondary done now the interesting thing is that the read file for gridding only mentions frs rd0 which im assuming wet and vap how then do i produce cldspc and the two derived vars well theres crucrutsfromdpe1acodeidlprocal_cld_gts_tdmpro also crucrutsfromdpe1acodeidlprocloudcorrspcpro crucrutsfromdpe1acodeidlprocloudcorrspcannpro crucrutsfromdpe1acodeidlprocloudcorrspcann9196pro loading just the first program opens up another huge can worms the program description reads pro cal_cld_gts_tdmdtr_prefixoutprefixyear1year2infoinfo calculates cld anomalies using relationship with dtr anomalies reads coefficients from predefined files 1000 reads dtr data from binary output files from quick_interp_tdm2pro binfac1000 creates cld anomaly grids at dtr grid resolution output can then be used as dummy input to splining program that also includes real cloud anomaly data so to this identifies it as the program we cannot use any more because the coefficients were lost as it says in the gridding read_me bear in mind that there is working synthetic method for cloud because mark new lost the coefficients file and never found it again despite searching on tape archives at uea and never recreated it this hasnt mattered too much because the synthetic cloud grids had not been discarded for 190195 and after 1995 sunshine data is used instead of cloud data anyway but lord how many times have i used however or but in this file when you look in the program you find that the coefficient files are called rdbinacrutyn1f709762cru_ts_20_constants_7190a257190gridsize25 rdbinbcrutyn1f709762cru_ts_20_constants_7190b257190gridsize25 and if you do search over the filesystems you get crua6crucruts ls fromdpe1adatagridcru_ts_20_makecld_constants_7190spc2cld_ann a25017190gloz a25057190gloz a25097190gloz a257190epsz b25047190gloz b25087190gloz b25127190gloz a25027190gloz a25067190gloz a25107190gloz b25017190gloz b25057190gloz b25097190gloz b257190epsz a25037190gloz a25077190gloz a25117190gloz b25027190gloz b25067190gloz b25107190gloz a25047190gloz a25087190gloz a25127190gloz b25037190gloz b25077190gloz b25117190gloz crua6crucruts ls fromdpe1adatagridcru_ts_20_makecld_constants_7190spc2cld_mon a25017190gloz a25057190gloz a25097190gloz a257190epsz b25047190gloz b25087190gloz b25127190gloz a25027190gloz a25067190gloz a25107190gloz b25017190gloz b25057190gloz b25097190gloz b257190epsz a25037190gloz a25077190gloz a25117190gloz b25027190gloz b25067190gloz b25107190gloz a25047190gloz a25087190gloz a25127190gloz b25037190gloz b25077190gloz b25117190gloz so we dont have the coefficients files just eps plots of something but what are all those monthly files dont know undocumented wherever i look there are data files info about what they are other than their names and thats useless take the above example the filenames in the _mon and _ann directories are identical but the contents are not and the only difference is that one directory is apparently monthly and the other annual yet both contain monthly files lots of further investigation probably the most useful program found is cal_cld_gts_tdmpro the description of which reads as follows pro cal_cld_gts_tdmdtr_prefixoutprefixyear1year2infoinfo calculates cld anomalies using relationship with dtr anomalies reads coefficients from predefined files 1000 reads dtr data from binary output files from quick_interp_tdm2pro binfac1000 creates cld anomaly grids at dtr grid resolution output can then be used as dummy input to splining program that also includes real cloud anomaly data it also tellingly contains unnecessary because 6190 normals have already been created print looking for 25 deg dtr 196190 mean_gtsm1gtsdtrglo25glo25dtrnor1nor2 mean_gts_tdmcrumark1f080gtsdtrglo25glo25dtrnor1nor2 print looking for 25 deg dtr normal rdbindtrnorm1gtsdtrglo25glo25dtrstringnor11900nor21900form2i22 dtrnorstrcrumark1f080gtsdtrglo25glo25dtrstringnor11900nor21900form2i22 rdbindtrnordtrnorstr the above has seemingly been replaced with rdbinacrutyn1f709762cru_ts_20_constants_7190a257190gridsize25 rdbinbcrutyn1f709762cru_ts_20_constants_7190b257190gridsize25 these are the files that have been lost according to the gridding read_me see above the conclusion of lot of investigation is that the synthetic cloud grids for 19011995 have now been discarded this means that the cloud data prior to 1996 are static edit have just located cld directory in mark news disk containing over 2000 files most however are binary and undocumented eventually find fortran f77 programs to convert sun to cloud sh2cld_tdmfor converts sun hours monthly time series to cloud percent sp2cld_mfor converts sun percent monthly time series to cloud oktas there are also programs to convert sun parameters sh2sp_mfor sun hours to sun percent sh2sp_normalfor sun hours monthly nrm to sunshine percent sh2sp_tdmfor sun hours monthly time series to sunshine percent agreed approach for cloud 5 oct 06 for 1901 to 1995 stay with published data clear way to replicate process as undocumented for 1996 to 2002 1 convert sun database to pseudocloud using the f77 programs 2 anomalise wrt 9600 with anomdtbf 3 grid using quick_interp_tdmpro which will use 6190 norms 4 calculate mean9600 mean6190 for monthly grids using the published cru_ts_20 cloud data 5 add to gridded data from step 3 this should approximate the correction needed on we go firstly examined the spc database seems to be in x10 looked at published data cloud is in x10 too first problem there is program to convert sun percentage to cloud percentage i can do sun percentage to cloud oktas or sun hours to cloud percentage so what the hell did tim do as i keep asking examined the program that converts sun to cloud oktas it is complicated have inserted line to multiple the result by 125 the result is in oktas10 and ranges from 0 to 80 so the new result will range from 0 to 1000 next problem which database to use the one with the normals included is not appropriate the conversion progs do not look for that line so obviously are not intended to be used on norm databases the non normals databases are either jan 03 in the _ateam directory or dec 03 in the regular database directory the newer database is smaller so more weeding than planting in 2003 unfortunately both databases contain the 6190 normals line just unpopulated so i will go with the spc0312221624dtb database and modify the already modified conversion program to process the 6190 line then comparing the two candidate spc databases spc0312221624dtb spc94000312221624dtb i find that they are broadly similar except the normals lines which both start with 6190 are very different i was expecting that maybe the latter contained 9400 normals what i wasnt expecting was that thet are in x10 not unbelievable even here the conventions have not been followed its botch after botch after botch modified the conversion program to process either kind of normals line decided to go with the spc94000312221624dtb database as it hopefully has some of the 9400 normals in i just wish i knew more conversion was hampered by the discovery that some stations have mix of and x10 values so more mods to hsp2cldp_mfor then conversion producing cldfromspc94000312221624dtb copied the dts file across as is not sure what it does unfortunately or cant remember after conversion ran anomdtb crua6crucrutsrerun1datacrutsrerun_cld anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required cld select the cts or dtb file to load cldfromspc94000312221624dtb specify the startend of the normals period 19942000 specify the missing percentage permitted 25 data required for normal 6 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 8 select the generic txt file to save yymmauto cldfromspctxt select the firstlast years ad to save 19942002 operating cts 96309 196 280712 572 process decision percent ofchk latlon 0 00 00 normal 209619 428 428 outofrange 177298 362 632 duplicated 154 00 01 accepted 103260 211 dumping years 19942002 to txt files crua6crucrutsrerun1datacrutsrerun_cld then ran quick_interp_tdm2 idl compile crucrutsfromdpe1acodeidlproquick_interp_tdm2pro compiled module quick_interp_tdm2 idl compile crucrutsfromdpe1acodeidlprordbinpro compiled module rdbin idl quick_interp_tdm219942002glo_from_idlcld600gs05pts_prefixtxt_4_idlcldfromspcdumpglodumpglo defaults set 1994 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1995 1996 1997 1998 1999 2000 2001 2002 idl tadaa glo files produced for 1994 to 2002 then retracked to produce regular 05degree grids for dtr having only produced 25degree binaries for synthetics earlier idl quick_interp_tdm219012002glo_dtr_gridsdtr750gs05pts_prefixdtr_txt_4idldtrdumpglodumpglo that went off without any apparent hitches so i wrote fortran prog maxminmakerfor to produce tmn and tmx grids from tmp and dtr it ran however yup more problems when i checked the inputs and outputs i found that in numerous instances there was value for mean temperature in the grid with corresponding dtr value this led to tmn tmx tmp for thos cells not good actually what was not good was my grasp of context oh curse this poor memory for the idl gridding program produces anomalies not actuals wrote program glo2absfor does fileforfile conversion of glo files as produced by quick_interp_tdm2pro to absolutevalue files also gridded and with headers after some experiments realised that the glo anomalies are in degrees but the normals are in 10ths of degree produced absolutes for tmp then wrote program cmpcrutsfor to compare the absolute grids with the published cru_ts_210 data the comparison simply measures absolute differences between old and new and categorises as either 1 identical 2 within 05 degs 3 within 1 deg 4 over 1 deg apart results for temperature tmp identical 05deg 051deg 1deg 30096176 48594200 2755281 1076423 and for temperature range dtr 45361058 31267870 3893754 1999398 these are very promising the vast majority in both cases are within 05 degrees of the published data however there are still plenty of values more than degree out the total number of comparisons is 6742010212 82522080 it seems prudent to add percentage calculations tmp final diff totals 30096176 48594200 2755281 1076423 percentages 3647 5889 334 130 tmp has comforting 95 within half degree though one still wonders why it isnt 100 spot on dtr final diff totals 45361058 31267870 3893754 1999398 percentages 5497 3789 472 242 dtr fares perhaps even better over half are spoton though about 75 are outside half however its not such good news for precip pre final diff totals 11492331 21163924 9264554 40601271 percentages 1393 2565 1123 4920 21 little experimentation goes short way i tried using the stn option of anomdtbfor not completely sure what its supposed to do but matter as it didnt work crua6crucrutsrerun1datacrutsrerun_pre anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required pre will calculate percentage anomalies select the cts or dtb file to load pre0312031600hdtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 5 select outputs 1cts2ann3txt4stn 4 check for duplicate stns after anomalising 0no0km range 8 select the stn file to save prefromanomdtbstn enter the correlation decay distance 450 submit grim that contains the appropriate grid enter the grim filepath cru_ts_2_1019611970pre grid dimensions and domain size 720 360 67420 select the firstlast years ad to save 19012002 operating normals mean percent stdev percent dtb 2635548 296 cts 4711327 528 7325296 822 process decision percent ofchk latlon 20761 02 02 normal 1585342 178 178 outofrange 20249 02 03 duplicated 317035 36 43 accepted 6972308 782 calculating station coverages withinrange alloc datab forrtl severe 174 sigsegv segmentation fault occurred crua6crucrutsrerun1datacrutsrerun_pre knowing how long it takes to debug this suite the experiment endeth here the option like all the anomdtb options is totally undocumented so well never know what we lost 22 right time to stop pussyfooting around the niceties of tims labyrinthine software suites lets have go at producing cru ts 30 since failing to do that will be the definitive failure of the entire project firstly we need to identify the updated data files i acquired the following iran_asean_ghcn_wwrcd_save50_climat_mcdw_updat_merged renamed to pre0611301502dat newbigfile0606dat renamed to tmp0611301507dat glseries_tmn_final_merged renamed to tmn0611301516dat glseries_tmx_final_merged renamed to tmx0611301516dat anders9106mdat renamed to tmp91060612011708dat and established directory hierarchy under crucrutsversion_3_0 next step convert the various db formats to the cru ts one made visual comparison which indicated that it would work unfortunately it will mean losing the extra fields that have been tacked onto the headers willynilly as they are undocumented furthermore the two extra fields in the cru ts format are undocumented as far as i can see so i wrote headergetterfor to produce stats on the cru ts headers it looks for violations of the mandatory blank spaces and for variations in the two extra fields sample output for temperature and precip header report for tmp0311051552dtb produced by headgetterfor total records read 12155 blanks expected at 81421264761667178 position missed 8 0 14 0 21 0 26 0 47 0 61 0 66 0 71 0 78 2 extra field 1 7277 type detected counted missing value code 12155 possible fp value 0 possible exp value 0 integer value found 0 real value found 0 unidentifiable 0 extra field 2 7986 type detected counted missing value code 709 possible fp value 697 possible exp value 0 integer value found 10749 real value found 0 unidentifiable 0 ends header report for pre0312031600dtb produced by headgetterfor total records read 12732 blanks expected at 81421264761667178 position missed 8 0 14 0 21 0 26 0 47 0 61 0 66 0 71 0 78 154 extra field 1 7277 type detected counted missing value code 12732 possible fp value 0 possible exp value 0 integer value found 0 real value found 0 unidentifiable 0 extra field 2 7986 type detected counted missing value code 3635 possible fp value 437 possible exp value 0 integer value found 8660 real value found 0 unidentifiable 0 ends as can be seen there are unidentifiable headers hurrah but quite few violations of the boundary between the two extra fields particularly in the precip database on examination the culprits are all african stations the two tmp exceptions 641080 330 1735 324 bandundu dem rep congo 1961 1990 99908 642200 436 1525 445 kinshasabinza dem rep congo 1960 1990 99920 and samples of the pre exceptions 656002 698 958 150 suakoko liberia 1951 1970 999123008050 655327 727 723 350 kouibly ivory coast 1977 1990 999109001290 655001 1320 235 332 gourcy burkina faso 1956 1980 999120001240 618504 788 1118 999 kenemafarm sierra leone 1951 1972 999139003500 612067 1407 307 253 koro mali 1958 1989 999127002650 so the first extra field is apparently unused it would be handy place for the 6character datacode and validstartyear from the temperature db on to more detailed look at the cru precip format not sure whether there are two extra fields or one and what the sizes are quick hack through the headers is not pleasing there appears to be only one field but it can have up to nine 9 digits in it and at least three missing value codes 67853001863 2700 1080hwangenpa zimbabwe 19621996 40 8100100 680 5820 2georgetown guyana 18462006 99 6274000 1420 2460 1160kutum sudan 19291990 194 6109200999999999 999unknown niger 19891989 999 6542000 945 2 197yendi ghana 19071997 8010 6544200 672 160 293kumasi ghana 19062006 17009 6122306 1670 299 267kabara mali 19231989 270022 6193128 32 672 999sao tome sao tome 19391973 8888888 6266000 1850 3180 249karima sudan 19172006 18315801 6109905 1208 367 315ouarkoye burkina faso 19601980 120002470 unimpressed this is irritating as it means precip has only 9 fields and i cant do generic mapping from any cru format to cru ts as glutton for punishment i then looked at the tmintmax db format looks like two extra fields i6i7 with mvcs of 999999 and 8888888 respectively however sigh inspection reveals the following two possibilities 851300 3775 2568 17ponta delgada portugal 18652004 9999998888888 851500 3697 2517 100santa maria acores 19542006 77777 8888888 isnt that marvellous these cant even be read with consistent header format so the approach will be to read exactly one extra field for cru tmp that will be the i2i4 andersbeststart codes as one for cru pre it will be the amazing multipurpose multilength field for cru tmnx it will be the first field which is at least stable at i6 conversionscorrections performed temperature converted tmp0611301507dat to tmp0612081033dat found one corrupted station name before 911900 209 1564 20 hikahului wso puu nene 1954 1990 101954 99900 after 911900 209 1564 20 kahului arptmaui hawaii 1954 1990 101954 99900 precipitation converted pre0611301502dat to pre0612081045dat found one corrupted station name before 4125600 2358 5828 15seeb apmuscat09oman 18932006 301965 after 4125600 2358 5828 15 seeb intlmuscat oman 1893 2006 999 99900 dl later reported that the name wasintended to signify that the data had been corrected by factor of 09 when data from another station was incorporated to extend the series this was mike hulmes work write db2dtbfor which converts any of the cru db formats to the cru ts format started work on mergedbfor which should merge primary database with and incoming database of the same cru ts format quite complicated operator interventions just log file of failed attempts but hooks left in for op sections in case this turns out to be the main programmatic deliverable to badc 23 interrupted work on mergedbfor in order to trial precip gridding for 30 this required another new proglet addnormlinefor which adds normals line below each header it fills in the normals values if the condisions are met 75 of values or 23 for the 30 year period initial results promising ran it for precip it added normals lines ok total of 15942 with 6003 missing value lines errors and ops interventions because the file didnt have normals lines before final precip file pre0612151458dtb tried running anomdtbf90 failed because it couldnt find the dts file matter that it doesnt need it argh examined existing dts files not sure what theyre for headers are identical to the dtb file all missing values are retained all other values are replaced with one of several code numbers idea what they mean wrote falsedtsfor to produce dummy dts files with all zeros in place of real data values produced pre0612151458dts added normals line producing pre0612181221dtb reproduced matching pre0612181221dts file tried running anomdtbf90 again this time it crashed at record 1096 wrote proglet findstnfor to find the nth station in dtb file pulled out 1096 0 486 10080 1036 bukit larut malaysia 1951 1988 999 99900 6190 2094 2015 2874 3800 4619 3032 5604 3718 4626 5820 5035 3049 1951 3330 2530 2790 5660 4420 4030 1700 2640 8000 5950 6250 2020 snipped normal years 1979 110 1920 1150 5490 3140 308067100 2500 4860 4280 4960 1600 uhoh thats 67m of rain in july 1979 looks like factorof10 problem confirmed with dl and changed to 6710 next run crashed at 4391 cherrapunji the wettest place in the world so here the high values are realistic however i did notice that the missing value code was 10 instead of 9999 so modified db2dtbfor to fix that and reproduced the precip database as pre0612181214dat this then had to have normals recalculated for it after fixing 1096 finally got it through anomdtbfor and quick_interp_tdm2 without crashing idl was even on the ball with the missing months at the end of 2006 idl quick_interp_tdm219012006preglopregrid450gs05dumpglodumpglopts_prefixpreanomspre compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1902 1903 etc 2005 2006 stations found in preanomspre200609txt stations found in preanomspre200610txt stations found in preanomspre200611txt stations found in preanomspre200612txt all good wrote mergegridsfor to create the morefamiliar decadal and fullseries files from the monthly gloabs ones then like an idiot i had to test the data duh firstly wrote mmeangridfor and cmpmgridsm to get visual comparison of old and new precip grids old being cru ts 210 this showed variations in expected areas where changes had been made it the southern tip of greenland next phil requested some statistical plots of percentage change in annual totals and longterm trends wrote anntotsfor to convert monthly gridded files into yearly totals files then tried to write precipcheckerm to do the rest in matlab it wasnt having it out of memory bah so wrote prestatsfor to calculate the final stats for printing with an emasculated precipcheckerm but it wouldnt work and on investigating i found 200odd stations with zero precipitation for the entire 19012006 period modified anntotsfor to dump single grid with those cells that remained at zero marked then plotted zero cells in north africa and the western coast of south america none in the cru ts 210 precip grids next step produce list of cell centres of the offending cells wrote quick proglet idzerocellsfor then getcellstationsfor which given cruts db file and list of latlon values extracts all stations lying inside the cells listed uhoh looked in the new pre db and found 15 stations for 257 zero cells they are 6061170 2810 670 381 ft flatters algeria 1925 1965 999 99900 6064000 2650 840 559 fort polignac algeria 1925 2006 999 99900 6262000 2080 3260 470 station 6 sudan 1950 1988 999 99900 8450100 810 7900 26 trujillo peru 1961 2006 999 99900 8453100 920 7850 10 chimbote peru 1961 2006 999 99900 8462800 1200 7710 13 limacallaointlap peru 1961 2006 999 99900 8463100 1210 7700 137 limatambocde marte peru 1927 1980 999 99900 8469100 1380 7630 6 pisco peru 1942 2006 999 99900 8540600 1850 7030 29 aricachacalluta chile 1903 2006 999 99900 8541700 2020 7020 6 iquiquecavancha chile 1886 1986 999 99900 8541800 2053 7018 52 iquique diego aracen chile 1989 2006 999 99900 8700494 707 7957 150 cayalti peru 1934 1959 999 99900 8700562 1203 7703 137 lima peru 1929 1963 999 99900 8700581 1207 7717 13 punta na peru 1939 1963 999 99900 9932040 2810 670 381 ft flatter algeria 1925 1965 999 99900 looked for the same zero cell stations in the old pre db pre0312031600dtb and only found 10 854031 2021 7015 5 iquiquecavancha chile 1899 1986 999 000 843002 1210 7700 135 limatambo peru 1927 1980 999 603550 2810 670 381 ft flatter algeria 1925 1965 999 99900 606400 2650 841 558 illiziillirane algeria 1925 2002 999 999 626200 2075 3255 468 station 6 sudan 1950 1988 999 99900 845010 810 7903 30 trujillomartinez peru 1961 2002 999 999 845310 916 7851 11 chimboteteniente peru 1961 2001 999 846280 1200 7711 13 limajorge chavez peru 1961 2002 999 999 846910 1375 7628 7 pisco civmil peru 1942 2002 999 999 854180 2053 7018 52 iquiquediego arac chile 1989 2002 999 99900 so why does the old db result in zero cells and the new db give us over 250 i wondered if normals might be the answer but none of the 10 stations from the old db have indb normals wheras three of the new db have 8453100 920 7850 10 chimbote peru 1961 2006 999 99900 6190 19 59 36 18 5 0 3 0 0 1 10 5 8469100 1380 7630 6 pisco peru 1942 2006 999 99900 6190 3 0 3 0 0 1 1 3 1 4 0 0 8540600 1850 7030 29 aricachacalluta chile 1903 2006 999 99900 6190 1 3 0 0 0 2 2 2 2 0 0 0 so these alone ought to guarantee three of the cells being nonzero they should have the bloody normals in so the next check has to be the climatology that which provides the cellbycell normals check of the gridded climatology revealed that all 257 zero cells have their climatologies set to zero too this was partially checked in the grimformat climatology just in case next focus on chimbote see header line above this has real data not just zeros it is in cell 162203 or 9257875 lat lon in both cases so we extract the full timeseries for that cell from the published 210 19012002 grim file gridref 203 162 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 0 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 7 0 3 2 0 0 0 2 0 0 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 0 0 0 5 0 3 2 0 0 0 2 0 2 0 0 5 0 3 2 0 0 0 2 0 0 0 0 5 0 3 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 2 5 6 0 0 0 0 3 2 3 0 0 0 0 17 0 0 4 0 3 2 0 0 0 3 0 2 0 0 2 0 3 0 0 0 0 0 0 14 0 0 9 0 0 0 0 0 0 0 0 0 0 0 2 0 2 0 0 0 0 0 0 12 0 0 0 0 5 0 0 0 0 0 0 0 0 0 3 0 2 0 0 0 0 0 0 10 0 0 0 0 2 0 0 0 0 3 0 11 0 0 2 0 3 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 4 0 0 3 0 0 0 0 0 15 0 0 0 0 2 0 0 0 0 0 0 0 0 0 4 3 2 5 0 0 0 0 0 0 0 0 12 0 3 0 0 2 2 4 2 0 0 2 3 0 3 0 0 0 0 3 0 0 2 0 2 2 3 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 3 0 0 0 0 0 0 0 0 2 3 0 0 0 4 0 0 12 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 2 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 7 0 0 0 2 0 0 0 3 2 0 7 0 0 2 0 0 2 0 0 0 0 0 0 7 0 0 2 2 2 0 0 0 8 0 2 0 0 0 0 2 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 10 0 3 0 0 0 0 0 9 0 0 0 0 3 0 0 0 0 0 0 0 0 0 3 0 5 4 0 0 2 10 2 0 0 0 0 0 4 0 0 0 0 0 0 0 0 2 5 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 8 2 0 0 0 0 0 3 0 0 2 0 2 0 0 0 0 0 2 3 0 0 0 0 2 0 2 0 0 5 0 2 0 0 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 2 0 0 2 0 0 0 0 2 0 2 0 0 0 0 0 0 5 0 0 0 0 0 0 11 0 2 0 0 4 0 3 2 3 2 0 13 0 0 0 0 0 0 0 2 6 0 3 0 0 0 0 2 3 0 7 2 0 0 0 2 0 0 0 0 0 0 3 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 3 yet in the 300 version its all zeros only one thing for it examine the attempt at regenerating 210 unfortunately well interestingly then this gave the same zero cells as the 300 generation so its something to do with the process not the database or the climatology assuming that has remained constant which i gather it has update aha phil pointed out that for precip the climatology is used as multiplier so if the clim hasnt changed the cells should always have been zero regardless of actual data as i should have remembered crua6crucrutsversion_3_0primariesprecip glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanpre enter name for the gridded climatology file clim6190lanpregrid enter the path and stem of the glo files preglopregrid enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files pregrid now concentrate addition or percentage ap p right erm off i jolly well go pregrid011901glo pregrid021901glo etc decided to read mitchell jones 2005 again noticed that the limit for sd when anomalising should be 4 for precip not 3 so reran with that crua6crucrutsversion_3_0primariesprecip anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required pre will calculate percentage anomalies select the cts or dtb file to load pre0612181221dtb pre0612181221dtb tmp_mntcruautocrutsversion_3_0primariesprecippre0612181221dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 4 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 8 select the generic txt file to save yymmauto pre4sdtxt select the firstlast years ad to save 19012006 operating tmp_mntcruautocrutsversion_3_0primariesprecippre0612181221dtb tmp_mntcruautocrutsversion_3_0primariesprecippre0612181221dtb tmp_mntcruautocrutsversion_3_0primariesprecippre0612181221dts tmp_mntcruautocrutsversion_3_0primariesprecippre0612181221dts normals mean percent stdev percent dtb 7315040 738 made it to here cts 299359 30 7613600 768 process decision percent ofchk latlon 17527 02 02 normal 2355659 238 238 outofrange 13253 01 02 duplicated 586206 59 78 accepted 6934807 700 dumping years 19012006 to txt files this is not as good percentage as for 210 normals mean percent stdev percent dtb 0 00 cts 3375441 841 3375441 841 process decision percent ofchk latlon 3088 01 01 normal 638538 159 159 outofrange 70225 17 21 duplicated 135457 34 41 accepted 3167636 789 dumping years 19012002 to txt files but the actual number of accepted values is more than twice 210 of course the same 257 gridcells are zeros because the multiplicative normals are still zero for reference these are the results for the 3 sd limit of 300 normals mean percent stdev percent dtb 7315040 738 made it to here cts 284160 29 7598401 767 process decision percent ofchk latlon 17527 02 02 normal 2370858 239 240 outofrange 32379 03 04 duplicated 583193 59 78 accepted 6903495 697 dumping years 19012006 to txt files so weve only gained 03 of values real figure of 31312 values conclusion stick with 3 standard deviation limit like the read_me says 24 cont of 22 really restarted work on mergedbfor decided i was taking the wrong approach so the interruption was probably good thing the process now is to read in the header lines and line numbers from the main database and to then process the incoming database one record at time its more logical and haivng the line numbers will speed things up enormously well it has done on previous occasions the biggest immediate problem was the loss of an hours edits to the program when the network died explanations from anyone i hope its not return to last years troubles some weeks later well it compiles ok and even runs enthusiastically however there are loads of bugs that i now have to fix eeeeek timesrunningouttimesrunningout even later getting there still ironing out glitches and poor programming 25 wahey its halfway through april and im still working on it this surely is the worst project ive ever attempted eeeek i think the main problem is the rather nebulous concept of the automatic updater if i hadnt had to write it to add the 19912006 temperature file to the main one it would probably have been lot simpler but that one operation has proved so costly in terms of time etc that the program has had to bend over backwards to accommodate it so yes in retrospect it was not brilliant idea to try and kill two birds with one stone i should have realised that one of the birds was actually pterodactyl with temper problem success crua6crucrutsversion_3_0dbtestmergedb mergedb mergedb merging of two database files ops id f098xxxx date 1217 250407 the session id is 0704251217f098xxxx log file mergedb0704251217f098xxxxlog please choose the mode of working this program can either run 1 interactively in which case an operator must be present throughout to make decision or 2 in batch mode in which case it may be left unattended if batch mode is used file of outstanding issues will be saved for later 3 resolution by an operator 1 interactive operator processing 2 batch operator processing 3 operator processing of saved batch 4 run previouslysaved action file please enter 123 or 4 4 run action file mode enter the action filename or x for list x the 1 most recent act files 1 mergedb0704201343f098xxxxact enter number or 0 for none of the above 1 enter to run this file or n to abort creation datetime 1343 200407 batch initiator was f098 number of actionsrequests 2586 this act file derived from original ops file mergedb0704201210f098xxxxops main existing database tmp0702091122dtb secondary incoming database tmp0612081519dat parameter is tmp confirm yn actions completed thank you for using mergedb well success in the sense that it ran and apparently all the datas in the right place in tmp0704251819dtb 26 ok now to merge in the us stations first wrote us2cru to convert the marksusanonwmocrudat file to the standard format were using that worked ok then used addnormline to well add normals line only 17 out of 1035 stations ended up with missing normals which is pretty good the withnormals us database file is tmp0704251654dat now i knew that using mergedb as it stands would not work it expects to be updating the existing records and actions like addnew require ops to confirm each one so i thought it best to add an ops clause to auto confirm additions where theres wmo match and the data density is ok say 50 or higher unfortunately that didnt work either and rather than spend even more time debugging mergedbfor i knocked off simpleaddnewfor which adds two nonoverlapping databases the resultant file with all three partial databases is tmp0704271015dtb 27 well enough excuses time to remember how to do the anomalising and gridding things fisrtly ran addnormline just to ensure all normals are up to date the result was 8 new sets of normals so well worth doing the database is now tmp0704292158dtb ran anomdtb got caught out by the requirement for companion dts file again ran falsedtsfor and carried on would still be nice to be sure that its not something meaningful sigh output begin quote crua6crucrutsversion_3_0primariestemp anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required tmp select the cts or dtb file to load tmp0704292158dtb tmp0704292158dtb tmp_mntcruautocrutsversion_3_0primariestemptmp0704292158dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 8 select the generic txt file to save yymmauto tmptxt select the firstlast years ad to save 19012006 operating tmp_mntcruautocrutsversion_3_0primariestemptmp0704292158dtb tmp_mntcruautocrutsversion_3_0primariestemptmp0704292158dtb tmp_mntcruautocrutsversion_3_0primariestemptmp0704292158dts tmp_mntcruautocrutsversion_3_0primariestemptmp0704292158dts failed to find file enter the file with suffix dts tmp0704292158dts tmp0704292158dts tmp_mntcruautocrutsversion_3_0primariestemptmp0704292158dts normals mean percent stdev percent dtb 3330007 813 made it to here cts 92803 23 3422810 836 process decision percent ofchk latlon 0 00 00 normal 671592 164 164 outofrange 744 00 00 duplicated 4102723 1002 1199 accepted 680657 166 dumping years 19012006 to txt files crua6crucrutsversion_3_0primariestemp end quote which is trifle worrying and looking at the txt files they look rather odd as well for instance tmp195303txt starts like this 709 087 100 010000 10010 783 155 280 480000 10080 697 189 100 090000 999 697 189 1000 050000 10260 745 190 160 310000 10280 695 255 1290 370000 10650 704 311 140 000000 10980 660 020 00 120000 11000 673 144 130 160000 999 668 140 390 220000 11530 now do those first two columns look like lat lon to you neither heres what the old version of the same file looks like 6000 2000 9990 040000990007 6200 3300 9990 040000990002 5650 5100 00 050000990000 690 12206 60 060000 999 1313 12373 170 020000 999 1452 12100 150 060000 999 1837 12163 40 110000 999 690 12200 60 060000 999 1070 12250 140 010000 999 1313 12373 190 010000 999 in fact the first two columns never get outside of 30 oh bugger what the hell is going on decided to pursue that worrying and impossible duplicates figure the function sort was used to sort the database so that any duplicate lines would be together then uniq was used to pull out duplicates there were quite few dupes and one or two triples too like these crua6crucrutsversion_3_0primariestemp grep n 1984 83 46 22 55 126 154 222 215 159 63 32 62 tmp0704292158dtb 1957891984 83 46 22 55 126 154 222 215 159 63 32 62 2542651984 83 46 22 55 126 154 222 215 159 63 32 62 2543801984 83 46 22 55 126 154 222 215 159 63 32 62 these are from the following stations 720344 408 1158 1539 elkofaaapusa 1870 1996 301870 99900 725837 408 1158 1549 nv elko faa ap 1930 1990 101930 99900 725910 401 1223 103 red bluff usa 1878 2006 101878 99900 the past two are consecutive stations looking at the last two it seems that 725910 has 725837s data 1977 71 124 118 184 167 275 283 280 230 190 126 99 1978 107 114 149 144 208 248 289 282 232 220 118 72 1979 85 99 139 150 218 256 282 258 253 189 117 94 1980 99 121 119 156 192 216 275 262 241 196 128 102 1981 14 19 49 90 123 196 233 227 164 71 47 11 1982 49 14 32 57 114 164 206 214 148 74 11 23 1983 9 1 54 59 114 167 204 223 170 104 25 19 1984 83 46 22 55 126 154 222 215 159 63 32 62 ascan be seen 1981 sees complete chance in range especially for autumnwinter in fact from 1981 to 1990 725910 is copy of 725837 it then reverts to the original range for the rest of the run so did the merging program do this unfortunately yes check dates crua6crucrutsversion_3_0dbtestmergedb grep n red bluff tmp0 tmp0612081519dat28595 725910 401 1223 103 red bluff usa 1991 2006 101991 99900 tmp0702091122dtb171674 725910 401 1223 103 red bluff usa 1878 1980 101878 99900 tmp0704251819dtb200331 725910 401 1223 103 red bluff usa 1878 2006 101878 99900 tmp0704271015dtb254272 725910 401 1223 103 red bluff usa 1878 2006 101878 99900 tmp0704292158dtb254272 725910 401 1223 103 red bluff usa 1878 2006 101878 99900 crua6crucrutsversion_3_0dbtestmergedb the first file is the 19912006 update file the second is the original temperature database note that the station ends in 1980 it has inherited data from the previous station where it had 9999 before i thought id fixed that goes off muttering to fix mergedbfor for the five hundredth time miraculously despite being dogtired at nearly midnight on sunday i did find the problem i was clearing the data array but not close enough to the action when stations were being passed through ie data to add to them they were not being cleaned off the array afterwards meh wrote specific routine to clear halves of the data array and back to square one reran the act file to merge the x1990 and 19912006 files created an output file exactly the same size as the last time phew but with crua6crucrutsversion_3_0dbtestmergedb comm 12 tmp0704292355dtb tmp0704251819dtb wc l 285516 crua6crucrutsversion_3_0dbtestmergedb wc l tmp0704292355dtb 285829 tmp0704292355dtb 313 lines different typically 1488114886c1488114886 1965999999999999999999999999999999999999999999999999 1966999999999999999999999999999999999999999999999999 1967999999999999999999999999999999999999999999999999 1968999999999999999999999999999999999999999999999999 1969999999999999999999999999999999999999999999999999 1970999999999999999999999999999999999999999999999999 1965 221 177 234 182 5 6 24 36 15 91 100 221 1966 272 194 248 192 66 10 27 45 12 75 139 228 1967 201 243 196 158 26 1 40 30 18 89 183 172 1968 253 256 253 107 42 10 46 33 21 64 134 195 1969 177 202 248 165 33 8 42 50 1 89 157 204 1970 237 192 217 160 87 6 30 25 5 55 143 222 ie what should have been missing data is now missing data again 200436200445c200436200445 1981999999999999999999999999999999999999999999999999 1982999999999999999999999999999999999999999999999999 1983999999999999999999999999999999999999999999999999 1984999999999999999999999999999999999999999999999999 1985999999999999999999999999999999999999999999999999 1986999999999999999999999999999999999999999999999999 1987999999999999999999999999999999999999999999999999 1988999999999999999999999999999999999999999999999999 1989999999999999999999999999999999999999999999999999 1990999999999999999999999999999999999999999999999999 1981 14 19 49 90 123 196 233 227 164 71 47 11 1982 49 14 32 57 114 164 206 214 148 74 11 23 1983 9 1 54 59 114 167 204 223 170 104 25 19 1984 83 46 22 55 126 154 222 215 159 63 32 62 1985 57 29 17 89 122 181 244 188 121 79 11 50 1986 2 31 66 72 113 187 194 214 116 78 11 39 1987 59 5 30 97 131 177 193 192 153 101 21 35 1988 65 15 29 80 108 184 222 198 138 116 8 57 1989 113 54 53 94 113 164 215 186 143 78 8 24 1990 24 30 49 100 100 166 214 194 177 77 9 97 hurrah so the interim database file is tmp0704292355dtb now to readd the us station dataset with simpleaddnewfor crua6crucrutsversion_3_0dbtestmergedb simpleaddnew simplyaddnew add stations to database this program assumes the two databases have common stations and will fail stop if any are found please enter the main database tmp0704292355dtb please enter the new database tmp0704251654dat please enter 3character parameter code tmp output database is tmp0704300053dtb crua6crucrutsversion_3_0dbtestmergedb so now we have the combined database again bit quicker than last time tmp0704300053dtb pity we slid into may i was hoping to only be five months late whats worse there are still duplicate nonmissing lines 210 of them the first example is this 1835 92 73 141 187 260 279 281 288 241 195 183 106 which belongs to this in the original database tmp0702091122dtb 722080 329 800 15 charleston s carol united states 1823 1990 101823 99900 6190 84 100 142 180 224 257 274 270 245 191 145 104 and to this in the us database tmp0704251654dat 720467 328 799 3 charlestoncityusa 1835 1996 301835 99900 6190 91 106 144 186 227 260 277 272 249 199 154 112 these two stations obviously have lot in common though not everything as their normals shown differ in fact on examination the us database record is poor copy of the main database one it has more missing data and so forth by 1870 they have diverged so in this case its probably ok but what about the others i just do not have the time to follow up everything well have to take 210 year repetitions as one of those things actually i decided in the end to follow up all 210 of them the likelihood is that the number is far greater since the filtering that gave the 210 figure excluded any lines with two or more consecutive missing values to avoid hundreds of justmissingvalue lines also i spotted some instances where data lines would be identical but for one or more missing values in one of the stations after checking i found that the majority of the duplications were between the original database and the us database with just couple of linked stations within the original database and half dozen in the 19912006 update file one surprise was that stations im sure i rejected ended up marked as addnew in the act file quite unsettling rather foolishly perhaps i decided to have go at interactively incorporating the us data rather than using simplyaddnew however progress was so slow because of the high number of near matches that this approach was abandoned tried anomdtb with the fixed final file tmp0704300053dtb better the crucial bits begin quote normals mean percent stdev percent dtb 3323823 813 made it to here cts 91963 22 3415786 835 process decision percent ofchk latlon 0 00 00 normal 675037 165 165 outofrange 744 00 00 duplicated 4100117 1002 1201 accepted 685075 167 dumping years 19012006 to txt files failed to create file try again enter the file with suffix ann tmpann failed to create file try again enter the file with suffix ann hann crua6crucrutsversion_3_0primariestemp end quote so the duplicated figure is slightly lower but whats this error with the ann file never seen before oh god if i could start this project again and actually argue the case for junking the inherited program suite ok the ann file was simply that it refuses to overwrite any existing one meh its happy to overwrite the log file of course nice bit of logic there and the duplicates well i inserted debug line where the decision is made heres an example 712600 vs 727340 47 84 47 84 00km here the two wmo codes look ok though others are 999 which seems unlikely but the two latlon pairs ooops here are the actual headers 712600 465 845 187 sault ste marie canada 1945 2006 361945 99900 727340 465 844 220 saultstemarie usa 1888 2006 101888 99900 so uhhhh what in tarnation is going on just how offbeam are these datasets not sure why the lats lons are factor of 10 too low may be intentional though it wasnt happening before ran with the original database begin quote normals mean percent stdev percent dtb 2113609 817 made it to here cts 0 00 2113608 817 process decision percent ofchk latlon 0 00 00 normal 474422 183 183 outofrange 68179 26 32 duplicated 923258 357 451 accepted 1122172 434 dumping years 19011990 to txt files end quote the lats lons look the same but lot less duplicates why well it could just be those pesky us stations so why not compare the two bespoke log files as excerpted above immediately another baffler the log file from the run of the final database has lots of debug detail information but the log file from the run of the original database does not so cropping those away with judicious tail i ran comm crua6crucrutsversion_3_0primariestemp comm 23 log_anomdtb_h0702091122dat barelog_anomdtb_h0704300053dat wc l 200 crua6crucrutsversion_3_0primariestemp comm 13 log_anomdtb_h0702091122dat barelog_anomdtb_h0704300053dat wc l 2572 crua6crucrutsversion_3_0primariestemp comm 12 log_anomdtb_h0702091122dat barelog_anomdtb_h0704300053dat wc l 1809 so 200 duplication events are unique to the older database and 2572 are unique to the new database with 1809 common to both quick look at the 2572 new ones showed majority of those with the first wmo as 999 this is the key the databases do not have any records with wmo999 as far as i know so something is going on 28 with huge reluctance i have dived into anomdtb and already i have that familiar twilight zone sensation i have found that the wmo code gets set to 999 if both lon and lat are missing however the following points are relevant loadcts multiplies nonmissing lons by 01 so they range from 18 to 18 with missing value codes passing through as long as they are 9999 if they are 999 they will be processed and become 999 it is not clear why lats are not treated in the same way the subroutine anomalise in anomdtb checks lon and lat against simple missval which is defined as 999 this will catch lats of 999 but not lons of 9999 this does still not explain how we get so many 999 codes unless we dont and its just one or two and the real baffler if the code is 999 because lat and lon are both missing how the bloody hell does it know theres duplication within 8km ah ok well for start the last point above does not apply not one case of the code being set to 999 because of latlon missing in fact i hate to admit it bit it is sort of clever the code is set to 999 to prevent it being used again because the distanceduplication checker will not make distance comparison if either code is 999 so how come loads of the duplicates have code of 999 the plot thickens i changed the exclusion tests in the duplication loops from if astnxastnnemissval then to if intastnxastnne999 then this made difference so having tested to ensure that the first of the pair hasnt already been used we then use it whats more ive noticed that its usually the one incorporated in the previous iteration consider 67700 vs 160660 46 09 46 09 54km 999 vs 160707 46 09 46 09 22km 999 vs 160800 46 09 45 09 73km 999 vs 160811 46 09 46 09 58km here we can see check the first set of latlons that after being incorporated into 160660 67700 goes on to also be incorporated into 160707 160800 and 160811 so the same data could end up in three other stations it gets worse because later on we find 160660 vs 160707 46 09 46 09 79km 999 vs 160800 46 09 45 09 70km 999 vs 160811 46 09 46 09 58km 160707 vs 160800 46 09 45 09 79km 999 vs 160811 46 09 46 09 66km 160800 vs 160811 45 09 46 09 22km so three of those recipients have gone on to be incorporated into one of them 160811 but although in this case 67700 is within 8km of 160811 there is guarantee indeed with this system the chosen station may hop all over the place in 8km steps collecting data as it goes in denselypacked area this could drastically reduce the number of stations then theres these 85997 vs 390000 100 200 100 200 00km 999 vs 685807 100 200 100 200 00km 999 vs 688607 100 200 100 200 00km 999 vs 967811 100 200 100 200 00km 999 vs 968531 100 200 100 200 00km as might be guessed they all end up incorporated into 968531 but surprise seeing as their lats lons are rubbish oh tim what have you done man actually what hes done is to let missing lats lons through missing lon code is 1999 not 9999 so these figures are the roundings all that said the biggest worry is still the lats lons themselves they just dont look realistic lats appear to have been reduced by factor of 10 too even though i cant find the code for that and from the top example is 67700 really 54km from 160660 67700 460 90 273 lugano switzerland 1864 2006 101864 99900 160660 456 87 999 milano malpensa italy 1961 1970 101961 99900 of course not its just over 50km i do not understand why the lats lons have been scaled when the stated distance threshold has not at least ive found where they are scaled in loadcts crutsfilesf90 if stninfoxstn2nelatmissval lat xstn realstninfoxstn2 reallatfactor if stninfoxstn3nelonmissval lon xstn realstninfoxstn3 reallonfactor looking at how loadcts is called from anomdtb subroutine loadcts stninfostnlocalstnnamestnctycodelatlonelvoldcodedatayearad nmldatadtbnormalscallfilehulmelegacyheadonlyheadformlongtypesilentextraphilj yearadminyearadmaxsourcesrccodesrcsuffixsrcdate latmvlonmvelvmvdatamvlatflonfelvfnmlyr0nmlyr1nmlsrcnmlinc call loadcts stninfoastnlocalastnnameastnctyacodeastnoldcodeastnold latalatlonalonelvaelvdtbnormalsdtbnormalsa datadataayearadayearadcallfileloadfileasilent1 get dtb file we see that legacy is not passed this means that from loadcts latfactor100 lonfactor100 elvfactor1 usualhulme hdr factors if presentlegacy then latfactor10 lonfactor10 elvfactor1 legacy hdr factors end if if presentlatf latfactor latf custom hdr factors if presentlonf lonfactor lonf if presentelvf elvfactor elvf latfactor and lonfactor are set to 100 so i added specific pair of arguments latf10lonf10 and got normals mean percent stdev percent dtb 3323823 813 made it to here cts 91963 22 3415786 835 process decision percent ofchk latlon 0 00 00 normal 675037 165 165 outofrange 744 00 00 duplicated 53553 13 16 accepted 3361489 822 dumping years 19012006 to txt files hurrah looking at the log it is still ignoring the 999 code and reintgrating stations but not to any extent worth worrying about not when duplications are down to 13 then got mail from pj to say we shouldnt be excluding stations inside 8km anyway yet thats in ijc mitchell jones 2005 so there you go ran again with 0km as the distance normals mean percent stdev percent dtb 3323823 813 made it to here cts 91963 22 3415786 835 process decision percent ofchk latlon 0 00 00 normal 675037 165 165 outofrange 744 00 00 accepted 3415042 835 dumping years 19012006 to txt files which hasnt saved much as it turns out in fact i must conclude that an inquiring mind is very dangerous thing i decided to see what difference it made turning off the proximity duplicate detection and elimination crua6crucrutsversion_3_0primariestemp wc l 196212txt 2773 oldtxtold196212txt 3269 tmptxt0kmtmp196212txt 3308 tmptxt8kmtmp196212txt so oldtxt is before i fixed the latlon scaling problem but look at the last two i got more results when i used an elimination radius whaaaaaaaaat goes home in huff gets out of huff and goes into house checks things and thinks hard okay i guess if we dont do the rollduplicatestogether thing then we could lose data because the rolled station ie the one subsumed into its neighbour might have useful years but normals so that data would be lost 29 i suddenly thought what about the australian data but luckily thats just tmaxtmin so i can roll that into the next database work 30 being an idiot much experience i decided to go back to the perfectlygood precip generation for v30 and redo the anomalies with the new anomdtb at 8km we got the duplicates down from 59 to 21 old anomdtb with latlon probs normals mean percent stdev percent dtb 7315040 738 made it to here cts 299359 30 7613600 768 process decision percent ofchk latlon 17527 02 02 normal 2355659 238 238 outofrange 13253 01 02 duplicated 586206 59 78 accepted 6934807 700 dumping years 19012006 to txt files new anomdtb with latlon fixed normals mean percent stdev percent dtb 7315040 738 made it to here cts 299359 30 7613600 768 process decision percent ofchk latlon 17527 02 02 normal 2355659 238 238 outofrange 13253 01 02 duplicated 207391 21 28 accepted 7313622 738 dumping years 19012006 to txt files and of course all in with 0km range normals mean percent stdev percent dtb 7315040 738 made it to here cts 299359 30 7613600 768 process decision percent ofchk latlon 17527 02 02 normal 2355659 238 238 outofrange 13253 01 02 accepted 7521013 759 dumping years 19012006 to txt files happy well because something is happening for precip that does not happen for temp but of course here are the first few lines from various 196212 text files tmptxt8kmtmp196212txt 7090 870 100 210000 10010 7830 1550 280 330000 10080 6970 1890 100 140000 999 6970 1890 1000 150000 10260 7450 1900 160 120000 10280 6950 2550 1290 310000 10650 7040 3110 140 020000 10980 6600 200 00 050000 11000 6730 1440 130 100000 11520 6680 1400 390 070000 11530 tmptxt0kmtmp196212txt 7090 870 100 210000 10010 7830 1550 280 330000 10080 6970 1890 100 140000 10250 6970 1890 1000 150000 10260 7450 1900 160 120000 10280 6950 2550 1290 310000 10650 7040 3110 140 020000 10980 6600 200 00 050000 11000 6730 1440 130 100000 11520 6680 1400 390 070000 11530 preanomspre196212txt old anomdtb output 6100 1060 1900 4820000511900 5445 607 1160 370000 999 5083 455 150 2240000389870 5022 530 760 3970000 999 5063 345 90 2810000388730 5143 267 510 3690000 999 5105 360 3140 2780000386030 5172 277 2450 3770000385850 5162 397 100 4610000384130 5235 382 3010 440000380860 pretxt8kmpre196212txt 61000 10600 1900 4820000511900 54450 6070 1160 370000392380 50830 4550 150 2240000389870 50220 5300 760 3970000389280 50630 3450 90 2810000388730 51430 2670 510 3690000386780 51050 3600 3140 2780000386030 51720 2770 2450 3770000385850 51620 3970 100 4610000384130 52350 3820 3010 440000380860 pretxt0kmpre196212txt 61000 10600 1900 4820000511900 54450 6070 1160 370000392380 50830 4550 150 2240000389870 50220 5300 760 3970000389280 50630 3450 90 2810000388730 51430 2670 510 3690000386780 51050 3600 3140 2780000386030 51720 2770 2450 3770000385850 51620 3970 100 4610000384130 52350 3820 3010 440000380860 as result of fixing the lats and lons for temperature and indeed precip it seems we have buggered up the outputs obviously the correction factor is expecting 100 not 10 but why isnt this problem for temperature went back and ran exactly the same version of anomdtb on temperature exactly the same as last time 2nd from top above so it is precip specific or erm nottemp specific on the other hand weve fixed the 999 wmo codes and actually those anomalies had better be percentage anomalies checks few yes they are so oookay loadcts reports the divisor is still 10 for lonlat so the stored values for the first station 511900 biri should be 61 and 106 sounds about right for norway the bit in anomdtb actually the subroutine dumping lol that writes the txt files just writes directly from the arrays so they must have been modified somewhere in anomalise theres nothing else in dumping modified anomdtb to dump the first stations lat lon at key stages they were too high throughout so loadcts assumed to be the troublemaker modified loadcts in the same way and it was holding them at x100 from their true values ie 610 6100 it was about now that i spotted something id not thought to examine before precip headers use two decimal places for their coordinates temperature header 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 precipitation header 100100 7093 867 10 jan mayen norway 1921 2006 999 99900 so this begs the question how does the software suite know which its got by rights it should look at the most extreme values for each something tells thats not the case decided to look at the ranges of values for different versions of the databases starting with temperature crua6crucruts head 1 fromdpe1adatacrutsdatabasenormtmp0311051552dtb 990017 9999 99999 999 unknown marine 1948 1990 999 99900 crua6crucruts head 1 fromdpe1adatacrutsdatabasenorm_oldtmp0310311715dtb 176000 3520 3330 220 nicosia cyprus 1932 1974 999 nocode crua6crucruts head 1 rerun1datacrutsrerun_tmptmp0311051552dtb 990017 9999 99999 999 unknown marine 1948 1990 999 99900 crua6crucruts head 1 rerun1datacrutsrerun_tmptmp0311051552ndtb 990017 9999 99999 999 unknown marine 1948 1990 999 99900 crua6crucruts head 1 rerun1datacrutsrerun_tmpdatabasenorm_oldtmp0310311715dtb 176000 3520 3330 220 nicosia cyprus 1932 1974 999 nocode crua6crucruts head 1 rerun1datacrutsrerun_tmpdatabasenormtmp0311051552dtb 990017 9999 99999 999 unknown marine 1948 1990 999 99900 crua6crucruts head 1 rerun1datacrutsrerun_tmpdatabasetmp0311051552dtb 990017 9999 99999 999 unknown marine 1948 1990 999 99900 crua6crucruts head 1 version_3_0primariestemptmp0702091122dtb 10010 709 87 10 jan mayen norway 1921 1990 341921 99900 crua6crucruts head 1 version_3_0primariestemptmp0704300053dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 crua6crucruts head 1 version_3_0dbtestmergedbtmp0702091122dtb 10010 709 87 10 jan mayen norway 1921 1990 341921 99900 crua6crucruts head 1 version_3_0dbtestmergedbtmp0704292355dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 crua6crucruts head 1 version_3_0dbtestmergedbbadtimelinetmp0704251819dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 crua6crucruts head 1 version_3_0dbtestmergedbbadtimelinetmp0704271015dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 crua6crucruts head 1 version_3_0dbtestmergedbbadtimelinetmp0704292158dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 crua6crucruts head 1 version_3_0dbtestmergedbtmp0704300053dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 crua6crucruts head 1 version_3_0dbtmp0702091122dtb 10010 709 87 10 jan mayen norway 1921 1990 341921 99900 crua6crucruts head 1 version_3_0dbtmp0704300053dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 without going any further its obvious that loadcts is going to have to auto sense the lat and lon ranges missing value codes can then be derived if it always returns actual unscaled degrees to one or two decimal places then any value lower than 998 will suffice for both parameters however this does make wonder why it wasnt done like that is there likelihood of the programs being used on spatial subset of stations say english then lon would never get into double figures though lat would well lets just hope not laughs hollowly okay so i wrote extra code into loadcts to detect lat lon ranges it excludes any values for which the modulus of 100 is 99 so hopefully missing value codes do not conribute the factors are set accordingly to 10 or 100 i had to default to 1 which is pity once youve got the factors detection of missing values can be simple outofrange test however sigh this led to examine the detection of nonstandard longitudes small section of code that converts pjstyle reversed longitudes or 0360 ones to regular 180 w to 180 this code is switched on by the presence of the longtype flag in the loadcts call the trouble is that flag is never set by anomdtb there is declaration integer qlongtype but that is never referred to again just another thing i cannot understand and another reason why this should all have been rewritten from scratch year ago so i wrote revlonsfor proglet to reverse all longitude values in database file ran it on the temperature database final begin quote crua6crucrutsversion_3_0dbtestmergedb revlons revlons reverse all longitudes this nifty little proglet will fix all of your longitudes so that they point the right way ie positive east of greenwich negative west of course if they are already fixed this will unfix them i am not that smart so be careful please enter the database to be fixed tmp0704300053dtb output file will be tmp0705101334dtb confirm this filename yn log file will be tmp0705101334log 5065 stations written to tmp0705101334dtb end quote thus the final temperature database is now tmp0705101334dtb reran anomdtb with working latlon detection and missing latlon value detection for both precip and temperature this should ensure that all wmo codes are present and all lats and lons are correct temp begin quote anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required tmp select the cts or dtb file to load tmp0705101334dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto tmptxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 3323823 813 cts 91963 22 3415786 835 process decision percent ofchk latlon 1993 00 00 normal 673044 165 165 outofrange 744 00 00 accepted 3415042 835 dumping years 19012006 to txt files end quote precip begin quote crua6crucrutsversion_3_0primariesprecip anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required pre will calculate percentage anomalies select the cts or dtb file to load pre0612181221dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 4 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto pretxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 7315040 738 cts 299359 30 7613600 768 process decision percent ofchk latlon 17911 02 02 normal 2355275 238 238 outofrange 13253 01 02 accepted 7521013 759 dumping years 19012006 to txt files end quote note that precip accepted values is up to 759 i honestly dont think well get higher decided to process temperature all the way ran idl idl quick_interp_tdm219012006tmpglotmpgrid1200gs05dumpglodumpglopts_prefixtmp0km0705101334txttmp then glo2abs then mergegrids to produce monthly output grids it apparently worked rw 1 f098 cru 138964083 may 13 2042 cru_ts_3_0019012006tmpdatgz rw 1 f098 cru 7852589 may 13 2042 cru_ts_3_0020012006tmpdatgz rw 1 f098 cru 13108065 may 13 2039 cru_ts_3_0019912000tmpdatgz rw 1 f098 cru 13106515 may 13 2036 cru_ts_3_0019811990tmpdatgz rw 1 f098 cru 13106963 may 13 2033 cru_ts_3_0019711980tmpdatgz rw 1 f098 cru 13123939 may 13 2030 cru_ts_3_0019611970tmpdatgz rw 1 f098 cru 13120586 may 13 2026 cru_ts_3_0019511960tmpdatgz rw 1 f098 cru 13120691 may 13 2023 cru_ts_3_0019411950tmpdatgz rw 1 f098 cru 13130077 may 13 2020 cru_ts_3_0019311940tmpdatgz rw 1 f098 cru 13104881 may 13 2016 cru_ts_3_0019211930tmpdatgz rw 1 f098 cru 13094948 may 13 2013 cru_ts_3_0019111920tmpdatgz rw 1 f098 cru 13085509 may 13 1708 cru_ts_3_0019011910tmpdatgz as reminder these output grids are based on the tmp0705101334dtb database with merging of neighbourly stations and limit of 3 standard deviations on anomalies decided to re process precip all the way in the hope that i was in the zone or something started with idl idl quick_interp_tdm219012006preglopregrid450gs05dumpglodumpglopts_prefixpre0km0612181221txtpre then glo2abs then mergegrids all went fine apparently 31 and so to dtr first time for generation i think wrote makedtrfor to tackle the thorny problem of the tmin and tmax databases not being kept in step sounds familiar if worrying am i the first person to attempt to get the cru databases in working order the program pulls punches i had already found that tmx0702091313dtb had seven more stations than tmn0702091313dtb but that hadnt prepared for the grisly truth begin quote crua6crucrutsversion_3_0dbdtr makedtr makedtr produce dtr database this program takes as its input database of of minimum temperatures and another of maximum temperatures and produces database of diurnal temperatures if the input databases are found to be out of synchronisation the option is also given to save synchronised versions so may i please have the tmin database tmn0702091139dtb may i please now have the tmax database tmx0702091313dtb the output database will now be called dtr0705152339dtb important please read its good for you the databases you gave are not synchronised tmn0702091139dtb has 42 extra stations tmx0702091313dtb has 49 extra stations you have the choice of quitting or of allowing to create two new synchronised databases which will be saved and used to create the dtr db enter q to quit s to synchronise s new tmin database is tmn0705152339dtb discarded tmin stations here tmn0702091139dtbdel new tmax database is tmx0705152339dtb discarded tmax stations here tmx0702091313dtbdel number of stations to process 14267 end quote yes the difference is lot more than seven and the program helpfully dumps listing of the surplus stations to the log file not pretty sight unfortunately it hadnt worked either it turns out that there are 3518 stations in each database with wmo code of 0 so as the makedtr program indexes on the wmo code you get the picture cries rewrote as makedtr2 which uses the first 20 characters of the header to match begin quote makedtr2 produce dtr database this program takes as its input database of of minimum temperatures and another of maximum temperatures and produces database of diurnal temperatures if the input databases are found to be out of synchronisation the option is also given to save synchronised versions so may i please have the tmin database tmn0702091139dtb may i please now have the tmax database tmx0702091313dtb the output database will now be called dtr0705162028dtb important please read its good for you the databases you gave are not synchronised tmn0702091139dtb has 203 extra stations tmx0702091313dtb has 209 extra stations you have the choice of quitting or of allowing to create two new synchronised databases which will be saved and used to create the dtr db enter q to quit s to synchronise s new tmin database is tmn0705162028dtb discarded tmin stations here tmn0702091139dtbdel new tmax database is tmx0705162028dtb discarded tmax stations here tmx0702091313dtbdel end quote the big jump in the number of surplus stations is because we are longer automatically matching stations with wmo0 heres what happened to the tmin and tmax databases and the new dtr database old tmin tmn0702091139dtb total records read 14309 new tmin tmn0705162028dtb total records read 14106 tmin tmn0702091139dtbdel total records read 203 old tmax tmx0702091313dtb total records read 14315 new tmax tmx0705162028dtb total records read 14106 tmax tmx0702091313dtbdel total records read 209 new dtr dtr0705162028dtb total records read 14107 sigh one record out also three header problems blanks expected at 81421264761667178 position missed 8 1 14 1 21 0 26 0 47 1 61 0 66 0 71 0 78 0 why well the sad answer is because weve got date wrong all three header problems relate to this line 6190 94 95 98 100 101 101 102 103 102 97 94 94 and as we know this is not conventional header oh bum but but how i know we do muck around with the header and startend years but still wrote filtertmmfor which simply steps through one database usually tmin and looks for perfect match in another database usually tmax perfect here means match of wmo code lat lon startyear and endyear if match is found both stations are copied to new databases begin quote crua6crucrutsversion_3_0dbdtr filtertmm filtertmm create good tminmax databases please enter the tmin database tmn0702091139dtb please enter the tmax database tmx0702091313dtb working old tmin database tmn0702091139dtb had 14309 stations new tmin database tmn0705182204dtb has 13016 stations old tmax database tmx0702091313dtb had 14315 stations new tmax database tmx0705182204dtb has 13016 stations end quote i am going to assume that worked so now to incorporate the australian monthly data packs ow most futureproof strategy is probably to write converter that takes one or more of the packs and creates cruformat databases of them edit nope thought some more and the best strategy is program that takes pairs of aus packs and updates the actual databases bearing in mind that these are trusted updates and wont be used in any other context from dave l who incorporated the initial australian dump for the tmintmax bulletins he used threshold of 26 daysmonth or greater for inclusion obtained two files from dave an email that explains some of the australian bulletin dataformatting and list of austraian headers matched with their internal codes the latter being generated by dave actually although i was going to assume that filtertmm had done the synching job ok brief look at the australian stations in the databases showed otherwise for instance i pulled all the headers with australia out of the two 0705182204 databases now because these were produced by filtertmm we know that the codes if present lats lons and dates will all match any differences will be in altitude andor name and so they were crua6crucrutsversion_3_0dbdtr diff tmn0705182204dtboz tmx0705182204dtboz wc l 336 so roughly 100 dont match they are mostly altitude discrepancies though there are an alarming number of name mismatches too examples of both 74c74 0 3800 14450 11 avalon airport australia 2000 2006 999 99900 0 3800 14450 8 avalon airport australia 2000 2006 999 99900 16c16 0 4230 14650 585 tarraleah village australia 2000 2006 999 99900 0 4230 14650 595 tarraleah chalet australia 2000 2006 999 99900 examples of the second kind name mismatch are most concerning as they may well be different stations looked for all occurences in all tmintmax databases crua6crucrutsversion_3_0dbdtr grep tarraleah dtb tmn0702091139dtb 0 4230 14650 585 tarraleah village australia 2000 2006 999 99900 tmn0702091139dtb9597000 4230 14645 595 tarraleah chalet australia 1991 2000 999 99900 tmn0705182204dtb 0 4230 14650 585 tarraleah village australia 2000 2006 999 99900 tmn0705182204dtb9597000 4230 14645 595 tarraleah chalet australia 1991 2000 999 99900 tmx0702091313dtb 0 4230 14650 595 tarraleah chalet australia 2000 2006 999 99900 tmx0702091313dtb9597000 4230 14645 595 tarraleah chalet australia 1991 2000 999 99900 tmx0705182204dtb 0 4230 14650 595 tarraleah chalet australia 2000 2006 999 99900 tmx0705182204dtb9597000 4230 14645 595 tarraleah chalet australia 1991 2000 999 99900 this takes little sorting out well first recognise that we are dealing with four files tmin and tmax early and late before and after filtertmmfor we see there are two tarraleah entries in each of the four files we see that tarraleah village only appears in the tmin file we see most importantly perhaps that they are temporally contiguous that is each pair could join with minimal overlap as one is 19912000 and the other 20002006 also we note that the early one of each pair has slightly different longitude and altitude the former being the thing that distinguished the stations in filtertmmfor finally this from the tmax2005120120051231txt bulletin 95018 051201051231 4230 14645 180 00 31 31 585 tarraleah village so we can resolve this case single station called tarraleah village running from 1991 to 2006 but what about the others there are close to 1000 incoming stations in the bulletins must every one be identified in this way oh god theres nothing for it ill have to write prog to find matches for the incoming australian bulletin stations in the main databases ill have to use the databases from before the filtertmm application so 0705182204dtb and it will only need the australian headers so i used grep to create 0705182204dtbauhead files the other input is the list of stations taken from the monthly bulletins now these have different number of stations each month so the prog will build an array of all possible stations based on the files we have oh boy and the program shall be called auminmaxmatchfor assembled some information crua6crucrutsversion_3_0db wc l auhead 1518 glseries_tmn_final_mergedauhead 1518 tmn0611301516datauhead 1518 tmn0612081255datauhead 1518 tmn0702091139dtbauhead 1518 tmn0705152339dtbauhead 1426 tmn0705182204dtbauhead the auhead files were created with grep australia actually stopped work on that trying to match over 800 bulletin stations against over 3000 database stations in two unsynchronised files was just hurting my brain the files have to be properly synchronised first with more lenient and interactive version of filtertmm or could i use mergedb pretend to merge tmin into tmax and see what pairings it managed roll through obviously well its worth play unfortunately not because when i tried i got lot of odd errors followed by crash the reason i eventually deduced was that i didnt build mergedb with the idea that wmo codes might be zero many of the australian stations have wmo0 this means that primary matching on wmo code is impossible this just gets worse and worse now it looks as though ill have to find wmo codes or pseudocodes for the 3521 stations in the tmin file that dont have one ok lets break the problem down firstly lot of stations are going to need wmo codes if available it shouldnt be too hard to find any matches with the existing wmo coded stations in the other databases precip temperature secondly we need to exclude stations that arent synchronised between the two databases tmintmax so can mergedb be modified to treat wmo codes of 0 as missing had look and it does check that the code isnt 999 or 0 but not when preallocating flags in subroutine countscnd fixed that and tried running it again exactly the same result crash i cant see anything odd about the station it crashes on 0 2810 11790 407 mount magnet aero australia 2000 2006 999 99900 6190999999999999999999999999999999999999999999999999 2000 339 344 280 252 214 202 189 196 262 291 316 377 2001 371 311 310 300 235 212 201 217 249 262 314 333 200299999999 339 297 258 209 205 212 246 299 341 358 2003 365 367 336 296 249 195 193 200 238 287 325 368 2004 395 374 321 284 219 214 173 188 239 309 305 370 2005 389 396 358 315 251 182 189 201 233 267 332 341 2006 366 331 314 246 2409999999999999999999999999999 its very similar to preceding and following stations and the station before has even less real data the one before that has none at all and is autodeleted the nature of the crash is forrtl error 65 floating invalid so type mismatch possibly the station has match in the tmin database tmn0702091139dtb but the longitude is different tmn0702091139dtb 0 2810 11780 407 mount magnet aero australia 2000 2006 999 99900 tmx0702091313dtb 0 2810 11790 407 mount magnet aero australia 2000 2006 999 99900 it also appears in the tmintmax bulletins eg 7600 070401070430 2812 11784 160 00 30 30 407 mount magnet aero note that the altitude matches as distinct from the station below naturally there is further mount magnet station but its probably distinct tmn0702091139dtb 9442800 2807 11785 427 mount magnet mount australia 1956 1992 999 99900 tmx0702091313dtb 9442800 2807 11785 427 mount magnet mount australia 1957 1992 999 99900 i am at bit of loss it will take very long time to resolve each of these rogue stations time i do not have the only pragmatic thing to do is to dump any stations that are too recent to have normals they will not after all be contributing to the output so i knocked out goodnormfor which simply uses the presence of valid normals line to sort the results were pretty scary begin quote crua6crucrutsversion_3_0dbdtr goodnorm goodnorm extract stations with nonmissing normals please enter the input database name tmn0702091139dtb the output database will be called tmn0705281724dtb removed stations will be placed in tmn0705281724del finished stations retained 5026 stations removed 9283 crua6crucrutsversion_3_0dbdtr goodnorm goodnorm extract stations with nonmissing normals please enter the input database name tmx0702091313dtb the output database will be called tmx0705281724dtb removed stations will be placed in tmx0705281724del finished stations retained 4997 stations removed 9318 end quote essentially two thirds of the stations have normals of course this still leaves us with lot more stations than we had for tmean goodnorm reported 3316 saved 1749 deleted though still far behind precipitation goodnorm reported 7910 saved 8027 deleted i suspect the high percentage lost reflects the influx of modern australian data indeed nearly 3000 of the 3500odd stations with missing wmo codes were excluded by this operation this means that for tmn0702091139dtb 1240 australian stations were lost leaving only 278 this is just silly i cant dump these stations they are needed to potentially match with the bulletin stations i am now going to try the following 1 attempt to pair bulletin stations with existing in the tmin database mark pairings in the database headers and in new australian mappings file program auminmatchfor 2 run an enhanced filtertmm to synchronise the tmin and tmax databases but prioritising the paired stations from step 1 so they are not lost mark the same pairings in the tmax headers too and update the australian mappings file 3 add the bulletins to the databases ok step 1 modified auminmaxmatchfor to produce auminmatchfor hit semiphilosophical problem what to do with positive match between bulletin station and zerowmo database station the station must have real wmo code or itll be rather hard to describe the match got list of around 12000 wmo codes and stations from dave l unfortunately there was problem with its formatting that i just couldnt resolve so current thinking is that if i find pairing between bulletin station and zerocoded australain station in the cru database ill give the cru database station the australian local bulletin code twice once at the end of the header and once as the wmo code multiplied by 1 to avoid implying that its legitimate then if proper code is found or allocated later the mapping to the bulletin code will still be there at the end of the header of course an initial check will ensure that match cant be found within the cru database between the zerocoded station and properlycoded one debated header formats with david i think were going to go with i8a8 at the end of the header though really its 2xi6a8 as i remember the anders code being i2 and the real start year being i4 both from the tmean database this will mean postprocessing existing databases of course but thats not priority brief hopefully diversion to get station counts sorted david needs them so might as well sort the procedure in the upsidedown world of mark and tim the numbers of stations contributing to each cell during the gridding operation are calculated not in the idl gridding program oh but in anomdtb yes the program which reads station data and writes station data has second almostentirely unrelated function of assessing gridcell contributions so to begin with it runs in the usual way crua6crucrutsversion_3_0primariesprecip anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required pre will calculate percentage anomalies select the cts or dtb file to load pre0612181221dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 4 but then we choose different output and it all shifts focus and has to ask all the idl questions select outputs 1cts2ann3txt4stn 4 check for duplicate stns after anomalising 0no0km range 0 select the stn file to save prestn enter the correlation decay distance 450 submit grim that contains the appropriate grid enter the grim filepath clim6190lanpre grid dimensions and domain size 720 360 67420 select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 7315040 738 cts 299359 30 7613600 768 process decision percent ofchk latlon 17911 02 02 normal 2355275 238 238 outofrange 13253 01 02 accepted 7521013 759 calculating station coverages and then it unhelpfully crashes withinrange alloc datab forrtl severe 174 sigsegv segmentation fault occurred ho hum i did try this last year which is why im not tearing my hair out the plan is to use the outputs from the regular anomdtb runs ie the monthly files of valid stations after all we need to know the station counts on per month basis we can use the lat and lon along with the correlation decay distance shouldnt be too awful just even more programming and work so before i commit to that quick look at the idl gridding prog to see if it can dump the figures instead after all this is where the actual station count information is assembled and used well that was erhhh interesting the idl gridding program calculates whether or not station contributes to cell using graphics yes it plots the station sphere of influence then checks for the colour white in the output so there is guarantee that the station number files which are produced independently by anomdtb will reflect what actually happened well ive just spent 24 hours trying to get great circle distance calculations working in fortran with precisely success ive tried the simple method as used in tim geodistpro and the more complex and accurate method found elsewhere wiki and other places neither give results that are anything near reality ffs worked out an algorithm from scratch it seems to give better answers than the others so well go with that also decided that the approach i was taking pick gridline of latitude and reverse engineer the gcd algorithm so the unknown is the second lon was overcomplicated when we dont need to know where it hits just that it does since for any cell the nearest point to the station will be vertex we can test candidate cells for the distance from the appropriate vertex to the station program is stncountsfor but is causing immense problems the problem is really the huge numbers of cells potentially involved in one station particularly at high latitudes working out the possible bounding box when youre within cdd of pole ie for tmean with cdd of 1200 the ns extent is over 20 cells 10 degs in each direction maybe not serious problem for the current datasets but an example of the complexity also deciding on the potential bounding box is nontrivial because of cell width changes at high latitudes at 61 degs north the halfdegree cells are only 27km wide with precip cdd of 450 km this means the bounding box is dozens of cells wide and will be wider at the northern edge clearly large number of cells are being marked as covered by each station so in denselystationed areas there will be considerable smoothing and in sparselystationed or empty areas there will be possibly untypical data i might suggest two station counts one of actual stations contributing from within the cell one for stations contributing from within the cdd the former being subset of the latter so the latter could be used as the previous release was used well got stncountsfor working finally and out of malicious interest i dumped the first stations coverage to text file and counted up how many cells it influenced the station was at 106e 610n the total number of cells covered was staggering 476 or if you prefer 475 indirect and one direct ran for the first month 011901 compared the resulting grid with that from cru ts 21 seems to compare fine some higher some lower example 210 139 142 146 154 156 157 165 170 300 141 148 154 153 153 159 163 168 data are on latitude 265 and longitudes 163170 wrote makelsmaskfor to well make landsea mask itll work with any gridded data file that uses 999 for sea the mask is called lsmaskhalfdegdat adapted stncountsfor to read it and use it to mask the output files still bit disturbed by the large number of cells marked as influenced by single station idl seems to use the inbuilt trigrid function to interpolate the grid so theres way of getting the station count for particular cell that way anyway not that it would mean much since there is bound to be some kind of weighting its not clear what that weighting is though from the idl website so the figures in the station count files are really rather loose what might be useful as companion dataset would be the actual station counts counts for cells with stations actually inside them of course that might be rather sensitive information managed full run of stncounts it took over five and half hours which is bit much back to the gridding i am seriously worried that our flagship gridded data product is produced by delaunay triangulation apparently linear as well as far as i can see this renders the station counts totally meaningless it also means that we cannot say exactly how the gridded data is arrived at from statistical perspective since were using an offtheshelf product that isnt documented sufficiently to say that why this wasnt coded up in fortran i dont know time pressures perhaps was too much effort expended on homogenisation that there wasnt enough time to write gridding procedure of course its too late for to fix it too meh well its been real day of revelations never mind the week this morning i discovered that proper angular weighted interpolation was coded into the idl routine but that its use was discouraged because it was slow aaarrrgghh there is even an option to trigrid at 01 degree resolution and then rebin to 720x360 also deprecated and now just before midnight so it counts having gone back to the tmintmax work ive found that most if not all of the australian bulletin stations have been unceremoniously dumped into the files without the briefest check for existing stations classic example would be these two stations 0 1570 12870 31 kimberley resstatio australia 2000 2006 999 99900 6190999999999999999999999999999999999999999999999999 2000 245 243 243 232 184 143 138 155 193 231 249 249 2001 245 247 241 216 156 167 163 129 201 238 246 247 2002 244 246 230 208 167 122 92 119 202 217 248 259 2003 253 249 222 220 169 151 144 158 203 216 248 250 2004 252 247 244 209 202 135 129 140 176 230 248 257 2005 245 246 237999999999999999999999999999999999999 2006999999999999999999999999999999999999999999999999 0 1565 12871 31 kimberley resstatio australia 1971 2000 999 99900 6190999999999999999999999999999999999999999999999999 1971 254 249 239 218 166 147 142 169 214 246 253 241 1972 246 244 226 198 175 158 126 182 200 222 244 259 1973 255 259 252 232 215 186 171 189 216 240 256 246 1974 247 243 240 217 183 144 134 171 216 247 248 246 1975 239 239 237 216 180 157 168 171 223 233 243 246 1976 235 244 227 190 148 142 142 144 177 236 252 250 1977 253 249 245 218 177 135 130 137 187 226 250 248 1978 247 244 239 199 218 174 162 186 195 233 245 253 1979 247 246 238 217 205 166 147 178 216 234 248 254 1980 249 245 240 221 186 161 141 171 192 241 249 252 1981999999999999999999999999999999999999999999999999 1982999999999999999999999999999999999999999999999999 1983999999999999999999999999999999999999999999999999 1984999999999999999999999999999999999999999999999999 1985999999999999999999999999999999999999999999999999 1986999999999999999999999999999999999999999999999999 1987999999999999999999999999999999999999999999999999 1988999999999999999999999999999999999999999999999999 1989999999999999999999999999999999999999999999999999 1990999999999999999999999999999999999999999999999999 1991 248 244 234 224 169 160 160 140 210 225 252 260 1992 253 251 247 239 2069999 141 173 218 237 246 260 1993 2479999 242 225 207 172 149 170 204 237 249 258 1994 2539999 214 196 171 140 130 141 171 222 248 247 1995 245 249 234 205 186 155 148 151 198 217 245 244 1996 245 238 220 208 159 166 136 161 179 225 233 247 1997 245 243 217 195 186 149 138 156 195 230 242 247 1998 248 250 245 229 188 167 177 158 200 247 253 250 1999 250 245 242 216 144 150 1239999 188 239 240 251 2000 245 243 243 232 184 143 138 154 194 231 249 249 now i admit the lats and lons arent spot on but cmon what are the chances of them being different the two year 2000s are almost identical what about 0 1550 12450 12 kuri bay australia 2000 2006 999 99900 9420800 1548 12452 29 kuri bay australia 1965 1992 999 99900 or 0 1550 12810 11 wyndham australia 2000 2006 999 99900 0 1550 12820 4 wyndham aero australia 2000 2006 999 99900 9421400 1549 12812 11 wyndham post office australia 1968 2000 999 99900 9421401 1547 12810 20 wyndham wyndham australia 1898 1966 999 99900 come on this is one station isnt it id be content to leave it but i have to match the bulletins and i can match to the long stable series or to the loose flapping ones put in for the purpose meh ii so in the end i matched to the 20002006 stations where they actually did match unfortunately the huge bulk of the bulletins still had to have new entries created for them which is shame and begs the question of why the australian update bulletins dont match the original catchup block they sent us for some reason the auminmatch program is causing end of grief i thought id managed complete run and it did produce goodlooking tmin database with lots of new station stubs tacked on the end 1009 6628 11054 12 kuri bay australia 2007 2007 999 1009 6190999999999999999999999999999999999999999999999999 2006999999999999999999999999999999999999999999999999 1019 6628 11054 23 kalumburu australia 2007 2007 999 1019 6190999999999999999999999999999999999999999999999999 2006999999999999999999999999999999999999999999999999 1020 6628 11054 51 truscott australia 2007 2007 999 1020 6190999999999999999999999999999999999999999999999999 2006999999999999999999999999999999999999999999999999 however it doesnt seem to have put the bulletin codes on the a8 header field for some of the matches only not sure why this is yet but have found also that there are cases of duplicated latlon pairs so multiple matches are being made argh will have to further augment auminmatch not happy an interesting aside david was looking at the v300 precip to help national geographic with an enquiry i produced second station file with the honest counts see above and he used that to mask out cells with 0 count ie that only had indirect data from nearby stations there were some odd results with certain months havign data and others being missing after considerable debate and investigation it was understood that anomdtb calculates normals on monthly basis so where there are 7 or 8 missing values in each month 19611990 station may end up contributing only in certain months of the year throughout its entire run this was noticed in the seychelles where only october has real data the remaining months being relaxed to the climatology but excluded by david using the tight station mask there is easy solution because essentially its an honest result only october has sufficient values to form normal so only october gets anomalised its an unfortunate concidence that its the only station in the cell but its not the only one solution could be for anomdtb to get bit more involved in the gridding to check that if cell only has one station for one or more years then its allornothing maybe if only one month has normal then its dumped and the whole reverts to climatology maybe if 4 or more months have normals maybe if 0 months have normals and the rest can be brought in with minor relaxation of the 75 rule who knows back to auminmatchfor and philosophical breakthrough built loop to find fuzzy matches and group them together the user then processes one group at time pairing up matches until the potential for further matches is zero or the user decides it is uses fsm to work out each chain all db matches for bulletin then all bulletins that match each of those db stations then etc to understand it either read the code especially the comments or just look at this mindboggling example from the first run of it user match decisions please bulletin stations 8 1 9021 3193 11598 15 perth airport 2 9225 3192 11587 25 perth metro 3 9106 3205 11598 10 gosnells city 4 9240 3201 11614 384 bickley 5 9172 3210 11588 30 jandakot aero 6 9215 3196 11576 41 swanbourne 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 18 1 0 3190 11590 25 perth metro 2000 2006 2 0 3190 11600 15 perth airport 2000 2006 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 6 0 3200 11580 41 swanbourne 2000 2006 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 11 0 3210 11590 30 jandakot aero 2000 2006 12 0 3210 11600 10 gosnells city 2000 2006 13 0 3200 11610 384 bickley 2000 2006 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 12 bulletin stations 7 2 9225 3192 11587 25 perth metro 3 9106 3205 11598 10 gosnells city 4 9240 3201 11614 384 bickley 5 9172 3210 11588 30 jandakot aero 6 9215 3196 11576 41 swanbourne 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 17 1 0 3190 11590 25 perth metro 2000 2006 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 6 0 3200 11580 41 swanbourne 2000 2006 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 11 0 3210 11590 30 jandakot aero 2000 2006 12 0 3210 11600 10 gosnells city 2000 2006 13 0 3200 11610 384 bickley 2000 2006 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 21 bulletin stations 6 3 9106 3205 11598 10 gosnells city 4 9240 3201 11614 384 bickley 5 9172 3210 11588 30 jandakot aero 6 9215 3196 11576 41 swanbourne 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 16 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 6 0 3200 11580 41 swanbourne 2000 2006 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 11 0 3210 11590 30 jandakot aero 2000 2006 12 0 3210 11600 10 gosnells city 2000 2006 13 0 3200 11610 384 bickley 2000 2006 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 312 bulletin stations 5 4 9240 3201 11614 384 bickley 5 9172 3210 11588 30 jandakot aero 6 9215 3196 11576 41 swanbourne 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 15 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 6 0 3200 11580 41 swanbourne 2000 2006 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 11 0 3210 11590 30 jandakot aero 2000 2006 13 0 3200 11610 384 bickley 2000 2006 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 413 bulletin stations 4 5 9172 3210 11588 30 jandakot aero 6 9215 3196 11576 41 swanbourne 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 14 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 6 0 3200 11580 41 swanbourne 2000 2006 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 11 0 3210 11590 30 jandakot aero 2000 2006 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 511 bulletin stations 3 6 9215 3196 11576 41 swanbourne 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 13 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 6 0 3200 11580 41 swanbourne 2000 2006 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 66 bulletin stations 2 7 9194 3222 11581 14 medina research cent 8 9256 3224 11568 6 garden island hsf database stations 12 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 14 0 3220 11580 14 medina research cent 2000 2006 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 714 bulletin stations 1 8 9256 3224 11568 6 garden island hsf database stations 11 3 9461000 3190 11600 20 perth airport compar 1944 2006 4 9461001 3190 11600 18 perth airport 1944 2004 5 9461501 3198 11607 210 kalamunda kalamunda 1908 1992 7 0 3200 11580 20 subiaco treatment pl 2000 2006 8 0 3196 11579 20 subiaco treatment pl 1991 1999 9 9460800 3195 11587 19 perth perth regiona 1897 1992 10 9460801 3195 11587 19 perthperthregiona 1897 1992 15 0 3220 11580 4 kwinana bp refinery 2000 2006 16 0 3223 11576 4 kwinana bp refinery 1961 2000 17 9560800 3222 11581 14 medina research cent 1991 2000 18 0 3220 11570 6 garden island hsf 2000 2006 enter matching pair bulletindatabase or n to end 818 amazing huh most are actually more like this user match decisions please bulletin stations 1 1 9053 3167 11602 40 pearce raaf database stations 2 1 0 3170 11600 40 pearce raaf 2000 2006 2 9461200 3167 11602 49 bullsbrook pearce 1940 1992 enter matching pair bulletindatabase or n to end 11 however still teething troubles with previouslypaired stations reappearing for second chance sometimes so more debugging fixed also added test before the user gets chain to anticipate what the user er i would do for instance i generally match to 2002006 wmo0 database station if the names match as theyre the ones david l put in from the aus update files i er the user then gets ambiguities and nearby but unconnected stations fine until you get nasty surprise like this one user match decisions please bulletin stations 2 1 58009 2864 15364 95 byron bay cape byro 2 58216 2864 15364 95 byron bay cape byro database stations 3 1 0 2860 15360 95 byron bay cape byro 2000 2006 2 0 2860 15360 95 byron bay cape byro 2000 2006 3 9459500 2863 15363 98 cape byron 1974 1992 looking in the files i see that bulletin 58009 is byron bay cape byron lighthouse and 58216 is byron bay cape byron aws but the database stubs that have been entered have not been intelligently named just truncated so i have way of knowing which is which cru needs data manager in this case i had to assume that the updates were processed in au code order so 11 and 22 argh few doubles found too bulletin stations 1 1 33106 2037 14895 59 hamilton island airp database stations 3 1 0 2040 14900 23 hamilton island airp 2000 2006 2 0 2040 14900 59 hamilton island airp 2000 2006 3 9436800 2035 14895 23 hamilton island airp 1991 2000 bulletin stations 1 1 90186 3829 14245 71 warrnambool airport database stations 4 1 0 3830 14250 71 warrnambool airport 2000 2006 2 0 3830 14240 75 warrnambool airport 2000 2006 3 0 3840 14248 21 warrnambool post of 1961 1980 4 0 3828 14243 76 warrnambool 1983 1999 and the results strictly average i thought but id forgotten to count the extra anticipated match routine achievements so i grepped the matchbymatch file matches0706281447dat and got crua6crucrutsversion_3_0dbdtr grep auto matches0706281447dat wc l 232 crua6crucrutsversion_3_0dbdtr grep auto from chain matches0706281447dat wc l 514 crua6crucrutsversion_3_0dbdtr grep manual matches0706281447dat wc l 12 in other words all that sweat was worth it 746 stations matched automatically and further 12 manually only 797758 39 bulletins unmatched wheeee and here they are 6072 2303 11504 111 emu creek station australia 2007 2007 999 6072 12044 3355 12070 220 munglinup west australia 2007 2007 999 12044 12241 2888 12132 370 leonora aero australia 2007 2007 999 12241 17031 2965 13806 50 marree comparison australia 2007 2007 999 17031 21118 3323 13800 10 port pirie aerodrome australia 2007 2007 999 21118 22801 3575 13659 143 cape borda compariso australia 2007 2007 999 22801 23122 3451 13868 65 roseworthy aws australia 2007 2007 999 23122 24521 3512 13926 33 murray bridge compar australia 2007 2007 999 24521 25509 3533 14052 99 lameroo comparison australia 2007 2007 999 25509 26026 3716 13976 3 robe comparison australia 2007 2007 999 26026 32004 1826 14602 5 cardwell marine pde australia 2007 2007 999 32004 35019 2282 14764 260 clermont sirius st australia 2007 2007 999 35019 48243 2943 14797 154 lightning ridge visi australia 2007 2007 999 48243 55024 3103 15027 307 gunnedah resource ce australia 2007 2007 999 55024 56037 3053 15167 987 armidale tree group australia 2007 2007 999 56037 60013 3218 15251 4 forster tuncurry r australia 2007 2007 999 60013 63039 3371 15031 1015 katoomba murri st australia 2007 2007 999 63039 63226 3348 15013 900 lithgow cooerwull australia 2007 2007 999 63226 68257 3406 15077 112 campbelltown mount australia 2007 2007 999 68257 70263 3475 14970 670 goulburn tafe australia 2007 2007 999 70263 82170 3655 14600 171 benalla airport australia 2007 2007 999 82170 84150 3787 14801 4 lakes entrance east australia 2007 2007 999 84150 85099 3863 14581 3 pound creek australia 2007 2007 999 85099 88023 3723 14591 230 lake eildon australia 2007 2007 999 88023 200001 2166 15027 209 middle percy island australia 2007 2007 999 200001 200100 2066 11558 24 varanus island australia 2007 2007 999 200100 200212 1061 12598 999 northern endeavour australia 2007 2007 999 200212 200283 1629 14997 8 willis island australia 2007 2007 999 200283 200288 2904 16794 112 norfolk island aero australia 2007 2007 999 200288 200731 1176 13003 7 point fawcett australia 2007 2007 999 200731 200783 1772 14845 3 flinders reef australia 2007 2007 999 200783 200790 1045 10569 261 christmas island aer australia 2007 2007 999 200790 200824 1753 21040 2 papeete australia 2007 2007 999 200824 200838 3922 14698 116 hogan island australia 2007 2007 999 200838 200851 52 16692 7 nauru arcs2 australia 2007 2007 999 200851 200852 206 14743 4 manus arcs1 australia 2007 2007 999 200852 300000 6858 7797 18 davis australia 2007 2007 999 300000 300001 6760 6287 10 mawson australia 2007 2007 999 300001 300017 6628 11054 40 casey australia 2007 2007 999 300017 resultant database tmn0707021605dtb edit found another fault had to rerun headers werent being modded if the wmo code was already there 32 the next stage heart falls will be to synchronise tmax against tmin sweeping up duplicates in the process how longs this gonna take well actually it might be fairly easy if we use similar approach we can base it all around the user being given cloud of related stations to pick pairs from only they will be uniquely numbered so that two from the same database can be selected the user can in this way pair up stations in groups of course this comes with the downside of complexity and therefore bugs and both databases will almost certainly have to be preloaded in their entirety because of the need for the user to be able to confirm header and data precedence info when stations within database are merged oh and ill have to move bloody quick so more bugs well its written and debugging around 1500 lines of code or 1000 without all the comments it does indeed read in all the data so has to be compiled on uealogin1 as crua6 doesnt have enough memory reusing code from auminmatchfor did speed things up bit though two new subroutines had to be written to carry out checking for merges within database and for matches between the databases also introduced user decision at the start to allow the tmin database to take precedence in terms of station metadata heres the current state of play begin quote uealogin1crucrutsversion_3_0dbdtr auminmaxsync welcome to the tmintmax synchroniser before we get started an important question should tmin header info take precedence over tmax this will significantly reduce user decisions later but is big step as tmax settings may be silently overridden to let tmin header values take precedence over those of tmax enter yes yes please enter the tmin database name tmn0707021605dtb please enter the tmax database name tmx0702091313dtb reading in both databases tmin database stations 14349 tmax database stations 14315 processing onetoone matches initial scan found onetoone matches 7875 of which confirmed 7691 in station cloud 6411 tmin in station cloud 6392 tmax unmatchable 63 tmin unmatchable 48 tmax processing match clouds user match decisions please tmin stations 2 1 401000 3178 3522 783 jerusalem 1863 2000 999 0 2 4018400 3178 3522 809 jerusalem 1977 1995 999 0 tmax stations 2 3 401000 3178 3522 783 jerusalem 1863 2000 999 0 4 4018400 3178 3522 809 jerusalem 1977 1995 999 0 remember merge first match second enter any pair to match or merge or n to end end quote so stats pretty much as expectedhoped the onetoone matches should of course be 100 but as the databases arent synchronised and as there are hundreds of duplicate entries only around 50 match straight away the situation isnt as bleak as it looks though there is further automatching at the beginning of each cloud so the user can still be spared the obvious if the merging gets too onerous though i might have to automate that with associated risks and of course if you look closely things are still little offbeam found another database bug by chance tab instead of space after cranwell 324320 5303 50 62 cranwell uk 1961 1995 999 99900 doesnt show up in reads as its white space character argh fixed in tmin tmax now to find out why some matched stations still dont have the backref in the last header field found it not my problem its the ones that preexisted in the databases theres 84 in total i think so i can write proglet to check that any with negative wmo codes have the positive version in that last field and i did fixtnxrefsfor fixed tmn0702091139dtb 84 fixed tmn0707021605dtb 651 fixed includes all with negative wmos regardless of end field tmx0702091313dtb 84 fixed so why when we matched 758 bulletins in the first place did this program only fix 651 of which 84 were preexisting because of course the matches only get negative wmo code if the original wmo code is missing zero the missing stations would be ones that already had wmo code so try again and its looking good begin quote uealogin1crucrutsversion_3_0dbdtr auminmaxsync welcome to the tmintmax synchroniser before we get started an important question should tmin header info take precedence over tmax this will significantly reduce user decisions later but is big step as tmax settings may be silently overridden to let tmin header values take precedence over those of tmax enter yes yes please enter the tmin database name tmn0702091139dtb please enter the tmax database name tmx0702091313dtb reading in both databases tmin database stations 14309 tmax database stations 14315 processing onetoone matches initial scan found onetoone matches 7889 of which confirmed 7702 in station cloud 6365 tmin in station cloud 6378 tmax unmatchable 55 tmin unmatchable 48 tmax processing match clouds user match decisions please tmin stations 2 1 401000 3178 3522 783 jerusalem 1863 2000 999 401000 2 4018400 3178 3522 809 jerusalem 1977 1995 999 0 tmax stations 2 3 401000 3178 3522 783 jerusalem 1863 2000 999 401000 4 4018400 3178 3522 809 jerusalem 1977 1995 999 0 remember merge first match second enter any pair to match or merge or n to end 12 merging two stations from the tmin database stn 1 401000 3178 3522 783 jerusalem israel 1863 2000 999 401000 stn 2 401000 3178 3522 783 jerusalem israel 1863 2000 999 401000 please resolve the following inconsistencies overlap station 401000 3178 3522 783 jerusalem israel 1863 2000 999 401000 station b 4018400 3178 3522 809 jerusalem israel 1977 1995 999 99900 you must decide which stations data takes precedence the intercorrelation for the period is 099 enter or b or undo pairx end quote well its kinda working i found some idiotic bugs though it is fearsomely complicated program with lots of indirect pointers though i do try and resolve them at the first opportunity one thing thats making debugging frustratingly difficult is something that must be uealogin1 feature and i havent seen it before the program doesnt actually flush the output channels whenever you write for example as i write this the program has dispensed with automatching initial scan found onetoone matches 7875 of which confirmed 7691 in station cloud 6411 tmin in station cloud 6392 tmax unmatchable 63 tmin unmatchable 48 tmax yes its little tighter now anyway since then ive merged two pair jerusalem then paired the remainder that activity has generated match reports on channel 31 but they are not in the file yet here is the tail of channel 31 crua6crucrutsversion_3_0dbdtr tail mat0707121500dat tmax 9929470 4330 1340 342 macerata italy 1953 1975 999 99900 auto pairing from onetoone scan tmin 9929480 4030 880 585 macomer italy 1952 1978 999 99900 tmax 9929480 4030 880 585 macomer italy 1952 1978 999 99900 auto pairing from onetoone scan tmin 9929500 4010 1850 86 palascia aero italy 1952 1978 999 99900 tmax 9929500 4010 1850 86 palascia aero italy 1952 1978 999 99900 auto pairing from onetoone scan tmin 9929520 4060 1490 30 pontecagnano italy 1951 1978 999 99900 tmax 9929520 4060 1490 30 pontecagnano italy 1951 1978 999 99900 in addition the log file is empty yet at least 416 bytes have been written to it how the hell can i debug if i cant monitor whats being written to the log files of course once i forcequit the program and wait bit the missing info appears similarly if i carry on using the program the files get more info its as if theres write buffer that runs fifo must look at the help why is it that whenever i crack the programming the systems themselves step in the screw it up and computer support is away of course looked at f77 help nothing well nothing obvious anyway more debugging and seems to be working but its going to take ages here is an example of the problem begin quote user match decisions please tmin stations 2 1 315770 5638 287 10 leuchars uk 1959 1995 999 315770 2 317100 5640 287 12 leuchars united kingdo 1997 2006 999 0 tmax stations 2 3 315770 5638 287 10 leuchars uk 1959 1995 999 315770 4 317100 5638 287 12 leuchars raf uk uk 1973 2006 999 0 remember merge first match second enter any pair to match or merge or n to end end quote not only do both databases have unnecessary duplicates introduced for external mapping purposes by the look of it but the main stations 2 and 4 have different station name country in fact one of the country names is illegal dealing with things like this cannot be automated as theyre the results of nonautomatic decisions something new listing of 147 australian bulletin stations most of which have mappings to wmo codes decided to xref against the mapped tmin database for laugh then decided to take it more seriously wrote prog to impose the mappings onto tmn0707021605dtb overriding existing mappings as necessary what bloody mess decided to be vaguely sensible and let the program auwmoxreffor evolve so to begin with it just did scan between the mappings file au_mapping_to_wmodat and the tmin database with my mappings in tmn0707021605dtb results crua6crucrutsversion_3_0dbdtr auwmoxref begin quote auwmoxref check australian crossreferences enter the file of wmo mappings au_mapping_to_wmodat 115 mappings read enter the mapped tmin database tmn0707021605dtb 14349 database headers read results wmo matches 92 multiples 0 ref matches 60 ref empty 31 ref wrong 1 ref matches 114 multiples 0 wmo matches 60 wmo 1ref 41 wmo wrong 13 end quote so first the good news duplicates well there shouldnt have been any anyway of course but the way things are going im taking nothing for granted see i count something turning out as expected as good news so anyway i also extracted the statistic that 26 mappings matched both ref and wmo but to separate database entries thus the 115 mappings are allocated as follows 60 mapping found to be correctly implemented over half excellent 41 wmo missing of which 26 wmo found elsewhere one of which has an unmapped ref attached to it 15 wmo not in database can add wmo codes for these 13 wmo wrong of which 5 can be merged with real wmo effectively same station 8 wmo not in database 1 completely unmatched 96003 949500 for the purposes of actions to take the 13 wmo wrong refs can simply be unmapped from their incorrect mappings and be rolled into the 41 wmo missing refs so 60 mapping found to be correctly implemented over half excellent 54 wmo missing or wrong of which 31 wmo found elsewhere one of which has an unmapped ref attached to it 23 wmo not in database but pairing made can add wmo codes for these 8 wmo not in database and pairing can add new stations for these 1 completely unmatched 96003 949500 so actions to take 1 for the first 60 action required 2 for the 13 with incorrectlyassigned wmos disengage and roll into the rest below 3 for the 1 wmo with an unmapped ref attached disengage and roll into the rest below 3 for the 31 with dislocated wmos print list and ref when doing the tmintmax syncing 4 for the 23 with wmoless stations add the wmo codes 5 for the 8 with wmo found and pairing found create new stations for the disengagements decided to work directly with an editor rather than craft another program so changes made to tmn0707021605dtb after suitable backup was made of course the following assignments were disengaged and replaced with 99900 where wmo code follows in brackets the ref was reassigned there 1 9460300 3200 11550 43 rottnest island australia 1898 2006 999 9193 9460200 2 9464600 3090 12810 159 forrest australia 1946 2006 999 11052 3 9432200 2020 13000 340 rabbit flat australia 1969 2006 999 15666 4 9557400 2640 15300 6 tewantin rsl park australia 1949 2006 999 40908 5 9451600 2810 14860 199 st george airport australia 1938 2006 999 43109 9451700 6 9452700 2950 14990 213 moree aero australia 1964 2006 999 53115 9552700 7 9454100 2980 15110 582 inverell raglan st australia 1907 2006 999 56242 8 9478700 3140 15290 4 port macquarie airpo australia 1907 2006 999 60139 9 9475800 3210 15090 216 scone scs australia 2000 2006 999 61089 9473800 10 9494000 3510 15080 85 jervis bay point pe australia 1907 2006 999 68151 11 9491600 3590 14840 1482 cabramurra smhea aws australia 1962 2006 999 72161 12 9482700 3630 14160 133 nhill australia 1897 2006 999 78031 9582900 13 9597900 4300 14710 63 grove comparison australia 1961 2006 999 94069 the mismatched wmo code station was disengaged from its reference and given 48027 instead 1 9471100 3150 14580 218 cobar airport aws australia 1962 2006 999 48237 48027 i mailed bom as we have 94711 cobar aws but they have 94710 for aws and 94711 for cobar mo the reply was as follows begin quote on 18 jul 2007 at 851 matthew bastin wrote hi ian i hope this table helps name bom wmo opened closed cobar comparison 48244 94711 1111997 15112000 cobar mo 48027 94711 1011962 cobar airport aws 48237 94710 11061993 cobar po 48030 111881 31121965 the blank in the closed column means that the site is still open when cobar comparison site closed it transferred its wmo number to cobar mo blank in the wmo column means that the site never had wmo number i am not sure of the overlap between the assignment of 94711 between 48244 and 48027 i will find out and get back to you end quote here are our current cobar headers 0 3150 14580 260 cobar comparison australia 2000 2006 999 99900 0 3150 14580 260 cobar mo australia 2000 2006 999 99900 0 3148 14582 265 cobar australia 1962 2004 999 99900 0 3150 14580 251 cobar post office australia 1902 1960 999 99900 9471100 3150 14580 218 cobar airport aws australia 1962 2006 999 48027 now looking at the dates something bad has happened hasnt it cobar airport aws cannot start in 1962 it didnt open until 1993 looking at the data the cobar station 19622004 seems to be an exact copy of the cobar airport aws station 19622004 except that the latter has more missing values now cobar airport aws has 15 months of missing value codes beginning oct 1993 coincidence i think that that series should start there furthermore the overlap between cobar and cobar mo 20002004 is almost identical 0 3148 14582 265 cobar australia 1962 2004 999 99900 2000 177 209 183 135 80 51 45 52 105 122 166 186 2001 223 214 159 126 72 61 43 52 105 110 148 181 2002 195 185 168 148 88 58 49 63 101 128 186 192 2003 222 216 161 137 97 71 56 61 92 113 159 208 2004 207 226 175 141 74 69 46 69 90 136 160 186 0 3150 14580 260 cobar mo australia 2000 2006 999 99900 2000 178 209 184 136 80 52 45 55 105 122 166 186 712 2001 223 214 159 126 72 61 43 52 105 110 148 181 1212 2002 195 185 168 148 88 58 49 63 101 128 187 192 1112 2003 222 216 161 137 97 71 56 61 92 113 159 208 1212 2004 207 226 175 141 74 69 46 69 90 136 160 186 1212 i therefore propose to extend cobar mo using cobar and to truncate cobar airport aws at 1993 all bom codes will be appended for completeness so the new headers with latlon from bom too are 0 3149 14583 260 cobar comparison australia 2000 2006 999 48244 closed 9471100 3149 14583 260 cobar mo australia 1962 2006 999 48027 0 3150 14583 251 cobar post office australia 1902 1960 999 48030 closed 9471000 3154 14580 218 cobar airport aws australia 1995 2006 999 48237 deleted 0 3148 14582 265 cobar australia 1962 2004 999 99900 the remaining 26 dislocated references were reassigned as for the 13 above legitimate mappings 1 3003 9420300 2 4032 9431200 3 5007 9430200 4 7176 9431700 5 9021 9461000 6 14508 9415000 7 14932 9413100 8 17031 9448000 9 22801 9480500 10 26026 9481200 11 27045 9417000 12 32040 9429400 13 40842 9457800 14 50052 9470700 15 55024 9474000 16 67105 9575300 17 68072 9475000 18 71041 9590800 19 86282 9486600 20 200283 9429900 21 200288 9499600 22 200790 9699500 23 200839 9499500 24 300000 8957100 25 300001 8956400 26 300017 8961100 wmo codes were added to these uncoded sites as shown 1 9410000 1430 12670 23 kalumburu australia 2000 2006 999 1019 2 9562500 3160 11720 217 cunderdin airfield australia 2000 2006 999 10286 3 9564000 3270 11670 275 wandering australia 2000 2006 999 10917 4 9567000 3380 13820 109 snowtown rayville p australia 2000 2006 999 21133 5 9481400 3530 13890 58 strathalbyn racecour australia 2000 2006 999 24580 6 9548200 2590 13940 47 birdsville airport australia 2000 2006 999 38026 7 9552900 2670 15020 305 miles constance stre australia 2000 2006 999 42112 8 9549200 2800 14380 132 thargomindah airport australia 2000 2006 999 45025 9 9578400 3190 15250 8 taree airport aws australia 2000 2006 999 60141 10 9571900 3220 14860 284 dubbo airport aws australia 2000 2006 999 65070 11 9586900 3560 14500 94 deniliquin airport australia 2000 2006 999 74258 12 9495400 4070 14470 94 cape grim baps australia 2000 2006 999 91245 13 9596400 4110 14680 3 low head australia 2000 2006 999 91293 14 9595900 4190 14670 1055 liawenee australia 2000 2006 999 96033 the following was corrected ref had been mistyped as 78013 1 9582900 3783 14206 200 hamilton research st australia 1971 1998 999 78031 now the results look like this wmo matches 106 ref matches 106 ref empty 0 ref wrong 0 ref matches 106 wmo matches 106 wmo 1ref 0 wmo wrong 0 in other words there are 115106 9 mappings unfulfilled the ref hasnt been matched and wmo code isnt in the database however that didnt mean they werent in the database with missing wmo code did it the following were found and augmented with both wmo code and ref 9457000 2639 15304 6 tewantin rsl park australia 2000 2004 999 40908 9594000 3509 15080 85 jervis bay pt perp aws australia 2000 2006 999 68151 the following were added as new station stubs 9532200 2018 13001 340 rabbit flat australia 2007 2007 999 15666 9554100 2978 15111 582 inverell raglan st australia 2007 2007 999 56242 9478600 3143 15287 4 port macquarie airpt australia 2007 2007 999 60139 9591600 3594 14838 1482 cabramurra smhea aws australia 2007 2007 999 72161 9597100 4298 14708 63 grove comparison australia 2007 2007 999 94069 the following was complicated by the fact that two versions of the station appear to have been concatenated this is the station as it already exists in the tmin database 9464600 3085 12811 159 forrest australia 1946 2006 999 99900 however the current live forrest station 11052 started in 1993 according to bomau records and wouldnt you know it the data for this station has missing data between 1292 and 1299 inclusive so i reckon its the old forrest aero station wmo 9464600 au id 11004 with the new australian bulletin updates tacked on hence starting in 2000 especially as the old station started in 1946 httpwwwbomgovauclimateaveragestablescw_011004shtml the trouble is that the bomau mappings all agree that forrest is now wmo9564600 so do i split off the 2000present data to new station with the new number or accept that whoever joined them dave looked into it and decided it would be ok the bom website says theyre 800m apart decided to be brave and split the data back into two stations with both codes attached in case we ever get replacement data for the closed station the site says it went to 1995 after all so there are now two forrest stations 9464600 3085 12811 159 forrest aero australia 1946 1992 999 11004 9564600 3085 12811 159 forrest australia 2000 2006 999 11052 hope thats right the following mapping was added though the station does not currently feature in the bulletins 9495900 4228 14628 999 butlers gorge australia 2007 2007 999 96003 6190999999999999999999999999999999999999999999999999 2007999999999999999999999999999999999999999999999999 also ran risky searchreplace to leftjustify the australia in its field provided the field wasnt touched by an extended station name seems to have been 100 successful all 115 refs now matched in the tmin database confidence in the fidelity of the australian station in the database drastically reduced likelihood of invalid merging of australian stations high lets go well ok made some final improvements to the syncing program now after it forms cloud it should automatically merge stations provided the criteria are met and others are possibles it also records in separate action file act every relevant action performed during the run so that if interrupted i should be able to hack in something to enable resume its been done bit hastily so guarantees that enough informations been saved debugging is still big issue unfortunately its complicated program to sort out and the possibilities for indexing errors are many in fact for the first time ever its just locked up thats first it was due to getmos not defaulting to months 1 12 if the data was all missing another problem solved spent ages wondering how the start end years for particular station waratah were being corrupted turns out they werent id written getmos to trim empty years but forgot to check the return flag duh so perhaps debugged run through im quickly realising that the australian stations are in such state that im having to constantly refer to the station descriptions on the bom website which are individual pdfs httpwwwbomgovauclimatecdometadatapdfmetadata088110pdf it takes time time i dont have though im pleased to see that the second fsm is helpfully chipping in to pair things up when possible getting seriously fed up with the state of the australian data so many new stations have been introduced so many false references so many changes that arent documented every time cloud forms im presented with bewildering selection of similarsounding sites some with references some with wmo codes and some with both and if i look up the station metadata with one of the local references chances are the wmo code will be wrong another station will have it and the latlon will be wrong too ive been at it for well over an hour and ive reached the 294th station in the tmin database out of over 14000 now even accepting that it will get easier as clouds can only be formed of whats ahead of you it is still very daunting i go on leave for 10 days after tomorrow and if i leave it running it isnt likely to be there when i return as to whether my action dump will work to save repetition who knows yay twoandahalf hours into the exercise and im in argentina pfft and back to australia almost immediately and then chile getting there unfortunately after around 160 minutes of uninterrupted decision making my screen has started to black out for half second at time more video cable problems but why now the count is up to 1007 though i am very sorry to report that the rest of the databases seem to be in nearly as poor state as australia was there are hundreds if not thousands of pairs of dummy stations one with wmo and one with usually overlapping and with the same station name and very similar coordinates i know it could be old and new stations but why such large overlaps if thats the case aarrggghhh there truly is end in sight look at this user match decisions please tmin stations 4 1 0 153 12492 80 menadodr sa indonesia 1960 1975 999 0 2 0 153 12492 80 menado sam ratulang indonesia 1986 2004 999 0 4 9701400 153 12492 80 menadodr sam ratul indonesia 1995 2006 999 0 5 9997418 153 12492 81 samratulangi menado indonesia 1973 1989 999 0 tmax stations 4 6 0 153 12492 80 mapangetmanado indonesia 1960 1975 999 0 7 0 153 12492 80 menado sam ratulang id id 1957 2004 999 0 9 9701400 153 12492 80 menadodr sam ratul indonesia 1995 2006 999 0 10 9997418 153 12492 81 samratulangi menado indonesia 1972 1989 999 0 remember merge first then match enter any pair to match or merge to automatch merges or x to end i honestly have idea what to do here and there are countless others of equal bafflingness ill have to go home soon leaving it running and hoping none of the systems die overnight it survived thank deity and long run of duplicate stations each requiring multiple decisions concerning spatial info exact names and data precedence for overlaps if for any reason this has to be rerun it can certainly be speeded up some large clouds too this one started with 59 members from each database user match decisions please tmin stations 7 11 7101965 4362 7940 78 toronto island 1905 1959 999 0 14 7163427 4363 7940 77 toronto island canada 1957 1994 999 0 23 7101987 4380 7955 194 toronto met res stn 1965 1988 999 0 24 7163434 4380 7955 194 toronto met res stn canada 1965 1988 999 0 36 0 4388 7944 233 richmond hill 1959 2003 999 0 39 7163408 4388 7945 233 richmond hill canada 1959 1990 999 0 40 7163409 4387 7943 218 richmond hill wpcp 1960 1981 999 0 tmax stations 8 70 7101965 4362 7940 78 toronto island 1905 1959 999 0 71 7126500 4363 7940 77 toronto island 1957 1994 999 0 73 7163427 4363 7940 77 toronto island canada 1957 1990 999 0 82 7101987 4380 7955 194 toronto met res stn 1965 1988 999 0 83 7163434 4380 7955 194 toronto met res stn canada 1965 1988 999 0 95 0 4388 7944 233 richmond hill 1959 2003 999 0 98 7163408 4388 7945 233 richmond hill canada 1959 1990 999 0 99 7163409 4387 7943 218 richmond hill wpcp 1960 1981 999 0 there were even larger clouds later one thing thats unsettling is that many of the assigned wmo codes for canadian stations do not return any hits with web search usually the countrys met office or at least the weather underground show up but for these stations nothing at all makes wonder if these are longdiscontinued or were even invented somewhere other than canada examples 7162040 brockville 7163231 brockville 7163229 brockville 7187742 forestburg 7100165 forestburg heres heartwarming example of cloud which selfpaired completely debug ines included begin quote dbg cloud formed with 6 6 members dbg automerging done leaving 6 6 dbg potauto ij 1 1 dbg incs2mcs2m15 1 1 1 8578 8582 8596 0 dbg paired 1 1 108 mile house abel attempting to pair stations from tmin 0 5170 12140 994 108 mile house abel 1987 2002 999 99900 from tmax 0 5170 12140 994 108 mile house abel 1987 2002 999 99900 dbg autopaired 1 1 dbg potauto ij 2 2 dbg incs2mcs2m15 2 1 2 8578 8582 8596 0 dbg paired 2 2 100 mile house attempting to pair stations from tmin 7194273 5165 12130 1059 100 mile house canada 1970 1999 999 99900 from tmax 7194273 5165 12130 1059 100 mile house canada 1970 1999 999 99900 dbg autopaired 2 2 dbg potauto ij 3 3 dbg incs2mcs2m15 3 1 3 8578 8582 8596 0 dbg paired 3 3 horse lake attempting to pair stations from tmin 7103611 5160 12120 994 horse lake 1983 1994 999 99900 from tmax 7103611 5160 12120 994 horse lake 1983 1994 999 99900 dbg autopaired 3 3 dbg potauto ij 4 4 dbg incs2mcs2m15 4 1 4 8578 8582 8596 0 dbg paired 4 4 lone butte 2 attempting to pair stations from tmin 7103629 5155 12120 1145 lone butte 2 1981 1991 999 99900 from tmax 7103629 5155 12120 1145 lone butte 2 1981 1991 999 99900 dbg autopaired 4 4 dbg potauto ij 5 5 dbg incs2mcs2m15 5 1 5 8578 8582 8596 0 dbg paired 5 5 100 mile house 6ne attempting to pair stations from tmin 7103637 5168 12122 928 100 mile house 6ne 1987 2002 999 99900 from tmax 7103637 5168 12122 928 100 mile house 6ne 1987 2002 999 99900 dbg autopaired 5 5 dbg potauto ij 6 6 dbg incs2mcs2m15 6 1 6 8578 8582 8596 0 dbg paired 6 6 watch lake north attempting to pair stations from tmin 7103660 5147 12112 1069 watch lake north 1987 1996 999 99900 from tmax 7103660 5147 12112 1069 watch lake north 1987 1996 999 99900 dbg autopaired 6 6 end quote now arguably the mile house abel stations should have rolled into one of the other mile house ones with wmo code but the latlonalt arent close enough which is as intended well it kind of worked thought the resultant files arent exactly what id expected rw 1 f098 cru 12715138 jul 25 1525 act0707241721dat rw 1 f098 cru 435839 jul 25 1525 log0707241721dat rw 1 f098 cru 4126850 jul 25 1525 mat0707241721dat rw 1 f098 cru 6221390 jul 25 1525 tmn0707021605dtblost rw 1 f098 cru 2962918 jul 25 1525 tmn0707241721dat rw 1 f098 cru 0 jul 25 1525 tmx0702091313dtblost rw 1 f098 cru 2962918 jul 25 1525 tmx0707241721dat act0707241721dat hopefullycomplete record of all activities log0707241721dat hopefullyuseful log of odd happenings and mergeinfo trails mat0707241721dat hopefullycomplete list of all merges and pairings tmn0707021605dtblost toosmall collection of unpaired stations tmn0707241721dat toosmall output database tmx0702091313dtblost much toosmall collection of unpaired stations tmx0707241721dat toosmall but hey the same size as the twin output database analysis well lol the reason the output databases are so small is that every station looks like this 9999810 748 10932 114 sempor indonesia 1971 2000 999 99900 6190999999999999999999999999999999999999999999999999 1971 229 225 225 229 2299999 223 221 222 225 2249999 yes just one line of data the write loops went from start year to start year ho hum not as easy to fix as you might think seeing as the data may well be the result of merge and so cant just be pasted in from the source database as for the unbalanced lost files well for start the same error as above just one line of data then on top of that both sets written to the same file what time did i write that bit 3am ecch 33 so as expected im gonna have to write in clauses to make use of the log act and mat files i so do not want to do this but not as much as i dont want to do days interacting again got it to work sort of turns out i had included enough information in the act file and so was able to write auminmaxresyncfor few teething troubles but two new databases tmnx0707301343dtb created with 13654 stations in each and yes the headers are identical edit see below the final databases are tm0708071548dtb here are the header counts demonstrating that somethings still not quite right original 14355 tmn0707021605dtbheads new 13654 tmn0707301343dtbheads lostmerged 14318 tmn0707021605dtblostheads should be 143551365437 664 37 tmn0707021605dtbmergheads seems low original 14315 tmx0702091313dtbheads new 13654 tmx0707301343dtbheads lostmerged 14269 tmx0702091313dtblostheads should be 143151365446 615 46 tmx0702091313dtbmergheads seems low in fact looking at the original act file that we used crua6crucrutsversion_3_0dbdtr grep usermerg act0707241721dat wc l 258 crua6crucrutsversion_3_0dbdtr grep automerg act0707241721dat wc l 889 so will have to look at how the db12xref arrays are prepped and set in the program nonetheless the construction of the new databases looks pretty good theres aminor problem where the external reference field is sometimes 99900 and sometimes 0 not sure which is best probably 0 as the field will usually be used for reference numberscharacters rather than real data values used an inline perl command to fix after some rudimentary corrections uealogin1crucrutsversion_3_0dbdtr wc l heads 14355 tmn0707021605dtbheads 122 tmn0707021605dtblostheads 579 tmn0707021605dtbmergheads 13654 tmn0708062250dtbheads 14315 tmx0702091313dtbheads 93 tmx0702091313dtblostheads 570 tmx0702091313dtbmergheads 13654 tmx0708062250dtbheads almost perfect but unfortunately there is slight discrepancy and they have habit of being tips of icebergs if you add up the headerstation counts of the new tmin database merg and lost files you get 13654 579 122 14355 the original station count if you try the same check for tmax however you get 13654 570 93 14317 two more than the original count i suspected couple of stations were being counted twice so using comm i looked for identical headers unfortunately there werent any so i have invented two stations hmm got the program to investigate and found two stations in the crossreference array which had cross refs and merge flags error db2xref 126 127 14010 126 9596400 4110 14680 3 low head australia 2000 2006 999 91293 14010 9596900 4170 14710 150 cressy research stat australia 1971 2006 999 91306 and error db2xref13948 227 226 13948 9570600 3470 14650 145 narrandera airport australia 1971 2006 999 0 226 0 3570 14560 110 finley csiro australia 2000 2001 999 0 so in the first case low head has been merged with another station 14010 and paired with 127 similarly narrandera airport has been mreged with 226 and paired with 227 however these apparent merges are false as we see in the first case 14010 is not low head similarly for the second case looking in the relevant match file from the process mat0707241721dat we find auto merge from chain tmax stn 1 0 4110 14680 3 low head australia 2000 2006 999 99900 tmax stn 2 0 4105 14678 4 low head australia 2000 2004 999 99900 new header 0 4110 14680 3 low head australia 2000 2006 999 0 note stn 1 data overwrote stn 2 data manual pairing from chain tmin 9596400 4110 14680 3 low head australia 2000 2006 999 91293 tmax 0 4110 14680 3 low head australia 2000 2006 999 0 new header 9596400 4110 14680 3 low head australia 2000 2006 999 91293 and auto merge from chain tmax stn 1 0 3470 14650 145 narrandera airport australia 2000 2006 999 99900 tmax stn 2 9570600 3471 14651 145 narrandera airport australia 1972 1980 999 99900 new header 9570600 3470 14650 145 narrandera airport australia 1972 2006 999 0 note stn 2 data overwrote stn 1 data manual pairing from chain tmin 9570600 3470 14650 145 narrandera airport australia 1971 2003 999 0 tmax 9570600 3470 14650 145 narrandera airport australia 1972 2006 999 0 new header 9570600 3470 14650 145 narrandera airport australia 1971 2006 999 0 found the problem mistyping of an assignment and so crua6crucrutsversion_3_0dbdtr wc l heads 14355 tmn0707021605dtbheads 122 tmn0707021605dtblostheads 579 tmn0707021605dtbmergheads 13654 tmn0708071548dtbheads 14315 tmx0702091313dtbheads 93 tmx0702091313dtblostheads 568 tmx0702091313dtbmergheads 13654 tmx0708071548dtbheads phew well the headers are identical for the two new databases crua6crucrutsversion_3_0dbdtr cmp tmn0708071548dtbheads tmx0708071548dtbheads wc l 0 34 so the to the real test converting to dtr wrote tmnx2dtrfor which does exactly that it reported 233 instances where tmin tmax all set to missing values and handful where tmin tmax prob looking at the 233 illogicals most of the stations look as though considerable work is needed on them this highlights the fact that all ive done is to synchronise the tmin and tmax databases with each other and with the australian stations there is still lot of data cleansing to perform at some stage but not right now input files tmin tmn0708071548dtb tmax tmx0708071548dtb output file dtr dtr0708071924dtb cases of identical values 39 cases of min max bad 233 all illegals written to illdtr0708071924dat example of illegal values to demonstrate quality of station data station 9600100 587 9532 126 sabangcut bau id id 1984 2006 999 0 min data 2006 203 197 2009999 211 207 23399999999999999999999 max data 2006 290 299 3079999 315 309 30899999999999999999999 doesnt look very likely normals added crua6crucrutsversion_3_0dbdtr addnormline addnormline calculates monthly normals for 19611990 provided at least 75 of values are present results go into normals line coming after the header operator called if different normals exist please enter the input database dtr0708071924dtb proposed output database name dtr0708081052dat acceptreject ar output database name dtr0708081052dat derived logfile name dtr0708081052log so the final dtr database is dtr0708081052dtb and so to the main process begin quote crua6crucrutsversion_3_0primariesdtr anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required dtr select the cts or dtb file to load dtr0708081052dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto dtrtxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 3746373 659 cts 178161 31 3924534 690 process decision percent ofchk latlon 650 00 00 normal 1763302 310 310 outofrange 24 00 00 accepted 3924510 690 dumping years 19012006 to txt files end quote so lower pewrcentage than last time 690 vs 789 but then more data overall so better result 3924510 vs 3167636 gridding idl quick_interp_tdm219012006dtrglodtr750gs05pts_prefixdtrtxtdtrdumpglodumpglo convert from glo crua6crucrutsversion_3_0primariesdtr glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190landtr enter name for the gridded climatology file clim6190landtrgrid enter the path and stem of the glo files dtrglodtr enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files now concentrate addition or percentage ap right erm off i jolly well go dtr011901glo etc dtr122006glo finally gridding writing cru_ts_3_0019011910dtrdat writing cru_ts_3_0019111920dtrdat writing cru_ts_3_0019211930dtrdat writing cru_ts_3_0019311940dtrdat writing cru_ts_3_0019411950dtrdat writing cru_ts_3_0019511960dtrdat writing cru_ts_3_0019611970dtrdat writing cru_ts_3_0019711980dtrdat writing cru_ts_3_0019811990dtrdat writing cru_ts_3_0019912000dtrdat writing cru_ts_3_0020012006dtrdat writing cru_ts_3_0019012006dtrdat 35 onto the secondaries working from the rerun methodology see section 20 above began with temperature using the anomaly txt files from the halfdegree generation idl quick_interp_tdm219012006tmpbintmpbin1200gs25dumpbindumpbinpts_prefixtmp0km0705101334txttmp this produced binaries such as tmpbin1901 then precipitation idl quick_interp_tdm219012006prebinprebin450gs25dumpbindumpbinpts_prefixpre0km0612181221txtpre finally dtr idl quick_interp_tdm219012006dtrbindtrbin50gs25dumpbindumpbinpts_prefixdtrtxtdtr eeek is that 50 mistype meaning that anything using binary dtr will need redoing ral dec 07 and so to the synthetics frs idl compile crucrutsfromdpe1acodeidlprordbinpro compiled module rdbin idl compile crucrutsfromdpe1acodeidlprofrs_gts_tdmpro compiled module frs_gts idl frs_gtsdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixfrssynfrssyn idl quick_interp_tdm219012006frsgridfrsgrid750gs05dumpglodumpglonostn1synth_prefixfrssynfrssyn crua6crucrutsversion_3_0secondariesfrs glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanfrs enter name for the gridded climatology file clim6190lanfrsgrid enter the path and stem of the glo files frsgridfrsgrid enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files now concentrate addition or percentage ap right erm off i jolly well go frsgrid011901glo etc frsgrid122006glo crua6crucrutsversion_3_0secondariesfrs mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month frsgridabsfrsgridmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeefrsdat writing cru_ts_3_0019011910frsdat writing cru_ts_3_0019111920frsdat writing cru_ts_3_0019211930frsdat writing cru_ts_3_0019311940frsdat writing cru_ts_3_0019411950frsdat writing cru_ts_3_0019511960frsdat writing cru_ts_3_0019611970frsdat writing cru_ts_3_0019711980frsdat writing cru_ts_3_0019811990frsdat writing cru_ts_3_0019912000frsdat writing cru_ts_3_0020012006frsdat rd0 idl compile crucrutsfromdpe1acodeidlprordbinpro compiled module rdbin idl compile crucrutsfromdpe1acodeidlprord0_gts_tdmpro compiled module rd0_gts idl rd0_gts1901200619611990outprefixrd0synrd0synpre_prefixprebinprebin reading precip and rd0 normals compiled module strip yes filesize 6220800 gridsize 0500000 compiled module defxyz yes filesize 6220800 gridsize 0500000 compiled module days calculating synthetic rd0 normal 1961 yes filesize 248832 gridsize 250000 compiled module rd0cal 1962 yes etc 2006 yes filesize 248832 gridsize 250000 program caused arithmetic error floating divide by 0 program caused arithmetic error floating illegal operand idl as before see section 20 idl quick_interp_tdm219012006rd0gridrd0grid450gs05dumpglodumpglonostn1synth_prefixrd0synrd0syn crua6crucrutsversion_3_0secondariesrd0 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file forrtl error 69 process interrupted sigint crua6crucrutsversion_3_0secondariesrd0 mkdir rd0gridabs crua6crucrutsversion_3_0secondariesrd0 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file clim6190lanwetgrid enter the path and stem of the glo files rd0gridrd0grid enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0gridabs now concentrate addition or percentage ap right erm off i jolly well go rd0grid011901glo etc rd0grid122006glo crua6crucrutsversion_3_0secondariesrd0 mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0gridabsrd0gridmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeerd0dat writing cru_ts_3_0019011910rd0dat etc i have to admit i still dont understand secondary parameter generation ive read the papers and the miniscule amount of read documentation and it just doesnt make sense in particular why use 25 degree grids of the primaries instead of 05 why deliberately lose spatial resolution only to have to reinterpolate later matter on to vapour pressure heres the complete output from the initial binary griddingusing dtr and tmp idl vap_gts_anomdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixvapsynvapsyndumpbin1 compiled module vap_gts_anom compiled module rdbin compiled module strip compiled module defxyz landsea 56016 68400 calculating tmn normal compiled module tvap calculating synthetic vap normal compiled module esat calculating synthetic anomalies compiled module moment 1901 vap xs2 161250e05 615570e06 0160607 0222689 compiled module wrbin 1902 vap xs2 0000123188 346116e05 0268891 00261283 1903 vap xs2 686689e05 452675e06 0121429 0123995 1904 vap xs2 130788e05 183887e05 0454975 00919596 1905 vap xs2 194645e05 132224e05 0408679 00498396 1906 vap xs2 322279e05 374796e06 0178658 00261283 1907 vap xs2 256545e05 168228e05 0268768 00498040 1908 vap xs2 639573e05 349149e06 0173230 0354836 1909 vap xs2 350080e05 321530e06 0201157 00261283 1910 vap xs2 345249e05 615026e06 0130285 0144744 1911 vap xs2 399470e05 585673e06 0360082 00261283 1912 vap xs2 791931e06 106891e05 0279282 00261283 1913 vap xs2 607153e05 710663e07 00148902 00261283 1914 vap xs2 722507e05 252354e06 0130205 0124774 1915 vap xs2 211176e05 159592e05 0308456 00579963 1916 vap xs2 895735e05 241852e05 0247123 0140438 1917 vap xs2 0000105104 243058e05 0229282 0282290 1918 vap xs2 114711e05 776188e06 0248782 00261283 1919 vap xs2 251597e05 575406e06 0295303 0215085 1920 vap xs2 278549e06 181183e05 0373193 00261283 1921 vap xs2 607153e05 710663e07 00148902 00261283 1922 vap xs2 186602e05 122345e05 0275667 00261283 1923 vap xs2 576800e05 122728e06 0170021 00261283 1924 vap xs2 607153e05 710663e07 00148902 00261283 1925 vap xs2 832519e05 555618e06 0109315 0186182 1926 vap xs2 0000106602 515263e06 0105764 0206929 1927 vap xs2 523023e05 264333e06 0194649 00498040 1928 vap xs2 550934e05 247944e06 0314917 00261283 1929 vap xs2 0000524952 0000155755 0417342 0215959 1930 vap xs2 828323e05 187314e05 0328074 0193805 1931 vap xs2 780687e05 363543e05 0315060 0215417 1932 vap xs2 562579e05 381547e06 0249130 0120583 1933 vap xs2 347433e05 169009e05 0218800 0148224 1934 vap xs2 0000156604 156121e05 0173230 0152809 1935 vap xs2 669520e05 491451e06 0160529 0120391 1936 vap xs2 0000255663 663373e05 0398866 00261283 1937 vap xs2 699402e05 270766e05 0328074 0201202 1938 vap xs2 591796e05 670722e06 0215017 0155977 1939 vap xs2 488266e05 525789e06 0173294 00893239 1940 vap xs2 963896e06 745103e06 0214763 00758103 1941 vap xs2 411127e05 415525e06 0234030 00261283 1942 vap xs2 997969e05 388466e05 0288682 0148893 1943 vap xs2 838607e05 348416e06 00148902 0163562 1944 vap xs2 796681e05 791305e06 0227413 0104055 1945 vap xs2 337215e05 399524e06 0248782 00261283 1946 vap xs2 531976e05 263755e06 0128263 0163584 1947 vap xs2 0000131113 166296e05 0353903 0193758 1948 vap xs2 680941e05 162353e06 00148902 0163624 1949 vap xs2 247925e05 245819e05 0328074 0237848 1950 vap xs2 957348e05 778468e05 0366764 0726541 1951 vap xs2 654446e06 135656e05 0446058 00261283 1952 vap xs2 0000158974 502732e05 0262313 0193617 1953 vap xs2 118525e05 422691e05 0282204 0230629 1954 vap xs2 0000151975 678713e05 0373235 0230602 1955 vap xs2 0000134153 523124e05 0298578 00841820 1956 vap xs2 961671e05 520484e05 0492004 00888951 1957 vap xs2 118048e05 131769e05 0220902 00261283 1958 vap xs2 861762e06 112079e05 0207799 0148170 1959 vap xs2 827399e05 488857e06 00929929 0170919 1960 vap xs2 338773e05 153901e05 0207944 0155940 1961 vap xs2 572571e05 901807e07 00653905 00261283 1962 vap xs2 820891e05 378016e06 0240435 0126662 1963 vap xs2 0000108489 385148e05 0266356 00836364 1964 vap xs2 302043e05 637207e06 0240547 0150816 1965 vap xs2 576898e05 248022e06 0279282 0143283 1966 vap xs2 0000300312 532054e05 0622719 00261283 1967 vap xs2 643500e05 858218e07 00148902 00496181 1968 vap xs2 0000241750 422773e05 0214442 0271730 1969 vap xs2 0000568502 992260e05 0385322 00732047 1970 vap xs2 607153e05 710663e07 00148902 00261283 1971 vap xs2 215333e05 477100e06 0188071 00261283 1972 vap xs2 714160e05 356948e05 0365803 0201611 1973 vap xs2 577503e05 117079e06 0160550 00261283 1974 vap xs2 349354e05 493069e06 0149678 0144313 1975 vap xs2 614429e05 736204e07 00148902 00380432 1976 vap xs2 649657e05 325410e06 0266356 0165472 1977 vap xs2 0000107180 192804e05 0304625 0208459 1978 vap xs2 480106e05 328909e05 0285492 0105108 1979 vap xs2 0000102001 235900e05 0214390 0112952 1980 vap xs2 416963e05 270211e06 0144913 00864268 1981 vap xs2 0000274196 186668e05 00148902 0222522 1982 vap xs2 857426e07 708135e06 0161781 00831981 1983 vap xs2 584499e06 176470e05 0234194 0128289 1984 vap xs2 0000106476 297454e05 0335850 0150833 1985 vap xs2 932757e06 435533e05 0323331 0222522 1986 vap xs2 722110e05 476179e06 0141725 0185658 1987 vap xs2 227107e05 209631e05 0291446 0103599 1988 vap xs2 658090e05 921014e07 00148902 00670816 1989 vap xs2 954406e05 172599e05 0266297 0160293 1990 vap xs2 0000218826 356583e05 0174187 0236204 1991 vap xs2 593288e05 818618e07 00776650 00261283 1992 vap xs2 757687e05 427091e06 0174292 0215085 1993 vap xs2 169378e05 236942e05 0314882 00420169 1994 vap xs2 636348e05 118760e06 00148902 0163543 1995 vap xs2 0000281573 609912e05 0463574 0259426 1996 vap xs2 503362e05 547691e06 0224751 0124774 1997 vap xs2 0000132649 297693e05 0446455 0281070 1998 vap xs2 596544e07 339098e05 0359037 0201228 1999 vap xs2 591499e05 237232e06 0166206 0215985 2000 vap xs2 406034e05 461604e06 00898572 0191977 2001 vap xs2 0000138230 853512e06 00512625 0206929 2002 vap xs2 0000218003 436873e05 0760830 0282290 2003 vap xs2 700864e05 767472e06 0301868 0237875 2004 vap xs2 549200e06 213246e05 0500544 0112129 2005 vap xs2 605939e06 583817e05 0885566 0199814 2006 vap xs2 902885e05 360834e05 0455230 0607388 how very useful idea what any of that means although its heartwarming to see that its nothing like the results of the 210 rerun where 1991 looked like this 1991 vap xs2 0000493031 0000742087 00595093 186497 now of course it looks like this 1991 vap xs2 593288e05 818618e07 00776650 00261283 from this i can deduce err umm anyway now i need to use whatever vap station data we have and here im little flaky again the vap database hasnt been updated is it going to be asked dave l and he supplied summaries hed produced of climat bulletins from 20002006 slightly odd format but very useful all the same and now brief interlude as weve reached the stage of thinking about secondary variables i wondered about the climat updates as one of the outstanding work items is to write routines to convert climat and mcdw bulletins to cru format so that mergedbfor can read them so i look at climat bulletin and whats the first thing i notice its that there is absolutely station identification information apart from the wmo code none latlon name country which means that all the bells and whistles i built into mergedb though they were needed for the db merging of course are surplus to requirements the data must simply be added to whichever station has the same number at the start and theres way to check its right i dont appear to have copy of mcdw bulletin yet only pdf i wonder if thats the same anyway back to the main job as i was examining the vap database i noticed there was wet database could i not use that to assist with rd0 generation well its not documented but then none of the process is so i might as well bluff my way into it units seem to vary climat bulletins have day counts surface land climat data for 200610 missing data32768 met office hadley centre crown copyright wmo blk wmo stn stnlp mslp temp vap p days rn rain r quint sun hrs sun min_t max_t 01 001 10152 10164 5 52 9 63 2 32768 32768 12 20 dave ls climat update has days x 10 100100 7093 867 9jan mayennornavy norway 20002006 7777777 2000 150 120 180 60 150 20 30 130 120 150 70 70 the existing wet database wet0311061611dtb has days x 100 10010 7093 866 9 jan mayennor navy norway 1990 2003 999 999 6190999999999999999999999999999999999999999999999999 19909999999999999999 400 600 600 1800 1500 1100 800 1800 the published climatology has days x 100 as well tyndall centre grim file created on 13012004 at 1522 by dr tim mitchell wet wet day frequency days 05deg lan clim196190 marknew but adj so that wetpre long18000 18000 lati 9000 9000 grid xy 720 360 boxes 67420 years19751975 multi 00100 missing999 gridref 1 148 1760 1580 1790 1270 890 510 470 290 430 400 590 1160 so i guess we go with days x100 daves files will have to be reformatted anyway so its negligible overhead okaaaay wrote dave2crufor to convert dave ls climat composites to cruformat files in the appropriate units one problem is the significant number of stations without names or countries they are simply xxxxxxxxxx and im not sure how mergedb is going to take to that well only one way to find out so i converted the rain days data begin quote crua6crucrutsversion_3_0db dave2cru dave2cru convert dave l climat composites to dtb files enter the climat composite to be converted climat_mcdw_mcdw_rdy_updat_merged example data line from that file 2000 150 120 180 60 150 20 30 130 120 150 70 70 please enter factor to apply or 1 10 please enter the 3ch parameter code rd0 the output file will be rd00708151122dtb 3411 stations written end quote then tried to merge that into wet0311061611dtb and immediately hot formatting issues that pesky last field has been badly abused here taking values including 99900 000 nocode yes really had quick review of mergedb it wont be trivial to update it to treat that field as a8 so reluctantly changed all the nocode entries to 0 crua6crucrutsversion_3_0dbrd0 perl pi snocode 0g wet0311061611dt unfortunately that didnt solve the problems as there are alphanumerics in that field later on 712356 5492 11782 665 spring crk wolverine canada 1969 1988 999 307f0p9 so sigh will have to alter mergedbfor to treat that field as alpha aaarrgghhh did that next problem is best summarised with an example operator decision required 100100 7093 867 9 jan mayennornavy norway 2000 2006 999 0 this incoming station has possible match in the current database but either the wmo code or the latlon values differ incoming 100100 7093 867 9 jan mayennornavy norway 2000 2006 999 0 potential match 10010 7093 866 9 jan mayennor navy norway 1990 2003 999 999 yes the wet database features oldstyle 5digit wmo codes the best approach is probably to alter mergedb again to multiply any 5digit codes by 10 not sure if there is similar problem with 7digit codes hopefully not oh more bloody delays modified mergedb to adjust the wmo codes fine but then proper run of it just demonstrated that its far too picky even 001degree difference in coordinates required ops intervention what we need for updates is an absolute priority for wmo codes and only shout if the name or the spatial coordinates are waaay off i am seriously considering scrapping mergedb in favour of version of auminmaxresync its cloudbased approach and intelligent matching is far more efficient than mergedbs bruteforce attack as youd expect from program built on top of that knowledge and it does save all its actions but i dont know that i have the wherewithal okay i do derived newmergedbfor from auminmaxresyncfor should be fairly robust doesnt offer as many bells and whistles as mergedbfor but should be faster and more helpful all the same well it works but the data doesnt its that old devil called wmo numbering again comparing update 718000 4868 622 217 nancyessey france 2001 2002 999 0 with master 718000 4665 5306 28 cape race mars canada 1920 1969 999 999 now whats happened here well the climat numbering only gives five digits 71 800 and so an extra zero has been added to bring it up to six unfortunately thats the wrong thing to do because thats the code of cape race the sixdigit code for nancyessey is 071800 mailed phil and dl as this could be big problem many of the update stations have other metadata also noticed that some of the climat data seemed to be missing eg for nancyessey 718000 4868 622 217nancyessey france 20002006 7777777 2000999999999999999999999999999999999999999999999999 20019999 11099999999999999999999 120 150 110 130 90 2002 80 160 70 70 80 30 60 120 100 130 180 140 2003999999999999999999999999999999999999999999999999 2004999999999999999999999999999999999999999999999999 2005999999999999999999999999999999999999999999999999 2006999999999999999999999999999999999999999999999999 i have the climat bulletin for 102006 which gives data for rain days 12 in this case it doesnt seem likely that nothing was reported after 2002 i am now wondering whether it would be best to go back to the mcdw and climat bulletins themselves and work directly from those well information is always useful and i probably did know this once long ago all official wmo codes are five digits countrycountrystationstationstation however we use sevendigit codes because when official code is available we improvise with two extra digits now i cant see why we didnt leave the rest at five digits that would have been clear i also cant see why if we had to make them all seven digits we extended the legitimate fivedigit codes by multiplying by 100 instead of adding two numerically meaningless zeros at the most significant left end but thats what happened and like everything else thats the way its staying so incoming stations with wmo codes can only match stations with codes ending 00 put another way for comparison purposes any 7digit codes ending 00 should be truncated to five digits also got the locations of the original climat and mcdw bulletins climat are here httphadobsmetofficecomcrutem3datastation_updates mcdw are here ftpftp1ncdcnoaagovpubdatamcdw httpwww1ncdcnoaagovpubdatamcdw downloaded all climat and mcdw bulletins climat 012003 to 072007 mcdw 012003 to 062007 with mysterious extra called ssm0302apr211542 which turns out to be identical to ssm0302fin wrote mcdw2crufor and climat2crufor just guess what they do go on begin quote uealogin1crucrutsversion_3_0incomingmcdw mcdw2cru mcdw2cru convert mcdw bulletins to cru format enter the earliest mcdw file ssm0301fin enter the latest mcdw file or ret for single files ssm0706fin all files processed tmp0709071541dtb 2407 stations written vap0709071541dtb 2398 stations written pre0709071541dtb 2407 stations written sun0709071541dtb 1693 stations written thanks for playing byeee end quote begin quote uealogin1crucrutsversion_3_0incomingclimat climat2cru climat2cru convert mcdw bulletins to cru format enter the earliest climat file climat_data_200301txt enter the latest climat file or ret for single file climat_data_200707txt all files processed tmp0709071547dtb 2881 stations written vap0709071547dtb 2870 stations written pre0709071547dtb 2878 stations written sun0709071547dtb 2020 stations written tmn0709071547dtb 2800 stations written tmx0709071547dtb 2800 stations written thanks for playing byeee end quote of course it wasnt quite that simple mcdw has an inexplicably complex format which im sure will vary over time and eventually break the converter for instance most text is leftjustified except the month names for the overdue data which are rightjustified also there is missing value code just blank space if value is absent this necessitates reading everything as strings and then testing for content oh and small amount of rain is marked t as are small departures from the mean so moan over now we have set of updates for the secondary databases and indeed for the primary ones except that ive already processed those as updated by dave l er ah well so as im running stupidly late anyway why not find out its that imp of the perverse on my shoulder again actually as i examined all the databases in the tree to work out what was wheat and what chaff i had my awful memory jogged quite nastily we need rain days so both conversion progs will need adjusting and rerunning waaaaah and frankly at 1845 on friday evening its not gonna happen right now okay another week another razorblade to slide down modified mcdw2cru to include rain days begin quote uealogin1crucrutsversion_3_0incomingmcdw mcdw2cru mcdw2cru convert mcdw bulletins to cru format enter the earliest mcdw file ssm0301fin enter the latest mcdw file or ret for single files ssm0706fin all files processed tmp0709111032dtb 2407 stations written vap0709111032dtb 2398 stations written rdy0709111032dtb 2407 stations written pre0709111032dtb 2407 stations written sun0709111032dtb 1693 stations written thanks for playing byeee end quote checked and the four preexisting databases match perfectly with their counterparts so i didnt break anything in the adjustments and the rdy file looks good too actually the above is the final run there were numerous bugs as per begin quote uealogin1crucrutsversion_3_0incomingclimat climat2cru climat2cru convert mcdw bulletins to cru format enter the earliest climat file climat_data_200301txt enter the latest climat file or ret for single file climat_data_200707txt all files processed tmp0709101706dtb 2881 stations written vap0709101706dtb 2870 stations written rdy0709101706dtb 2876 stations written pre0709101706dtb 2878 stations written sun0709101706dtb 2020 stations written tmn0709101706dtb 2800 stations written tmx0709101706dtb 2800 stations written thanks for playing byeee end quote again existing outputs are unchanged and the new rdy file looks ok though see bracketed note above for mcdw so to the incorporation of these updates into the secondary databases oh my beginning with rain days known variously as rd0 rdy pdy this allowed to modify newmergedbfor to cope with various freedoms enjoyed by the existing databases such as sixdigit wmo codes and then when run an unexpected sideeffect of my flash correlation display thingy it shows up existing problems with the data here is the first issue encountered by newmergedb taken from the top and with my comments in anglebrackets begin quote uealogin1crucrutsversion_3_0dbrd0 newmergedb welcome to the database updater before we get started an important question should the incoming update header info and data take precedence over the existing database or even viceversa this will significantly reduce user decisions later but is big step enter u to give updates precedence m to give masters precedence x for equality u please enter the master database name wet0311061611dtb please enter the update database name rdy0709111032dtb reading in both databases master database stations 4988 update database stations 2407 looking for wmo code matches operator adjudication required in attempting to pair two stations possible data incompatibilities have been found master 221130 6896 3305 51 murmansk ex ussr 1936 2003 999 999 update 2211300 6858 3303 51 murmansk russian feder 2003 2007 999 0 correlation statistics enter c for more information 060 is minimum correlation coeff 065 is maximum correlation coeff 001 is mean correlation coeff enter to allow n to deny or an information code letter c okay so ive requested display of the lagged correlations master data correlation with update first year aligned to this year v 1936 900 600 1000 800 1000 900 1300 1700 2100 1800 900 1000 027 1937 300 1400 1300 800 1400 1800 500 1200 1600 1000 1100 1500 015 1938 900 1000 1500 1800 1200 1500 1200 1700 500 700 1600 700 013 1939 1500 1300 1100 1400 1200 1200 1000 1300 1800 1600 1100 1300 024 1940 1000 1500 1000 1200 1100 1700 2600 1500 1500 1400 1700 1100 015 1941 1800 1200 1000 1200 900 1100 900 1200 1900 1500 1000 1400 048 1942 900 900 1700 900 1600 1000 600 1100 1400 1300 700 700 051 1943 800 1000 1000 1300 900 800 1500 1600 1400 1500 1300 1200 044 1944 1000 400 900 800 1200 600 900 2000 900 1100 1000 900 032 1945 500 400 700 700 800 1800 900 1100 1200 1100 1300 700 019 1946 1200 1200 100 700 900 1200 400 900 800 1900 1300 1400 016 1947 900 1300 1300 1100 1600 1000 800 1400 1400 1700 2100 1900 009 1948 1100 1400 1400 1200 1300 1800 1200 1700 1500 2200 2100 1900 010 1949 1100 1100 500 1500 1600 1100 1500 1200 2200 2500 900 1600 004 1950 1300 800 1000 1100 1700 1200 1500 800 1100 1300 1500 1400 004 1951 1100 600 1400 1400 1500 1600 2100 1300 1500 1700 2000 1700 013 1952 2100 800 1100 1800 1300 1200 2400 2200 1600 1000 1000 2300 023 1953 2100 1400 2100 1500 900 300 1300 1700 1500 800 1200 800 024 1954 2100 600 1300 1000 1300 1700 1600 2000 1800 1300 1400 1200 040 1955 2200 1300 900 1000 1600 2000 1100 1400 1000 2100 2300 1600 020 1956 1300 1100 1300 400 1600 1300 900 1500 2000 1300 2000 1400 030 1957 1700 1600 1100 1100 1900 1900 1400 1600 1400 1700 2300 2600 027 1958 1300 2200 1900 700 1500 1200 2100 1000 1900 1700 1600 1000 021 1959 2500 1800 1300 900 900 1600 1600 1500 2200 1700 1000 900 033 1960 1800 1700 1500 400 1300 1500 400 1000 1300 1500 1000 1400 021 1961 2100 1800 2200 1500 800 1400 1600 1100 1900 1200 1200 2100 059 1962 2100 1100 1000 1500 1300 1100 1300 1700 1200 2000 1600 2300 037 1963 2100 2100 2000 1000 700 2000 1400 1800 1400 1600 2000 2400 056 1964 2400 1100 1000 1700 1100 1400 1400 1400 2000 1200 2100 1800 042 1965 1400 2100 1300 1000 1700 1700 1400 2400 1300 2100 1900 2100 041 1966 1600 1600 2000 2000 1700 1200 2000 2500 2500 2700 1600 600 034 1967 2200 1700 1600 1200 1000 1400 1600 1300 1700 1500 1200 2100 021 1968 1600 1800 1800 1800 1500 1800 1400 2100 1000 2000 2100 2000 028 1969 1100 300 1900 1200 1000 1300 1500 1200 1200 2000 1700 800 025 1970 1900 1400 1200 900 600 1200 1500 700 2300 1700 1700 2100 023 1971 2000 1300 1600 1600 1200 1100 1400 1800 2000 1600 1700 1500 039 1972 1300 1200 1300 1200 1700 800 1400 1800 1900 2000 1700 1600 026 1973 1800 1100 1700 900 1200 1500 500 1800 1200 2000 2100 2100 036 1974 1100 2400 700 1600 1300 1300 1800 2000 1900 1200 1400 2400 029 1975 1500 2200 1400 1700 2500 2200 2300 1600 1700 2300 1800 2600 047 1976 1900 800 1100 1500 1000 900 1300 1800 2200 1600 1400 1600 033 1977 1800 1400 2200 1200 1600 1900 1300 1500 1500 1900 1500 2000 040 1978 1500 1800 1400 2100 700 1000 1100 1900 1700 2300 1500 2200 024 1979 1700 1700 1700 1200 1500 1800 900 1200 1800 1600 1500 2300 039 1980 1900 1300 1300 1000 1400 900 700 1100 1300 1600 2200 1700 036 1981 2600 500 1900 2000 800 1900 1500 2000 1400 1500 1800 1600 046 1982 2200 1800 1100 1600 1500 2200 1800 1400 1700 1700 1900 1400 060 1983 2400 1900 1700 1200 800 1500 1200 2000 1400 2100 2000 2500 023 1984 1900 800 1500 2000 1100 1600 2000 1700 1100 1400 1000 1200 1985999999999999999999999999999999999999999999999999 1986999999999999999999999999999999999999999999999999 1987999999999999999999999999999999999999999999999999 1988999999999999999999999999999999999999999999999999 1989999999999999999999999999999999999999999999999999 065 199099999999999999999999 500 1300 900 700 900 1300 700 062 19919999 900 500 300 700 1000 1500 700 1700 1000 1300 1300 054 1992 800 1000 600 500 700 9009999 13009999 700 900 1200 060 1993 600 900 400 500 900 1500 1000 800 800 1000 400 1000 055 1994 1300 1000 300 600 700 1000 900 600 1200 0 1400 600 043 1995 900 900 600 700 700 900 1100 1300 600 1800 1300 500 061 1996 500 1100 400 700 700 1200 1200 1100 1100 900 1000 1400 054 1997 1200 800 1300 600 600 100 500 1100 9009999 1000 900 061 1998 1200 1300 800 1100 1100 1100 800 600 1200 1100 600 1200 052 1999 600 400 600 1000 700 700 1800 1400 700 1600 800 1200 062 2000 1100 600 1500 1700 900 1500 800 800 1000 1000 600 600 040 2001 600 500 700 700 600 500 1200 1200 700 1300 900 1000 063 2002 1000 800 1300 200 900 1100 1400 1200 1400 1800 1100 700 2003 110099999999999999999999999999999999999999999999 update data 2003 1100 700 700 500 1000 400 700 1100 1200 2100 800 1900 2004 900 700 600 600 1300 1200 1000 1200 1400 900 1000 1000 2005 1000 400 800 1100 900 600 1200 1000 1600 1000 1300 1200 2006 700 500 1300 400 600 1200 1600 700 10009999 600 1500 2007 1400 400 400 1300 1200 1200999999999999999999999999 do you see theres that ohso familiar block of missing codes in the late 80s then the data picks up again but look at the correlations on the right all good after the break decidedly dodgy before it these are two different stations arent they aaaarrrggghhhhhhh master 221130 6896 3305 51 murmansk ex ussr 1936 2003 999 999 update 2211300 6858 3303 51 murmansk russian feder 2003 2007 999 0 correlation statistics enter c for more information 060 is minimum correlation coeff 065 is maximum correlation coeff 001 is mean correlation coeff enter to allow n to deny or an information code letter end quote so should i really go to town again and allow the master database to be fixed by this program quite honestly i dont have time but it just shows the state our data holdings have drifted into who added those two series together when why untraceable except anecdotally its the same story for many other russian stations unfortunately meaning that probably there was full russian update that did data integrity checking at all i just hope its restricted to russia there are of course metadata issues too take begin quote master 206740 7353 8040 47 dikson island ex ussr 1936 2003 999 999 update 2067400 7330 8024 47 ostrov dikson russian feder 2003 2007 999 0 correlation statistics enter c for more information 070 is minimum correlation coeff 081 is maximum correlation coeff 001 is mean correlation coeff end quote this is pretty obviously the same station well ok apart from the duff early period but ive got used to that now but look at the longitude thats probably 20km luckily i selected update wins and so the metadata arent compared this is still going to take ages because although i can match wmo codes or should be able to i must check that the data correlate adequately and for all these stations there will be questions i dont think it would be good idea to take the usual approach of coding to avoid the situation because it will be nontrivial to code for and b not all of the situations are the same but i am beginning to wish i could just blindly merge based on wmo code the trouble is that then im continuing the approach that created these broken databases look at this one begin quote operator adjudication required in attempting to pair two stations possible data incompatibilities have been found master 239330 6096 6906 40 hanty mansijsk ex ussr 1936 1984 999 999 update 2393300 6101 6902 46 hantymansijsk russian feder 2003 2007 999 0 correlation statistics enter c for more information 042 is minimum correlation coeff 039 is maximum correlation coeff 002 is mean correlation coeff enter to allow n to deny or an information code letter c master data correlation with update first year aligned to this year v 1936 1400 800 1700 900 1200 800 700 800 1800999999999999 033 1937 1400 800 500 1700 1500 800 1200 1000 1700 1300 700 1200 032 1938 1000 1700 1200 1100 1100 800 800 1300 1400 1900 1800 1300 004 1939 1100 1700 1600 1800 1500 800 1500 1900 1700 1800 1300 1300 009 1940 1300 700 900 900 1800 1200 900 1300 1200 2200 1900 1800 008 1941 1400 1100 1800 1000 1400 1900 1400 700 1300 1200 1900 2000 002 1942 1700 900 1600 900 1200 1500 1300 1500 1200 1900 1500 1500 006 1943 1400 1300 1300 800 1400 1600 1300 1500 1900 2000 700 1900 017 1944 1900 1500 2000 1100 1200 1300 1500 1700 1800 1200 1500 1900 032 1945 1300 1000 1400 2100 2000 1100 1700 700 1600 1800 2300 1700 042 1946 2300 1900 1500 1100 1100 2000 1800 1000 1200 2100 2000 1800 035 1947 1900 1400 1600 1000 2100 1900 2100 1000 1200 2000 2100 1500 035 1948 1700 1500 1800 800 1300 1800 1700 1300 1800 2200 2000 2100 015 1949 2300 2100 1000 700 1600 1400 1200 800 2100 2000 1100 1400 007 1950 2100 2300 1000 1100 1500 1600 1600 2300 1900 1200 1100 1500 000 1951 1600 1000 1500 800 1500 1400 1200 600 1800 1800 1400 2400 007 1952 1600 400 1100 1300 1100 1400 800 2000 1500 2300 1300 1600 004 1953 2000 1200 1500 500 1300 1500 1100 1200 2300 2200 1600 2100 002 1954 1700 1800 700 700 1000 1300 1200 1600 2000 1800 1800 600 001 1955 2400 1400 1000 1100 1700 1200 1000 1300 1500 1300 2300 1600 008 1956 1300 800 1000 1100 1000 1000 1400 1800 1900 1900 2600 2000 029 1957 1900 1200 1700 1000 1100 1100 1100 700 800 2300 1900 2200 018 1958 1300 1600 1500 400 1500 1100 1300 1400 1900 2400 2000 1600 028 1959 1700 1600 700 1300 1700 1100 1100 1600 2000 2100 1900 1600 004 1960 1800 16009999999999999999999999999999999999999999 024 19619999999999999999999999999999 1600 1600 1700 1900 1600 033 1962 1700 800 1200 600 400 1100 900 2000 1100 1900 1700 1500 025 1963 1200 1300 1700 700 1100 1600 900 1000 1100 1400 1800 2000 004 1964 1900 500 1300 1300 1200 1200 1100 1100 1700 1500 2000 1800 013 1965 1200 1400 700 900 1200 1100 1300 1400 1800 2500 1000 1700 023 1966 1800 1600 2100 1300 1500 2100 900 1800 1500 2400 1900 800 011 1967 1600 1200 1100 600 800 1100 1100 700 1300 1200 1300 1900 039 1968 1600 1400 1600 1200 900 1300 1400 1000 1700 1300 1400 1200 024 1969 900 1000 1100 1500 1700 1700 1000 1800 1200 1400 1900 1300 004 1970 1500 1200 1600 1400 700 1600 700 1600 1000 1500 1900 1600 002 1971 1700 400 1100 1700 1300 1700 700 2000 900 2100 2000 1900 011 1972 1200 1500 1400 800 1700 1300 1700 2000 2100 1700 2500 1900 008 1973 1200 1100 1100 700 800 1300 2100 1000 2400 1900 1800 2300 011 1974 700 1200 1800 1800 1400 1200 1000 1300 1100 1600 1900 700 014 1975 2200 1800 1400 1300 1500 1500 1400 1500 1400 2300 1900 2100 015 1976 2000 1500 600 700 1100 1600 1300 1100 1500 1800 1600 1200 011 1977 1900 1700 1800 1400 1000 1100 1000 1300 1500 1800 1700 2100 015 1978 1600 1000 800 1400 1400 800 1600 1600 2300 2200 2200 1800 003 1979 1600 1600 1600 900 900 1900 1200 1700 1200 2100 1600 2000 000 1980 1600 1200 500 800 1500 1100 800 1700 1200 600 2200 2200 005 1981 2000 1000 1700 1300 1500 1100 800 400 1500 800 1500 1900 006 1982 2400 1800 1100 1200 1200 1100 1000 1700 1200 2100 1800 2000 003 1983 2500 2100 1800 1300 1400 1200 1200 1300 1300 1900 2300 1900 010 1984 1200 700 500 1300 900 800 1100 1000 1700 1600 1600 1300 update data 2003 1500 900 600 400 900 1200 500 700 1100 600 700 1500 2004 700 600 700 400 600 1100 500 900 900 1400 1500 600 2005 700 400 800 1400 300 900 800 800 900 500 1200 600 2006 800 700 900 1000 800 500 1000 500 1300 1100 700 1600 2007 1100 1100 900 700 1300 1500999999999999999999999999 end quote here the expected 19902003 period is missing so the correlations arent so hot yet the wmo codes and station names locations are identical or close what the hell is supposed to happen here oh yeah there is supposed i can make it up so i have if an update station matches master station by wmo code but the data is unpalatably inconsistent the operator is given three choices begin quote you have failed match despite the wmo codes matching this must be resolved please choose one 1 match them after all 2 leave the existing station alone and discard the update 3 give existing station false code and make the update the new wmo station enter 12 or 3 end quote you cant imagine what this has cost to actually allow the operator to assign false wmo codes but what else is there in such situations especially when dealing with master database of dubious provenance which er they all are and always will be false codes will be obtained by multiplying the legitimate code 5 digits by 100 then adding 1 at time until number is found with matches in the database this is not perfect but as there is central repository for wmo codes especially madeup ones well have to chance duplicating one thats present in one of the other databases in any case anyone comparing wmo codes between databases something ive studiously avoided doing except for tmintmax where i had to will be treating the false codes with suspicion anyway hopefully of course option 3 cannot be offered for climat bulletins there being metadata with which to form new station this still meant an awful lot of encounters with naughty master stations when really i suspect nobody else gives hoot about so with somewhat cynical shrug i added the nuclear option to match every wmo possible and turn the rest into new stations er climat excepted in other words what cru usually do it will allow bad databases to pass unnoticed and good databases to become bad but i really dont think people care enough to fix em and its the main reason the project is nearly year late and there are still wmo code problems lets try again with the issue lets look at the first station in most of the databases jan mayen here it is in various recent databases dtr0705152339dtb 100100 7093 867 9 jan mayen norway 1998 2006 999 99900 pre0709111032dtb0100100 7056 840 9 jan mayen norway 2003 2007 999 0 sun0709111032dtb0100100 7056 840 9 jan mayen norway 2003 2007 999 0 tmn0702091139dtb 100100 7093 867 9 jan mayen norway 1998 2006 999 99900 tmn0705152339dtb 100100 7093 867 9 jan mayen norway 1998 2006 999 99900 tmp0709111032dtb0100100 7056 840 9 jan mayen norway 2003 2007 999 0 tmx0702091313dtb 100100 7093 867 9 jan mayen norway 1998 2006 999 99900 tmx0705152339dtb 100100 7093 867 9 jan mayen norway 1998 2006 999 99900 vap0709111032dtb0100100 7056 840 9 jan mayen norway 2003 2007 999 0 as we can see even im cocking it up though recoverably dtr tmn and tmx need to be written as i77 anyway here it is in the problem database wet0311061611dtb 10010 7093 866 9 jan mayennor navy norway 1990 2003 999 999 you see the leading zeros been lost presumably through writing as i7 and then zero has been added at the trailing end so its 5digi wmo code but not the right one aaaarrrgghhhhhh i think this can only be fixed in one of two ways 1 by hand 2 by automatic comparison with other more reliable databases as usual im going with 2 hold onto your hats actually brief interlude to churn out the tmin tmax primaries which got sortof forgotten after dtr was done begin abridged quotes separated by anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required tmn select the cts or dtb file to load tmn0708071548dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto tmntxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 3814210 655 cts 210801 36 4025011 692 process decision percent ofchk latlon 650 00 00 normal 1793923 308 308 outofrange 976 00 00 accepted 4024035 691 dumping years 19012006 to txt files idl quick_interp_tdm219012006tmnglotmn750gs05pts_prefixtmntxttmndumpglodumpglo welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file gunzip clim6190lantmn file not found please try again clim6190lantmn enter name for the gridded climatology file clim6190lantmngrid enter the path and stem of the glo files tmnglotmn enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files tmnabs now concentrate addition or percentage ap right erm off i jolly well go tmn011901glo etc tmn122006glo welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month tmnabstmnmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeetmndat writing cru_ts_3_0019011910tmndat etc anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required tmx select the cts or dtb file to load tmx0708071548dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto tmxtxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 3795470 654 cts 205607 35 4001077 689 process decision percent ofchk latlon 652 00 00 normal 1805313 311 311 outofrange 471 00 00 accepted 4000606 689 dumping years 19012006 to txt files idl quick_interp_tdm219012006tmxglotmx750gs05pts_prefixtmxtxttmxdumpglodumpglo welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lantmx enter name for the gridded climatology file clim6190lantmxgrid enter the path and stem of the glo files tmxglotmx enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files tmxabs now concentrate addition or percentage ap right erm off i jolly well go tmx011901glo etc tmx122006glo welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month tmxabstmxmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeetmxdat writing cru_ts_3_0019011910tmxdat etc end abridged quotes this took longer than hoped running out of disk space again this is why tim didnt save more of the intermediate products which would have made my detective work easier the ridiculous process he adopted and which we have dutifully followed creates hundreds of intermediate files at every stage none of which are automatically zippedunzipped crazy ive filled 100gb disk so anyway back on earth i wrote wmocmpfor program to you guessed it compare wmo codes from given set of databases results were ah interesting begin quote report database title exact match close match vague match awful match codes added wmo 0 dbprepre0612181221dtb na na na na 14397 1540 dbdtrtmn0708071548dtb 1865 3389 57 77 5747 2519 dbtmptmp0705101334dtb 0 4 28 106 4927 0 end quote so the largest database precip contained 14397 stations with usable wmo codes and 1540 without the tmin and tmax and dtr which were tested then excluded as they matched tmin 100 database only agreed perfectly with precip for 1865 stations nearby 3389 believable 57 worrying 77 tmean fared worse with exact matches wmo misformatting again and over 100 worrying ones the big story is the need to fix the tmean wmo codes for instance 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 is illegal and needs to become one of 01001 709 87 10 jan mayen norway 1921 2006 341921 99900 0001001 709 87 10 jan mayen norway 1921 2006 341921 99900 0100100 709 87 10 jan mayen norway 1921 2006 341921 99900 i favour the first as its technically accurate alternatively we seem to have widely adopted the third which at least has the virtue of being consistent of course its the only one that will match the precip 100100 7093 867 10 jan mayen norway 1921 2006 999 99900 which itself should be either 0100100 7093 867 10 jan mayen norway 1921 2006 999 99900 or 01001 7093 867 10 jan mayen norway 1921 2006 999 99900 aaaaarrrggghhhh and the reason this is so important is that the incoming updates will rely primarily on matching the wmo codes in fact climat bulletins carry other identification of course clearly i am going to need reference set of qenuine wmo codes and wouldnt you know it ive found four location n stations notes httpweathernoaagovdatansd_bbssstxt 11548 full country names delim httpwwwhtwdresdendekleistwx_stations_cthtml 13000 10 leading zeros kept fmt probs from dave lister 13080 10 and leading zeros lost country codes from philip brohan 11894 23 countries the strategy is to use dave listers list grabbing country names from the dresden list wrote getcountrycodesfor and extracted an imperfect but usefulasareference list hopefully in the main the country will not need fixing or referring to wrote fixwmosfor probably not for the first time but its the first prog of that name in my repository so ill have to hope for the best after an unreasonable amount of teething troubles due to my forgetting that the tmp database stores lats lons in degs100 not degs10 and also to the presence of 99999 as the lon for guatemala in the reference set i managed to sortof fix the tmp database begin quote crua6crucrutsversion_3_0dbtmp fixwmos fixwmos fix wmo codes in database enter the database to be fixed tmp0705101334dtb the operation completed successfully 2263 wmo codes were fixed and all were rewritten as i77 the output database is tmp0709281456dtb crua6crucrutsversion_3_0dbtmp end quote the first records have changed as follows crua6crucrutsversion_3_0dbtmp diff tmp0705101334dtb tmp0709281456dtb head 30 1c1 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 0100100 709 87 10 jan mayen norway 1921 2006 341921 99900 so far so good but records that werent matched with the reference set didnt fare so well 89c89 10050 780 142 9 isfjord radio norway 1912 1979 101912 99900 0010050 780 142 9 isfjord radio norway 1912 1979 101912 99900 this is misleading because although there probably wont be any incoming updates for isfjord radio we cant say for certain that there will never be updates for any station outside the current reference set in fact we can say with confidence that there will be so what to do do we assume particular factor to adjust all codes by based on the matches or do we attempt note careful use of verb to use the country codes database to work out the most significant real digits of these codes well i fancy the first one well make two passes through the data the first pass changes nothing but saves counts of the successful factors in bins 001 01 1 10 100 should do it i sure hope all the results are in one bin it worked an initial verbose run showed consistent choice of factor though itll exit with an error code if multiple factors are registered in one database begin quote crua6crucrutsversion_3_0dbtmp fixwmos fixwmos fix wmo codes in database enter the database to be fixed tmp0705101334dtb locfac set to 10 first ref 0100100 the operation completed successfully 2263 wmo codes were matched all codes were modified with factor of 10 lonslats were modified with factor of 10 the output database is tmp0710011359dtb crua6crucrutsversion_3_0dbtmp end quote example results begin quote crua6crucrutsversion_3_0dbtmp diff tmp0705101334dtb tmp0710011359dtb head 12 1c1 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 0100100 7090 870 10 jan mayen norway 1921 2006 341921 99900 89c89 10050 780 142 9 isfjord radio norway 1912 1979 101912 99900 0100500 7800 1420 9 isfjord radio norway 1912 1979 101912 99900 159c159 10080 783 155 28 svalbard lufthavn norway 1911 2006 341911 99900 0100800 7830 1550 28 svalbard lufthavn norway 1911 2006 341911 99900 end quote then attacked the wet database and immediately found this beauty 0 9999 99999 999 unknown unknown 1994 2003 999 0 6190999999999999999999999999999999999999999999999999 1994 500 800 600 400 600 100 0 100 200 400 1000 1300 1995 400 100 1100 900 1200 800 200 100 200 400 800 500 1996 500 1100 1500 600 9009999 0 300 400 700 0 1100 1997 800 1000 700 1000 1000 1000 200 200 400 700 200 1000 1998 700 700 1000 10009999 800 100 100 0 200 400 700 1999 300 1000 8009999 700 800 0 2009999 600 400 200 2000 1100 600 900 900 1000 4009999 100 200 300 0 400 2001 0 800 300 500 1200 0 0 0 200 200 500 800 2002 800 300 600 1300 800 500 400 100 300 400 400 600 2003 30099999999999999999999999999999999999999999999 gotta love the system like this is ever going to be blind bit of use modified the code to leave such stations unmolested but identified in separate file so they can be cleansed it being little too risky to autocleanse such things hopefully the final attack on wet begin quote crua6crucrutsversion_3_0dbrd0 fixwmos fixwmos fix wmo codes in database enter the database to be fixed wet0311061611dtb the operation completed successfully 1920 wmo codes were matched all codes were modified with factor of 10 lonslats were modified with factor of 1 the output database is wet0710021341dtb important the following wmo codes were not altered false codes wmo0 2917 illegal codes 0wmo1000 1 illegals written to wet0311061611bad crua6crucrutsversion_3_0dbrd0 end quote i then removed the sole illegal see above from wet0710021341dtb which becomes the new old wetrd0 database so to incorporate the updates finally first the mcdw metadatarich ones begin quote uealogin1crucrutsversion_3_0dbrd0 newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw ian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name wet0710021341dtb please enter the update database name rdy0709111032dtb reading in both databases master database stations 4987 update database stations 2407 looking for wmo code matches new header 0100100 7056 840 9 jan mayen norway 1990 2007 999 999 2 rejects from update process 0710041559 writing wet0710041559dtb outputs written new master database wet0710041559dtb update database stations 2407 matched with master stations 1556 automatically 1556 by operator 0 added as new master stations 0 rejected 2 rejects file rdy0709111032dtbrejected note ieee floatingpoint exception flags raised inexact invalid operation see the numerical computation guide ieee_flags3m uealogin1crucrutsversion_3_0dbrd0 end quote also knocked up rrstatsfor at this stage to analyse replication rates by latitude band for given database needs matlab prog to drive really bit of debugging here as the last records werent being written properly filenames adjusted above accordingly then the climat nothingbutthecode ones warning ignore this the climat bulletins were later improved with metadata and newmergedb rerun begin quote uealogin1crucrutsversion_3_0dbrd0 newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name wet0710041559dtb please enter the update database name rdy0709101706dtb reading in both databases master database stations 5836 update database stations 2876 looking for wmo code matches 378 rejects from update process 0710081508 writing wet0710081508dtb outputs written new master database wet0710081508dtb update database stations 2876 matched with master stations 2498 automatically 2498 by operator 0 added as new master stations 0 rejected 378 rejects file rdy0709101706dtbrejected note ieee floatingpoint exception flags raised inexact invalid operation see the numerical computation guide ieee_flags3m uealogin1crucrutsversion_3_0dbrd0 end quote now of course we cant add any of the climat bulletin stations as new stations because we dont have any metadata so is it worth using the lookup table because although im thrilled at the high match rate 87 it does seem worse when you realise that you lost the rest see below climat metadata fixed at this stage i knocked up rrstatsfor and the visualisation companion tool cmprrm simple process to show station counts against time for each 10degree latitude band with 20degree bands at the north and south extremities bit basic and needs more work but good for quick dirty check wrote dllist2headersfor to convert the dave lister wmo list to cru header format the main difficulty being the accurate conversion of the twocharacter country codes especially since many are actually state codes for the us ended up with wmo0710151633dat as our reference wmo set incorporated the reference wmo set into climat2crufor successfully reprocessed the climat bulletins into databases with at least some metadata pre0710151817dtb rdy0710151817dtb sun0710151817dtb tmn0710151817dtb tmp0710151817dtb tmx0710151817dtb vap0710151817dtb in fact it was far more successful than i expected only 11 stations out of 2878 without metadata reran newmergedb begin quote uealogin1crucrutsversion_3_0dbrd0 newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name wet0710041559dtb please enter the update database name rdy0710151817dtb reading in both databases master database stations 5836 update database stations 2876 looking for wmo code matches 71 rejects from update process 0710161148 writing wet0710161148dtb outputs written new master database wet0710161148dtb update database stations 2876 matched with master stations 2498 automatically 2498 by operator 0 added as new master stations 307 rejected 71 rejects file rdy0710151817dtbrejected note ieee floatingpoint exception flags raised inexact invalid operation see the numerical computation guide ieee_flags3m uealogin1crucrutsversion_3_0dbrd0 end quote 307 stations rescued and theyll be there in future of course for metadatafree climat bulletins to match with so where were we rain days family tree wet0311061611dtb rdy0709111032dtb mcdw composite rdy0710151817dtb climat composite with metadata added v v wet0710161148dtb now it gets tough the current model for secondary is that it is derived from one or more primaries plus their normals plus the normals for the secondary the idl secondary generators do not allow genuine secondary data to be incorporated this would have been ideal as the gradual increase in observations would have gradually taken precedence over the primaryderived synthetics the current stats for the wet database were derived from the new proglet dtbstatsfor begin quote crua6crucrutsversion_3_0secondariesrd0 dtbstat dtbstat database stats report please enter the 18ch database name wet0710161148dtb report for wet0710161148dtb stations in northern hemisphere 5365 stations in southern hemisphere 778 total 6143 maximum timespan in northern hemisphere 1840 to 2007 maximum timespan in southern hemisphere 1943 to 2007 global timespan 1840 to 2007 crua6crucrutsversion_3_0secondariesrd0 end quote so without further ado i treated rd0 as primary and derived gridded output from the database begin quote crua6crucrutsversion_3_0secondariesrd0 anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required rd0 select the cts or dtb file to load wet0710161148dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto rd0txt select the firstlast years ad to save 19012007 operating normals mean percent stdev percent dtb 0 00 cts 731118 454 730956 454 process decision percent ofchk latlon 0 00 00 normal 878015 546 546 outofrange 56 00 00 accepted 731062 454 dumping years 19012007 to txt files crua6crucrutsversion_3_0secondariesrd0 end quote not particularly good the bulk of the data being recent less than half had valid normals anomdtb calculates normals on the fly on permonth basis however this isnt so much of problem as the plan is to screen it for valid station contributions anyway begin quote idl quick_interp_tdm219012007rd0glord0450gs05dumpglodumpglopts_prefixrd0txtrd0 compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1902 etc 2007 stations found in rd0txtrd0200708txt stations found in rd0txtrd0200709txt stations found in rd0txtrd0200710txt stations found in rd0txtrd0200711txt stations found in rd0txtrd0200712txt idl end quote begin quote crua6crucrutsversion_3_0secondariesrd0 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file clim6190lanwetgrid2 enter the path and stem of the glo files rd0glord0 enter the starting year 1901 enter the ending year 2007 enter the path if any for the output files rd0abs now concentrate addition or percentage ap this was guess well see how the results look right erm off i jolly well go rd0011901glo etc end quote then wait minute i checked back and sure enough quick_interp_tdmpro does allow both synthetic and real data to be included in the gridding from the program description begin quote tdm the dummy grid points default to zero but if the synth_prefix files are present in call the synthetic data from these grids are read in and used instead end quote and so after some confusion and renaming so that anomdtb selects percentage anomalies idl quick_interp_tdm219012006rd0pcglord0pc450gs05dumpglodumpglosynth_prefixrd0synrd0synpts_prefixrd0pctxtrd0pc the trouble is we wont be able to produce reliable station count files this way or can we use the same strategy producing station counts from the wet database route and filling in gaps with the precip station counts err begin quote crua6crucrutsversion_3_0secondariesrd0 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file climgrid enter the path and stem of the glo files rd0pcglord0pc enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0pcgloabs now concentrate addition or percentage ap p right erm off i jolly well go rd0pc011901glo etc end quote begin quote crua6crucrutsversion_3_0secondariesrd0 mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0pcgloabsrd0pcmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeerd0dat writing cru_ts_3_0019011910rd0dat writing cru_ts_3_0019111920rd0dat writing cru_ts_3_0019211930rd0dat writing cru_ts_3_0019311940rd0dat writing cru_ts_3_0019411950rd0dat writing cru_ts_3_0019511960rd0dat writing cru_ts_3_0019611970rd0dat writing cru_ts_3_0019711980rd0dat writing cru_ts_3_0019811990rd0dat writing cru_ts_3_0019912000rd0dat writing cru_ts_3_0020012006rd0dat crua6crucrutsversion_3_0secondariesrd0 end quote all according to plan except the values themselves for january 2001 minimum 0 maximum 32630 vals 31000 1 for the whole of 2001 minimum 0 maximum 56763 vals 31000 5 not good were out by factor of at least 10 though the extremes are few enough to just cap at dim so where has this factor come from well heres the january 2001 climatology minimum 0 maximum 3050 vals 3100 0 that all seems fine for percentage normals set not entirly sure about 0 though so lets look at the january 2001 gridded anomalies file minimum 48046 maximum 00129 this leads to showstopper im afraid it looks as though the calculation im using for percentage anomalies is not to put too fine point on it cobblers this is what i use to build actuals from anomalies in glo2absfor absgridiloniilati nintnormalsiimo anomsiloniilati normalsiimo 100 or to put it another way v nan100 this is what anomdtbf90 uses to build anomalies from actuals dataaxayearxmonthxastn nint10000realdataaxayearxmonthxastn realnormmeanxmonthxastn10 or in the same terms 1000vn1 which reverses to v na10001000 this could well explain things it could also mean that i have to reproduce v300 precip after its been used against my wishes by dave l and dimitrious well to start with ill try the new calculation in glo2abs to reproduce the rd0 data begin quote crua6crucrutsversion_3_0secondariesrd0 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file cgrid enter the path and stem of the glo files rd0pcglord0pc enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0pcgloabs now concentrate addition or percentage ap p right erm off i jolly well go rd0pc011901glo etc end quote this does improve matters considerably now for january 2001 minimum 0 maximum 5090 little high but not fatal vals 3100 556 vals 3500 110 vals 4000 2 so the bulk of the excessions are only few days over in fact the 2nd highest max is 4369 well below 5090 so good news but only in the sense that ive found the error bad news in that its further confirmation that my abilities are short of whats required here rushed back to precip found the glo files in crucrutsversion_3_0primariesprecippre0km0612181221glo and reran glo2abs with the revised percentage anomaly equation begin quote crua6crucrutsversion_3_0primariesprecip glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanpre enter name for the gridded climatology file clim6190lanpregridded2 enter the path and stem of the glo files pre0km0612181221glopregrid enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files pre0km0612181221abs now concentrate addition or percentage ap p right erm off i jolly well go pregrid011901glo etc end quote begin quote crua6crucrutsversion_3_0primariesprecip mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month pre0km0612181221abspregridmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeepredat writing cru_ts_3_0019011910predat writing cru_ts_3_0019111920predat writing cru_ts_3_0019211930predat writing cru_ts_3_0019311940predat writing cru_ts_3_0019411950predat writing cru_ts_3_0019511960predat writing cru_ts_3_0019611970predat writing cru_ts_3_0019711980predat writing cru_ts_3_0019811990predat writing cru_ts_3_0019912000predat writing cru_ts_3_0020012006predat crua6crucrutsversion_3_0primariesprecip end quote then back to finish off rd0 modified glo2abs to allow the operator to set minima and maxima with specific option to set wet day limits dim100 begin quote crua6crucrutsversion_3_0secondariesrd0 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file climgrid enter the path and stem of the glo files rd0pcglord0pc enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0pcgloabs now concentrate addition or percentage ap p do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum 3 set monthly minima and maxima for wetrd0 choose 3 right erm off i jolly well go rd0pc011901glo etc end quote output was checked and as expected january 2001 had 556 values of 3100 begin quote crua6crucrutsversion_3_0secondariesrd0 mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0pcgloabsrd0pcmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeerd0dat writing cru_ts_3_0019011910rd0dat writing cru_ts_3_0019111920rd0dat writing cru_ts_3_0019211930rd0dat writing cru_ts_3_0019311940rd0dat writing cru_ts_3_0019411950rd0dat writing cru_ts_3_0019511960rd0dat writing cru_ts_3_0019611970rd0dat writing cru_ts_3_0019711980rd0dat writing cru_ts_3_0019811990rd0dat writing cru_ts_3_0019912000rd0dat writing cru_ts_3_0020012006rd0dat crua6crucrutsversion_3_0secondariesrd0 end quote back to where this all started vapour pressure we have 1 master ie original database vap0311181410dtb 2 mcdw updates database vap0709111032dtb 3 climat updates database with added metadata vap0710151817dtb so first we incorporate the mcdw updates begin quote uealogin1crucrutsversion_3_0dbvap newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name vap0311181410dtb please enter the update database name vap0709111032dtb reading in both databases master database stations 7691 update database stations 2398 looking for wmo code matches 2 rejects from update process 0710241541 writing vap0710241541dtb outputs written new master database vap0710241541dtb update database stations 2398 matched with master stations 1847 automatically 1847 by operator 0 added as new master stations 549 rejected 2 rejects file vap0709111032dtbrejected uealogin1crucrutsversion_3_0dbvap end quote then the climat ones begin quote uealogin1crucrutsversion_3_0dbvap newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name vap0710241541dtb please enter the update database name vap0710151817dtb reading in both databases master database stations 8240 update database stations 2870 looking for wmo code matches 68 rejects from update process 0710241549 writing vap0710241549dtb outputs written new master database vap0710241549dtb update database stations 2870 matched with master stations 2599 automatically 2599 by operator 0 added as new master stations 203 rejected 68 rejects file vap0710151817dtbrejected uealogin1crucrutsversion_3_0dbvap end quote so not as good as the mcdw update lost 68 but then of course we are talking about station data that arrived with metadata at all so we will try the unaltered rd0 process on vap it should be the same mix of synthetic and observed priority interrupt priority interrupt priority interrupt priority interrupt after an email enquiry from wladimir j alonso alonsowmailnihgov in which unusual behaviour of cru ts 210 vapour pressure data was observed i discovered that some of the wet days and vepour pressure datasets had been swapped the files i was looking at were decadal 19811990 vapour pressure january min 0 max 310 vapour pressure february min 0 max 280 wet days january min 0 max 3220 wet days february min 0 max 3240 so i wrote crutsstatsfor whioch returns monthly and annual minima maxima and means for any gridded output file tried it on the full runs and they look ok crua6crucrutsvap_wet_investigation head 90 cru_ts_2_1019012002vapgridstats tail 10 1981 0 322 82 0 324 84 0 320 90 0 335 99 0 352 111 0 356 130 0 349 144 0 344 143 0 360 124 0 323 105 0 320 90 0 321 83 0 360 107 1982 0 312 80 0 323 83 0 318 88 0 329 98 0 348 111 0 357 126 0 365 143 0 364 140 0 355 124 0 318 105 0 321 90 0 318 84 0 365 106 1983 0 348 82 0 340 85 0 330 90 0 505 99 0 348 112 0 364 130 0 360 145 0 362 143 0 368 126 0 323 105 0 318 91 0 317 82 0 505 108 1984 0 312 80 0 320 82 0 315 89 0 329 97 0 347 112 0 359 130 0 353 144 0 343 140 0 353 122 0 324 105 0 318 89 0 316 81 0 359 106 1985 0 314 80 0 320 81 0 319 88 0 359 98 0 352 111 0 367 128 0 358 141 0 355 141 0 353 123 0 323 105 0 322 90 0 323 82 0 367 106 1986 0 312 81 0 330 83 0 316 89 0 321 99 0 366 112 0 394 129 0 371 143 0 342 139 0 354 122 0 323 104 0 318 90 0 316 82 0 394 106 1987 0 320 81 0 318 85 0 318 88 0 335 98 0 363 112 0 366 130 0 397 147 0 356 142 0 354 126 0 345 105 0 325 91 0 365 84 0 397 107 1988 0 413 83 0 324 84 0 352 90 0 323 99 0 346 113 0 363 131 0 367 148 0 358 144 0 387 126 0 342 105 0 320 89 0 315 83 0 413 108 1989 0 336 80 0 320 83 0 327 90 0 324 98 0 343 112 0 366 130 0 365 145 0 349 142 0 353 124 0 323 105 0 324 90 0 332 84 0 366 107 1990 0 320 83 0 323 85 0 476 92 0 413 101 0 361 113 0 363 132 0 371 146 0 353 143 0 371 124 0 327 106 0 318 93 0 317 84 0 476 108 crua6crucrutsvap_wet_investigation head 90 cru_ts_2_1019012002wetgridstats tail 10 1981 0 3100 1018 0 2800 919 0 3100 980 0 3000 911 0 3100 945 0 3000 1010 0 3100 1051 0 3100 1040 0 3000 981 0 3100 1017 0 3000 1021 0 3100 1003 0 3100 992 1982 0 3100 983 0 2800 894 0 3100 967 0 3000 925 0 3100 927 0 3000 941 0 3100 979 0 3100 1054 0 3000 1007 0 3100 1055 0 3000 996 0 3100 1044 0 3100 981 1983 0 3100 1035 0 2800 863 0 3100 941 0 3000 919 0 3100 929 0 3000 949 0 3100 990 0 3100 1039 0 3000 996 0 3100 1026 0 3000 1034 0 3100 1057 0 3100 982 1984 0 3100 981 0 2900 848 0 3100 920 0 3000 841 0 3100 932 0 3000 973 0 3100 1048 0 3100 1057 0 3000 1023 0 3100 1057 0 3000 992 0 3100 1016 0 3100 974 1985 0 3100 969 0 2800 896 0 3100 952 0 3000 896 0 3100 928 0 3000 938 0 3100 1057 0 3100 1043 0 3000 993 0 3100 1043 0 3000 1066 0 3100 1029 0 3100 984 1986 0 3100 988 0 2800 908 0 3100 950 0 3000 895 0 3100 922 0 3000 962 0 3100 1022 0 3100 1052 0 3000 1037 0 3100 1052 0 3000 1048 0 3100 986 0 3100 985 1987 0 3100 1011 0 2800 909 0 3100 930 0 3000 856 0 3100 954 0 3000 972 0 3100 1021 0 3100 1064 0 3000 978 0 3100 991 0 3000 1002 0 3100 1047 0 3100 978 1988 0 3100 1033 0 2900 924 0 3100 971 0 3000 903 0 3100 938 0 3000 980 0 3100 1039 0 3100 1101 0 3000 1014 0 3100 1017 0 3000 1007 0 3100 1054 0 3100 998 1989 0 3100 1019 0 2800 936 0 3100 1015 0 3000 892 0 3100 978 0 3000 1020 0 3100 1054 0 3100 1075 0 3000 1023 0 3100 1070 0 3000 1046 0 3100 1053 0 3100 1015 1990 0 3100 996 0 2800 959 0 3100 1011 0 3000 953 0 3100 928 0 3000 907 0 3100 983 0 3100 986 0 3000 915 0 3100 968 0 3000 949 0 3100 959 0 3100 960 so the monthly maxima are fine here but for the decadal files crua6crucrutsvap_wet_investigation cat cru_ts_2_1019811990vapgridstats0 1981 0 310 102 0 280 92 0 310 98 0 300 91 0 310 95 0 300 101 0 310 105 0 310 104 0 300 98 0 310 102 0 300 102 0 310 100 0 310 99 1982 0 310 98 0 280 89 0 310 97 0 300 93 0 310 93 0 300 94 0 310 98 0 310 105 0 300 101 0 310 106 0 300 100 0 310 104 0 310 98 1983 0 310 104 0 280 86 0 310 94 0 300 92 0 310 93 0 300 95 0 310 99 0 310 104 0 300 100 0 310 103 0 300 103 0 310 106 0 310 98 1984 0 310 98 0 290 85 0 310 92 0 300 84 0 310 93 0 300 97 0 310 105 0 310 106 0 300 102 0 310 106 0 300 99 0 310 102 0 310 97 1985 0 310 97 0 280 90 0 310 95 0 300 90 0 310 93 0 300 94 0 310 106 0 310 104 0 300 99 0 310 104 0 300 107 0 310 103 0 310 98 1986 0 310 99 0 280 91 0 310 95 0 300 90 0 310 92 0 300 96 0 310 102 0 310 105 0 300 104 0 310 105 0 300 105 0 310 99 0 310 99 1987 0 310 101 0 280 91 0 310 93 0 300 86 0 310 95 0 300 97 0 310 102 0 310 106 0 300 98 0 310 99 0 300 100 0 310 105 0 310 98 1988 0 310 103 0 290 92 0 310 97 0 300 90 0 310 94 0 300 98 0 310 104 0 310 110 0 300 101 0 310 102 0 300 101 0 310 105 0 310 100 1989 0 310 102 0 280 94 0 310 101 0 300 89 0 310 98 0 300 102 0 310 105 0 310 107 0 300 102 0 310 107 0 300 105 0 310 105 0 310 101 1990 0 310 100 0 280 96 0 310 101 0 300 95 0 310 93 0 300 91 0 310 98 0 310 99 0 300 91 0 310 97 0 300 95 0 310 96 0 310 96 crua6crucrutsvap_wet_investigation cat cru_ts_2_1019811990wetgridstats 1981 0 3220 819 0 3240 842 0 3200 903 0 3350 992 0 3520 1113 0 3560 1304 0 3490 1440 0 3440 1427 0 3600 1236 0 3230 1048 0 3200 898 0 3210 833 0 3600 1071 1982 0 3120 801 0 3230 827 0 3180 881 0 3290 982 0 3480 1108 0 3570 1264 0 3650 1432 0 3640 1405 0 3550 1239 0 3180 1048 0 3210 901 0 3180 835 0 3650 1060 1983 0 3480 820 0 3400 850 0 3300 898 0 5050 993 0 3480 1125 0 3640 1295 0 3600 1451 0 3620 1428 0 3680 1259 0 3230 1050 0 3180 912 0 3170 822 0 5050 1075 1984 0 3120 803 0 3200 823 0 3150 887 0 3290 971 0 3470 1124 0 3590 1299 0 3530 1437 0 3430 1404 0 3530 1218 0 3240 1053 0 3180 894 0 3160 812 0 3590 1060 1985 0 3140 803 0 3200 815 0 3190 882 0 3590 978 0 3520 1113 0 3670 1277 0 3580 1405 0 3550 1411 0 3530 1233 0 3230 1048 0 3220 900 0 3230 821 0 3670 1057 1986 0 3120 809 0 3300 827 0 3160 889 0 3210 990 0 3660 1120 0 3940 1294 0 3710 1428 0 3420 1393 0 3540 1220 0 3230 1041 0 3180 895 0 3160 821 0 3940 1061 1987 0 3200 810 0 3180 849 0 3180 880 0 3350 980 0 3630 1124 0 3660 1296 0 3970 1466 0 3560 1423 0 3540 1260 0 3450 1054 0 3250 910 0 3650 844 0 3970 1075 1988 0 4130 829 0 3240 835 0 3520 902 0 3230 989 0 3460 1133 0 3630 1311 0 3670 1475 0 3580 1441 0 3870 1264 0 3420 1054 0 3200 889 0 3150 832 0 4130 1079 1989 0 3360 804 0 3200 825 0 3270 898 0 3240 978 0 3430 1120 0 3660 1301 0 3650 1447 0 3490 1421 0 3530 1240 0 3230 1052 0 3240 900 0 3320 836 0 3660 1069 1990 0 3200 827 0 3230 853 0 4760 918 0 4130 1005 0 3610 1127 0 3630 1322 0 3710 1462 0 3530 1428 0 3710 1236 0 3270 1062 0 3180 930 0 3170 844 0 4760 1084 much confusion the orders of magnitude have changed to reflect the expected ranges but the data have clearly been swapped another decade crua6crucrutsvap_wet_investigationcat cru_ts_2_1019211930vapgridstats 1921 0 310 102 0 280 89 0 310 100 0 300 88 0 310 95 0 300 97 0 310 101 0 310 104 0 300 102 0 310 104 0 300 97 0 310 101 0 310 98 1922 0 310 95 0 280 93 0 310 97 0 300 89 0 310 95 0 300 98 0 310 105 0 310 107 0 300 98 0 310 104 0 300 102 0 310 103 0 310 99 1923 0 310 100 0 280 88 0 310 97 0 300 90 0 310 97 0 300 98 0 310 101 0 310 101 0 300 100 0 310 104 0 300 101 0 310 103 0 310 98 1924 0 310 97 0 290 89 0 310 95 0 300 90 0 310 91 0 300 97 0 310 100 0 310 102 0 300 101 0 310 102 0 300 102 0 310 100 0 310 97 1925 0 310 98 0 280 89 0 310 98 0 300 87 0 310 90 0 300 96 0 310 101 0 310 103 0 300 103 0 310 101 0 300 103 0 310 100 0 310 97 1926 0 310 99 0 280 87 0 310 95 0 300 87 0 310 95 0 300 93 0 310 103 0 310 104 0 300 99 0 310 102 0 300 102 0 310 101 0 310 97 1927 0 310 96 0 280 87 0 310 96 0 300 89 0 310 94 0 300 97 0 310 103 0 310 104 0 300 102 0 310 103 0 300 102 0 310 99 0 310 98 1928 0 310 97 0 290 89 0 310 91 0 300 88 0 310 90 0 300 96 0 310 101 0 310 104 0 300 97 0 310 99 0 300 99 0 310 96 0 310 96 1929 0 310 95 0 280 84 0 310 95 0 300 86 0 310 91 0 300 95 0 310 100 0 310 102 0 300 98 0 310 102 0 300 98 0 310 98 0 310 95 1930 0 310 98 0 280 88 0 310 97 0 300 88 0 310 93 0 300 93 0 310 99 0 310 103 0 300 99 0 310 105 0 300 101 0 310 97 0 310 97 crua6crucrutsvap_wet_investigation cat cru_ts_2_1019211930wetgridstats 1921 0 3120 805 0 3190 814 0 3140 874 0 3210 969 0 3800 1106 0 3590 1289 0 3600 1439 0 3440 1390 0 3530 1220 0 3230 1032 0 3180 877 0 3160 824 0 3800 1053 1922 0 3120 794 0 3220 813 0 3140 874 0 3210 971 0 3470 1104 0 3590 1280 0 3560 1420 0 3440 1387 0 3530 1211 0 3230 1025 0 3180 896 0 3140 812 0 3590 1049 1923 0 3070 799 0 3140 808 0 3140 871 0 3210 947 0 3460 1082 0 3660 1276 0 3560 1410 0 3440 1392 0 3530 1222 0 3230 1048 0 3180 907 0 3160 826 0 3660 1049 1924 0 3270 792 0 3230 817 0 3160 879 0 3340 955 0 3460 1094 0 3710 1264 0 3560 1415 0 3440 1386 0 3530 1228 0 3160 1034 0 3180 892 0 3140 806 0 3710 1047 1925 0 3110 786 0 3190 815 0 3140 873 0 3210 966 0 3470 1084 0 3590 1253 0 3560 1408 0 3460 1397 0 3530 1231 0 3230 1025 0 3160 896 0 3220 828 0 3590 1047 1926 0 3260 815 0 3290 842 0 3310 889 0 3310 957 0 3460 1085 0 3950 1266 0 3560 1406 0 3450 1402 0 3530 1237 0 3230 1042 0 3250 899 0 3150 811 0 3950 1054 1927 0 3120 795 0 3300 822 0 3170 873 0 3360 959 0 3540 1096 0 3610 1271 0 3550 1424 0 3450 1390 0 3530 1233 0 3230 1053 0 3180 897 0 3280 814 0 3610 1052 1928 0 3200 809 0 3240 823 0 3140 875 0 3400 963 0 3470 1095 0 3590 1263 0 3560 1425 0 3450 1397 0 3530 1228 0 3230 1039 0 3180 902 0 3160 824 0 3590 1054 1929 0 3150 794 0 3190 802 0 3160 867 0 3310 950 0 3600 1084 0 3580 1250 0 3550 1399 0 3440 1385 0 3530 1218 0 3230 1049 0 3180 897 0 3160 806 0 3600 1042 1930 0 3190 798 0 3190 824 0 3150 881 0 3210 965 0 3470 1099 0 3590 1276 0 3530 1424 0 3440 1409 0 3540 1220 0 3200 1042 0 3300 907 0 3280 829 0 3590 1056 the same story and the final two years crua6crucrutsvap_wet_investigation cat cru_ts_2_1020012002vapgridstats 2001 0 310 87 0 280 84 0 310 90 0 300 81 0 310 87 0 300 93 0 310 95 0 310 95 0 300 89 0 310 95 0 300 95 0 310 87 0 310 90 2002 0 310 91 0 280 85 0 310 92 0 300 83 0 310 88 0 300 89 0 310 93 0 310 94 0 300 92 0 310 93 0 300 88 0 310 86 0 310 90 crua6crucrutsvap_wet_investigation cat cru_ts_2_1020012002wetgridstats 2001 0 3320 834 0 3250 841 0 3180 913 0 3490 1010 0 3490 1147 0 4380 1323 0 3660 1487 0 5120 1466 0 3530 1266 0 3460 1088 0 3620 932 0 3410 843 0 5120 1096 2002 0 3310 837 0 3390 863 0 3270 918 0 3370 1012 0 3930 1151 0 4140 1339 0 3750 1503 0 5110 1453 0 3530 1261 0 3310 1067 0 3470 922 0 3300 833 0 5110 1096 it looks like consistent problem all the decadal vap and wet files should be discarded and only the full run 19012002 files used but my theory that the error occurred when the 19012002 files were converted to decadal doesnt sound true now because why would the precision levels change surely if the decadal files are derived from the 19012002 files its just case of copying data across lets look at just 1981 to try and assess this issue full 19012002 file vap 1981 0 322 82 0 324 84 0 320 90 0 335 99 0 352 111 0 356 130 0 349 144 0 344 143 0 360 124 0 323 105 0 320 90 0 321 83 0 360 107 wet 1981 0 3100 1018 0 2800 919 0 3100 980 0 3000 911 0 3100 945 0 3000 1010 0 3100 1051 0 3100 1040 0 3000 981 0 3100 1017 0 3000 1021 0 3100 1003 0 3100 992 decadal 19811990 file vap 1981 0 310 102 0 280 92 0 310 98 0 300 91 0 310 95 0 300 101 0 310 105 0 310 104 0 300 98 0 310 102 0 300 102 0 310 100 0 310 99 wet 1981 0 3220 819 0 3240 842 0 3200 903 0 3350 992 0 3520 1113 0 3560 1304 0 3490 1440 0 3440 1427 0 3600 1236 0 3230 1048 0 3200 898 0 3210 833 0 3600 1071 its evident that the data have not only been swapped theyve been scaled too aaaarrrgghhhhhh priority interrupt ends priority interrupt ends priority interrupt ends now where were we ah yes vapour pressure so far original vap0311181410dtb mcdw vap0709111032dtb v v intermediate vap0710241541dtb climat vap0710151817dtb v v final vap0710241549dtb produce anomalies begin_quote crua6crucrutsversion_3_0secondariesvap anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required vap select the cts or dtb file to load vap0710241549dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto vaptxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 908812 452 cts 35390 18 944202 470 process decision percent ofchk latlon 105 00 00 normal 1064261 530 530 outofrange 49 00 00 accepted 944153 470 dumping years 19012006 to txt files crua6crucrutsversion_3_0secondariesvap end_quote well 47 accepted 53 normals pretty much as expected and unlikely to improve matter how many new climat and mcdw updates there are we need back data for 19611990 synthetic production begin_quote idl vap_gts_anomdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixvapsynvapsyndumpbin1 compiled module vap_gts_anom compiled module rdbin compiled module strip compiled module defxyz landsea 56016 68400 calculating tmn normal compiled module tvap calculating synthetic vap normal compiled module esat calculating synthetic anomalies compiled module moment 1901 vap xs2 161250e05 615570e06 0160607 0222689 compiled module wrbin 1902 vap xs2 0000123188 346116e05 0268891 00261283 1903 vap xs2 686689e05 452675e06 0121429 0123995 etc end_quote also produced vapsynvapsyn1901 vapsynvapsyn2006 gridding with both observed and synthetic data idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynth_prefixvapsynvapsynpts_prefixvaptxtvap create absolute grids from anomaly grids begin_quote crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum 3 set monthly minima and maxima for wetrd0 choose 1 right erm off i jolly well go vap011901glo vap021901glo etc end_quote and finally create the output files begin_quote crua6crucrutsversion_3_0secondariesvap mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00ssssyyyyvapdat try again read instructions this time please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeevapdat writing cru_ts_3_0019011910vapdat writing cru_ts_3_0019111920vapdat writing cru_ts_3_0019211930vapdat writing cru_ts_3_0019311940vapdat writing cru_ts_3_0019411950vapdat writing cru_ts_3_0019511960vapdat writing cru_ts_3_0019611970vapdat writing cru_ts_3_0019711980vapdat writing cru_ts_3_0019811990vapdat writing cru_ts_3_0019912000vapdat writing cru_ts_3_0020012006vapdat end_quote ah and i was really hoping this time that it would just work but of course not nothing works first time in this project i ran crutsstats on cru_ts_3_0019012006vapdat and begin_quote crua6crucrutsversion_3_0secondariesvap crutsstats crutsstats stats for cru ts gridded files enter the monthly gridded data file cru_ts_3_0019012006vapdat please enter the start year 1901 106 years from 1901 to 2006 output file is cru_ts_3_0019012006vapdatstats 1901 1 358 106 1902 1 358 106 1903 1 358 106 1904 1 358 106 1905 1 358 106 etc 2002 1 358 106 2003 1 358 106 2004 1 358 106 2005 1 358 106 2006 1 358 106 end_quote what every year has the same min fine vap of 0 is probably impossible max i can just about believe if theres cell with stations inside the cdd and the normal for it happens to be the highest value and mean oh way whats odder the glo files are different crua6crucrutsversion_3_0secondariesvapvapabs diff vap061974gloabsnh vap061975gloabsnh wc l 56 admittedly 56 lines different out of 360 isnt hugely different and looking they are only slight and infrequent differences but the monthly stats are all cloned as well 1901 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1902 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1903 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1904 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1905 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1906 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1907 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 well the first thing to do after the inevitable wailing and gnashing of teeth is to rerun glo2abs without the zero minimum flag just in case i coded that badly i was in hurry begin_quote crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid2 enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn n right erm off i jolly well go vap011901glo vap021901glo etc end_quote begin_quote crua6crucrutsversion_3_0secondariesvap mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeevapdat writing cru_ts_3_0019011910vapdat writing cru_ts_3_0019111920vapdat writing cru_ts_3_0019211930vapdat writing cru_ts_3_0019311940vapdat writing cru_ts_3_0019411950vapdat writing cru_ts_3_0019511960vapdat writing cru_ts_3_0019611970vapdat writing cru_ts_3_0019711980vapdat writing cru_ts_3_0019811990vapdat writing cru_ts_3_0019912000vapdat writing cru_ts_3_0020012006vapdat end_quote sadly that gave the same result so what of the published v210 vap dataset that looks ok begin_quote crua6crucrutsversion_3_0secondariesvap crutsstats crutsstats stats for cru ts gridded files enter the monthly gridded data file cru_ts_2_1019012002vapgrid please enter the start year 1901 102 years from 1901 to 2002 output file is cru_ts_2_1019012002vapgridstats 1901 0 411 105 1902 0 413 104 1903 0 465 104 1904 0 359 104 1905 0 383 104 1906 0 376 105 1907 0 387 104 etc end_quote not good at all or rather good that it must be solvable problem except that its 10 to 5 on sunday afternoon and its thats got to solve it where to start well retrace your steps thats how you get out of minefield so first up to compare similar months in the anomaly files though i already know what im going to find dont i because glo2abs isnt going to do anything unusual it just adds the normal and there you go so if the absolutes are very similar the anomalies will be too hmm well i suppose i could try producing two more copies of the output files one with just synthetic data and one with just observed data its only couple of reruns of the quick_interp_tdm2pro idl routine started with the syntheticonly run begin_quote idl quick_interp_tdm219012006vapsynglovapsyn1000gs05dumpglodumpglonostn1synth_prefixvapsynvapsyn crua6crucrutsversion_3_0secondariesvapsyn_only glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid enter the path and stem of the glo files vapsynglovapsyn enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapsynabs now concentrate addition or percentage ap do you wish to limit the output values yn n right erm off i jolly well go vapsyn011901glo vapsyn021901glo etc crua6crucrutsversion_3_0secondariesvapsyn_only mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapsynabsvapsynmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeevapsyndat writing cru_ts_3_0019011910vapsyndat writing cru_ts_3_0019111920vapsyndat writing cru_ts_3_0019211930vapsyndat writing cru_ts_3_0019311940vapsyndat writing cru_ts_3_0019411950vapsyndat writing cru_ts_3_0019511960vapsyndat writing cru_ts_3_0019611970vapsyndat writing cru_ts_3_0019711980vapsyndat writing cru_ts_3_0019811990vapsyndat writing cru_ts_3_0019912000vapsyndat writing cru_ts_3_0020012006vapsyndat end_quote and then the observedonly begin_quote idl quick_interp_tdm219012006vapobsglovapobs1000gs05dumpglodumpglopts_prefixvaptxtvap crua6crucrutsversion_3_0secondariesvapobs_only glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid enter the path and stem of the glo files vapobsglovapobs enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapobsabs now concentrate addition or percentage ap do you wish to limit the output values yn n right erm off i jolly well go vapobs011901glo vapobs021901glo etc crua6crucrutsversion_3_0secondariesvapobs_only mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapobsabsvapobsmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeevapobsdat writing cru_ts_3_0019011910vapobsdat writing cru_ts_3_0019111920vapobsdat writing cru_ts_3_0019211930vapobsdat writing cru_ts_3_0019311940vapobsdat writing cru_ts_3_0019411950vapobsdat writing cru_ts_3_0019511960vapobsdat writing cru_ts_3_0019611970vapobsdat writing cru_ts_3_0019711980vapobsdat writing cru_ts_3_0019811990vapobsdat writing cru_ts_3_0019912000vapobsdat writing cru_ts_3_0020012006vapobsdat end_quote so how do the stats look for these two datasets syntheticonly begin_quote crua6crucrutsversion_3_0secondariesvapsyn_only crutsstats crutsstats stats for cru ts gridded files enter the monthly gridded data file cru_ts_3_0019012006vapsyndat please enter the start year 1901 106 years from 1901 to 2006 output file is cru_ts_3_0019012006vapsyndatstats 1901 1 358 106 1902 1 358 106 1903 1 358 106 1904 1 358 106 1905 1 358 106 1906 1 358 106 etc end_quote observedonly begin_quote crua6crucrutsversion_3_0secondariesvapobs_only crutsstats crutsstats stats for cru ts gridded files enter the monthly gridded data file cru_ts_3_0019012006vapobsdat please enter the start year 1901 106 years from 1901 to 2006 output file is cru_ts_3_0019012006vapobsdatstats 1901 1 358 106 1902 1 358 106 1903 1 358 106 1904 1 358 106 1905 1 358 106 1906 1 358 106 etc end_quote oh god what is going on are we data sparse and just looking at the climatology how can synthetic dataset derived from tmp and dtr produce the same statistics as an real dataset derived from observations lets be logical here are the two separated gridding runs idl quick_interp_tdm219012006vapsynglovapsyn1000gs05dumpglodumpglonostn1synth_prefixvapsynvapsyn idl quick_interp_tdm219012006vapobsglovapobs1000gs05dumpglodumpglopts_prefixvaptxtvap well they look fine the synthetic run has other data inputs nostn1 and the observed run has references to the synthetic data so either quick_interp_tdm2pro is doing something unusual or or hang on lets try the climatology for stats 1961 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 ah bingo was his nameo as i was hoping well ok its bad kind of hope the reason its all the same is that it is by and large defaulting to the climatology which means that not much any data is getting through matter if we use synthetic observed or both together whats odd about that conclusion is that the synthetic data is derived from tmp and dtr two very wellpopulated datasets so synthetics alone should pretty much fill the hang on just though of something horrendous oh okay probably not that i was wondering if glo2absfor was factoring the normals so that the anomalies were insignificant but the equation is absgridiloniilati nintanomsiloniilati10 normalsiimo so the anomaly is getting the weight but still not wise thing to leave to automatics so glo2abs should prompt the user but with what just one anomaly and normal several the same one from different timesteps eeek lets look at this actual case january 1961 lines 11103 11104 in the glo file 11099 11100 without header putting it on about 335 degs n 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 47173e04 47224e03 54273e03 61323e03 68372e03 75422e03 82472e03 19677e03 00000e00 00000e00 those anomalies are mighty tiny given that the absolutes are threedigit integers hardly surprising theyre not really appearing on the radar when added to normals typically two orders of magnitude higher even with the 10 in the glo2abs prog were still looking at values around 006 looked at the observed anomalies output from anomdtbf90 here the anomalies are larger between 5 and 5 roughly which is what im used to seeing in txt files to investigate the synthetics i needed to look at rerun vap_gts_tdmpro it says note that anomalies are in hpa10 bin or hpa glo so the binary file anomaly units the ones were using are in hpa10 lets get one them synthetic glo files idl vap_gts_anomdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19611961outprefixvapsynglovapsyndumpglo1 landsea 56016 68400 calculating tmn normal compiled module tvap calculating synthetic vap normal compiled module esat calculating synthetic anomalies compiled module moment 1961 vap xs2 572571e05 901807e07 00653905 00261283 compiled module saveglo compiled module selectmodel for jan 1961 may as well stick with it 999 is the missing value code the range is 00149 to 00222 remember this is an anomaly in hpa according to the program comment so if its telling the truth the binary anomalies presented to quick_interp_tdm2pro will range from roughly 03 to 03 still nt going to impinge on normals between 1 and 358 is it so what are the normals in well according to clim6190lanvap crua6crucrutsversion_3_0secondariesvap head 11 clim6190lanvap tyndall centre grim file created on 12012004 at 1147 by dr tim mitchell vap vapour pressure hpa 05deg lan clim196190 marknew long18000 18000 lati 9000 9000 grid xy 720 360 boxes 67420 years19751975 multi 01000 missing999 gridref 1 148 291 294 296 293 287 279 265 262 271 279 286 287 gridref 1 311 14 11 13 21 44 69 92 90 65 37 22 14 gridref 1 312 13 10 12 20 43 67 90 87 63 35 21 13 thats what ive been missing doh that multi 01000 that would still only give range of 01 to 358 hpa and my anomalies are still around 0006 or 03 for synthetics two things then firstly to get glo2abs to read the multiplicative factor from the climatology header and impose it on the output secondly to work out why all the anomalies have different magnitudes or is vapour pressure really so teeny working on glo2abs well my theory for additive anomalies is this i read in the normals and apply the multiplicative factor in the header for vap its 01 i assume the anomalies are already in the relevant units ie require factoring this looks to be the case for txt files anyway so i can add the anomaly to the adjusted normal then because i need integer output i can divide by the factor because that got us from integer to real before fine in theory but it all depends on the anomalies being in regular units why wouldnt they be theyre reals ok check from the beginning obs first database hpa10 typically 3digit integers anomdtbfor calls subroutine checkvarisuffix which contains begin_quote else if suffixeqvap then variablevapour pressure hpa factor 01 end_quote and how does anomdtbf90 use the factor well in the original version begin_quote crua6crucrutsuntouchedcodelinuxcruts grep factor anomdtbf90 real missthreshstdevthreshdistancethreshfactor exespacewyespace call checkvarisuffix loadsuffixvariablefactor optot optot realdataaxayearxmonthxastnfactor optotsq optotsq realdataaxayearxmonthxastnfactor 2 normmean xmonthxastn factoroptotopen if optotsqgt0 normstdev xmonthxastn factorsqrtoptotsqopenoptotopen2 optot optot realdataaxayearxmonthxastnfactor optotsq optotsq realdataaxayearxmonthxastnfactor 2 normmean xmonthxastn factoroptotopen normstdev xmonthxastn factorsqrtopenopen1optotsqopenoptotopen2 optot optot dataaxayearxmonthxastnfactor optotsq optotsq dataaxayearxmonthxastnfactor 2 opstdev factorsqrtopenopen1optotsqopenoptotopen2 opmean factoroptotopen alatxastnalonxastnaelvxastnrealdataaxayearxmonthxastnfactorastnxastn end_quote i think the factor is being used multiplicatively i dont understand why its being used as divisor though i must have understood last december because i managed to rewrite the standard deviation section also using it as divisor one obvious thing to try is to use the revised glo2abs that should now be working in units but saving in whatever range the normals are in after that i could try comparing the old and new ie modded by versions of anomdtbf90 to ensure i didnt break something sure i didnt but still so i revised glo2abs it now reads the multi factor from the climatology header and applies it to the normals before theyre used so reran quick_interptdm2pro idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynth_prefixvapsynvapsynpts_prefixvaptxtvap sample of the outputs vap121962glo had range of values from 23006 to 18388 with the majority being 0 total of 56387 cells were nonzero which given that there are 67420 land cells isnt too bad its pretty gaussian distribution too it still seems like small variation typically 05 for the cell where i live norwich 363286 the normals are gridref 363 286 71 69 76 86 107 129 147 149 135 115 88 77 or in hpa gridref 363 286 71 69 76 86 107 129 147 149 135 115 88 77 the nearest station well based on quick search is lowestoft taking 1962 and 1963 and scaling 62 76 69 65 92 109 126 144 150 136 123 89 65 63 54 55 79 99 111 148 158 151 146 117 103 69 the ranges 22 14 14 07 02 22 14 01 10 06 14 04 well our sample december 1962 range of anomalies was 23006 to 18388 and the january range is 33640 to 21250 so i have to admit thats the same order of magnitude for our particular cell year and months so assuming these glo files are ok well try glo2abs again begin_quote crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file deleteme1 enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum 3 set monthly minima and maxima for wetrd0 choose 1 right erm off i jolly well go vap011901glo vap021901glo etc end_quote and the result look good for again december 1962 min 0 well i did set that see above max 315 number of zeros 1078 perfectly respectable although i do wonder if vap0 is illegal hmm ok added an option in glo2abs begin_quote crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file deleteme3 enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum 3 set monthly minima and maxima for wetrd0 4 set all values 0 ie positive choose 4 right erm off i jolly well go vap011901glo vap021901glo etc end_quote result for december 1962 min 1 max 315 good spread of values without disproportionate number of 1s im please to say so to generate the output files again begin_quote crua6crucrutsversion_3_0secondariesvap mergegrids welcome this is the mergegrids program i will create decadal and full gridded files from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee cru_ts_3_00sssseeeevapdat writing cru_ts_3_0019011910vapdat writing cru_ts_3_0019111920vapdat writing cru_ts_3_0019211930vapdat writing cru_ts_3_0019311940vapdat writing cru_ts_3_0019411950vapdat writing cru_ts_3_0019511960vapdat writing cru_ts_3_0019611970vapdat writing cru_ts_3_0019711980vapdat writing cru_ts_3_0019811990vapdat writing cru_ts_3_0019912000vapdat writing cru_ts_3_0020012006vapdat end_quote and what of the statistics well by now ive realised that we dont have complete coverage so the normals are bound to poke through quite bit in fact the story is as it was in the beginning cries begin_quote crua6crucrutsversion_3_0secondariesvap crutsstats crutsstats stats for cru ts gridded files enter the monthly gridded data file cru_ts_3_0019012006vapdat please enter the start year 1901 106 years from 1901 to 2006 output file is cru_ts_3_0019012006vapdatstats 1901 1 358 106 1902 1 358 106 1903 1 358 106 1904 1 358 106 1905 1 358 106 1906 1 358 106 1907 1 358 106 1908 1 358 106 etc end_quote now admittedly the 106 mean does vary it hioits the dizzying heights of 107 on occasion with couple of 105s thrown in to balance the books had look at the stats in detail compared to those for cru ts 210 and guess what yes the old stats are better heres the first decade cru ts 210 1901 0 324 79 0 338 82 0 314 88 0 321 97 0 411 110 0 378 128 0 358 143 0 343 140 0 353 122 0 332 103 0 318 88 0 314 81 0 411 105 1902 0 312 80 0 319 82 0 314 87 0 321 96 0 413 109 0 366 125 0 356 141 0 343 138 0 353 122 0 323 102 0 318 88 0 315 80 0 413 104 1903 0 314 79 0 331 82 0 315 88 0 334 95 0 465 109 0 359 125 0 371 141 0 359 139 0 353 122 0 323 102 0 318 88 0 315 80 0 465 104 1904 0 310 78 0 319 81 0 312 86 0 321 95 0 347 109 0 359 126 0 355 140 0 344 138 0 354 121 0 323 103 0 318 89 0 316 81 0 359 104 1905 0 314 79 0 319 79 0 321 86 0 326 95 0 346 109 0 383 127 0 356 142 0 344 139 0 353 122 0 330 103 0 318 90 0 321 82 0 383 104 1906 0 328 80 0 330 81 0 323 87 0 335 98 0 376 111 0 359 128 0 356 142 0 343 140 0 353 122 0 323 103 0 318 89 0 316 82 0 376 105 1907 0 312 79 0 327 80 0 314 87 0 321 94 0 387 106 0 359 125 0 379 140 0 343 139 0 353 122 0 323 104 0 318 87 0 316 81 0 387 104 1908 0 312 79 0 323 81 0 330 86 0 338 95 0 346 109 0 359 127 0 353 142 0 343 138 0 353 122 0 316 102 0 318 87 0 316 81 0 359 104 1909 0 312 79 0 319 81 0 323 87 0 321 94 0 346 107 0 359 125 0 355 141 0 343 140 0 354 122 0 320 103 0 318 90 0 316 81 0 359 104 1910 0 312 80 0 319 82 0 315 86 0 321 95 0 347 109 0 359 126 0 383 142 0 343 139 0 353 122 0 318 102 0 318 87 0 316 80 0 383 104 cru ts 300 1901 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1902 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1903 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1904 1 311 80 1 320 82 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1905 1 311 80 1 320 83 1 315 88 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1906 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1907 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 141 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1908 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 129 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1909 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 1910 1 311 80 1 320 83 1 315 89 1 320 98 1 346 111 1 358 128 1 356 143 1 342 140 1 354 123 1 323 104 1 318 90 1 315 82 1 358 106 and heres more recent decade cru ts 210 1991 0 314 82 0 322 84 0 331 90 0 672 100 0 523 113 0 540 134 0 607 147 0 424 143 0 353 125 0 328 106 0 386 91 0 350 83 0 672 108 1992 0 337 82 0 383 84 0 450 90 0 613 98 0 347 112 0 359 128 0 373 140 0 345 140 0 353 122 0 347 103 0 414 89 0 384 83 0 613 106 1993 0 324 81 0 403 83 0 449 90 0 622 98 0 518 113 0 534 131 0 652 147 0 398 143 0 353 122 0 333 105 0 408 89 0 339 84 0 652 107 1994 0 346 82 0 396 82 0 457 90 0 626 100 0 524 113 0 507 132 0 605 146 0 416 143 0 349 125 0 332 107 0 397 93 0 341 84 0 626 108 1995 0 369 83 0 406 86 0 461 90 0 686 100 0 505 114 0 565 134 0 673 146 0 492 147 0 364 127 0 342 108 0 427 91 0 339 82 0 686 109 1996 0 334 81 0 431 83 0 548 88 0 634 97 0 524 113 0 530 131 0 645 147 0 422 142 0 366 124 0 337 106 0 413 91 0 344 84 0 645 107 1997 0 367 82 0 322 84 0 348 90 0 323 99 0 344 113 0 484 133 0 426 147 0 523 145 0 353 126 0 348 108 0 345 93 0 370 86 0 523 109 1998 0 339 84 0 345 89 0 338 92 0 355 104 0 361 116 1 531 137 1 356 152 0 560 149 0 370 128 0 347 108 0 369 92 0 334 85 0 560 111 1999 0 323 83 0 334 86 0 324 90 0 336 100 0 362 113 0 487 132 0 362 148 0 357 143 1 353 127 0 331 107 0 337 91 0 316 85 0 487 109 2000 0 319 82 0 319 85 0 319 91 0 328 102 0 356 114 0 476 133 0 358 146 0 520 146 0 353 124 0 333 107 0 335 91 0 334 84 0 520 109 cru ts 300 1991 1 311 81 1 320 83 1 320 90 1 320 100 1 346 113 1 358 132 1 356 146 1 342 143 1 354 125 1 323 105 1 318 91 1 315 82 1 358 108 1992 1 311 82 1 319 84 1 315 90 1 320 97 1 346 111 1 358 127 1 356 141 1 342 140 1 354 122 1 323 102 1 317 89 1 315 83 1 358 106 1993 1 313 81 1 315 83 1 315 89 1 320 98 1 346 112 1 358 131 1 356 146 1 342 142 1 354 122 1 323 103 1 323 88 1 317 83 1 358 106 1994 1 311 82 1 322 82 1 315 89 1 320 99 1 346 112 1 358 131 1 356 146 1 346 142 1 354 125 1 323 106 1 318 92 1 315 83 1 358 107 1995 1 311 82 1 318 85 1 320 90 1 324 99 1 346 112 1 358 131 1 356 146 1 345 144 1 354 124 1 323 107 1 321 90 1 315 81 1 358 108 1996 1 311 80 1 321 82 1 320 87 1 320 96 1 346 111 1 358 130 1 356 145 1 343 141 1 354 122 1 323 105 1 318 90 1 319 82 1 358 106 1997 1 311 81 1 320 84 1 315 90 1 320 99 1 346 113 1 358 131 1 356 145 1 342 143 1 354 123 1 323 106 1 318 90 1 315 83 1 358 107 1998 1 311 81 1 334 85 1 326 89 1 338 100 1 346 114 1 358 134 1 356 148 1 342 145 1 354 125 1 323 105 1 318 89 1 315 84 1 358 108 1999 1 316 82 1 320 85 1 322 88 1 320 99 1 346 112 1 358 131 1 356 148 1 342 142 1 354 125 1 323 106 1 318 91 1 315 84 1 358 108 2000 1 317 82 1 320 84 1 315 90 1 320 100 1 346 113 1 358 131 1 356 146 1 342 144 1 354 123 1 323 105 1 318 90 1 315 83 1 358 108 i dont understand well ok i see that vap of zero is acceptable though as its pressure i dont believe it ill stick with 1 the issue is that the earlier dataset has variability in the maximum that we just dont have in the new one and i feel that ive been through every bloody phase of the process and checked were doing it right right lets look at the distributions of values in each dataset well take jan 1910 and jun 2000 and as this is textual document ill have to describe the results offsets well each month has 360 lines so each year has 4320 lines so for jan 1910 we need to skip nine years or 38880 lines then take the next 360 for jun 2000 we need to skip 99 years or 427680 lines then another five months or 1800 lines then take the next 360 so head 39240 cru_ts_21019012002vapdat tail 360 cru_ts_210jan1910vapdat head 39240 cru_ts_30019012006vapdat tail 360 cru_ts_300jan1910vapdat head 428040 cru_ts_21019012002vapdat tail 360 cru_ts_210jun2000vapdat head 428040 cru_ts_3_0019012006vapdat tail 360 cru_ts_3_00jun2000vapdat i loaded the resultant monthly files into matlab and played with them mercilessly well to start with they all look the same truly ive got 4plot page with ts 210 in the lefthand column and ts 300 on the right january 1910 on the top june 2000 on the bottom and they look pretty much inseparable though if i had to spot the difference the ts 210 june 2000 distribution is little flatter that is the massive spike at the low end is little shorter and the rest of the entourage are little taller what are particularly worthy of note are the maximums because they dont match those produced by crutsstatsfor month model max matlab max crutsstats jan 1910 ts 210 312 312 jan 1910 ts 300 311 311 jun 2000 ts 210 319 476 jun 2000 ts 300 317 358 not entirely sure why the latter ones would be wrong but i suspect crutsstats because otherwise i miscounted the line numbers to extract june 2000 with actually ok that does seem more likely lets try it from the 19912000 files the offset will be 94320 5360 360 41040 gunzip c crucrutsfromtyn1datacru_ts_210newly_griddeddata_deccru_ts_2_1019912000vapgridgz head 41040 tail 360 cru_ts_2_10jun2000vapdat gunzip c cru_ts_3_0019912000vapdatgz head 41040 tail 360 cru_ts_3_00jun2000vapdat well looks like i did miscount because the new files are different and so are the maxima month model max matlab max crutsstats jun 2000 ts 210 300 476 jun 2000 ts 300 358 358 so almost perfect at least the stats for the file im creating match and now the june 2000 histograms are much more interesting and of course for this is this project much more worrying the june 2000 plot for the new data 300 shows fall at vap 0 this is in contrast to the other three which show more expotential decline from high near 0 though admittedly the 210 version does have second peak at around 120 in fact the june 2000 300 series has peaks at 90 and 300 oh help the big question must be why does it have so little representation in the low numbers especially given that im rounding erroneous negatives up to 1 oh sod it itll do i dont think i can justify spending any longer on dataset the previous version of which was completely wrong misnamed and nobody noticed for five years so one week to go before handover and im just starting the suncloud parameter the one i thought would cause the most trouble oh boy lets try and work out the scenario historically weve issued cloud crua6crucrutsfromtyn1datacru_ts_210data_all gunzip c cru_ts_2_1019012002cldz head 10 tyndall centre grim file created on 22012004 at 1352 by dr tim mitchell cld cloud cover percentage cru ts 21 long18000 18000 lati 9000 9000 grid xy 720 360 boxes 67420 years19012002 multi 01000 missing999 gridref 1 148 725 750 750 700 638 600 613 613 663 675 713 725 so data is in x10 then of course theres the relevant read_me text from crucrutsfromdpe1acodeidlproread_me_griddingtxt bear in mind that there is working synthetic method for cloud because mark new lost the coefficients file and never found it again despite searching on tape archives at uea and never recreated it this hasnt mattered too much because the synthetic cloud grids had not been discarded for 190195 and after 1995 sunshine data is used instead of cloud data anyway so thats alright then see also the earlier attempts to recreate ts 210 cloud the main gridding prog for cloud appears to be cal_cld_gts_tdmpro pro cal_cld_gts_tdmdtr_prefixoutprefixyear1year2infoinfo calculates cld anomalies using relationship with dtr anomalies reads coefficients from predefined files 1000 reads dtr data from binary output files from quick_interp_tdm2pro binfac1000 creates cld anomaly grids at dtr grid resolution output can then be used as dummy input to splining program that also includes real cloud anomaly data as for converting sun hours to cloud cover we only appear to have interactive filebyfile programs herewith all the relevant progs i can find idl idlprocal_cld_gts_tdmpro synthetic cloud from dtr idlprocloudcorrpro construct cloud correlation coefficients with dtr idlprocloudcorrspcpro construct cloud correlation coefficients with sunshine idlprocloudcorrspcannpro construct cloud correlation coefficients with sunshine idlprocloudcorrspcann9196pro construct cloud correlation coefficients with sunshine the ann versions above include the assumption that the relationships remain constant through the year f77 f77mnewsh2cld_tdmfor this one needs to be modded as for sp2cldp_mfor i think f77mnewhsp2cldp_mfor one i wrote last year which seems to almost do what we need f77mnewsp2cld_mfor this one needs to be modded as for sp2cldp_mfor i think f77mnewsh2sp_mfor f77mnewsh2sp_normalfor f77mnewsh2sp_tdmfor aaaand another headbanging shocker the program sh2cld_tdmfor which describes itself thusly program sunh2cld c converts sun hours monthly time series to cloud percent nn does such thing instead it creates sun percentages this is clear from the variable names and user interactions so if i add the sunh sun process from sh2cld_tdmfor into hsp2cldp_mfor i should end up with sun hours to cloud percent convertor possibly except that the sun to cld engine looks like its creating oktas instead do im112 ratio realsunpim100 if ratioge095 cldpim 0 if ratiolt095andratioge035 cldpim 095ratio100 if ratiolt035andratioge015 cldpim 035ratio5060 if ratiolt015 cldpim 015ratio10070 if cldpimgt800 cldpim 800 if ratiolt0 cldpim 9999 enddo added the previous 125 mod to approximate true percentages 10 looking back i see we found cloud and sunpercent databases line counts shown 228936 cld0301081434dtb 104448 cld0312181428dtb 111989 comboclddtb 57395 spc0301201628dtb 51551 spc0312221624dtb 51551 spc94000312221624dtb and agreed strategy begin_quote agreed approach for cloud 5 oct 06 for 1901 to 1995 stay with published data clear way to replicate process as undocumented for 1996 to 2002 1 convert sun database to pseudocloud using the f77 programs 2 anomalise wrt 9600 with anomdtbf 3 grid using quick_interp_tdmpro which will use 6190 norms 4 calculate mean9600 mean6190 for monthly grids using the published cru_ts_20 cloud data 5 add to gridded data from step 3 this should approximate the correction needed end_quote this is confusing i can only use one observed cloud database in the final gridding the above agreement seems to assume that all data after 1996 will come from sun but dtbstatfor reports begin_quote report for spc0312221624dtb its similar for the other spcs except the earlier one goes to 2002 stations in northern hemisphere 1750 stations in southern hemisphere 350 total 2100 maximum timespan in northern hemisphere 1889 to 2003 maximum timespan in southern hemisphere 1944 to 2003 global timespan 1889 to 2003 minimum data value 0 maximum data value 1000 end_quote so the sun percent databases run for long periods similarly for cloud begin_quote report for cld0312181428dtb stations in northern hemisphere 3286 stations in southern hemisphere 319 total 3605 maximum timespan in northern hemisphere 1905 to 1996 maximum timespan in southern hemisphere 1959 to 1996 global timespan 1905 to 1996 minimum data value 0 maximum data value 1000 end_quote not as long run and it sure ends at 1996 so 1901 to 1995 will as agreed remain untouched well lets try converting the mcdw and climat sun hours to sun percents then adding to the spc database spc0312221624dtb modified hsh2cld for to save sun percent too lots of debugging eventually dug out doorenbos j pruitt wo 1977 guidelines for predicting crop water requirements fao irrigation and drainage paper 24 food and agriculture organization of the united nations rome this was used to inform the fortran conversion programs by indicating the latitudepotential_sun and suntocloud relationships it also assisted greatly in understanding what was wrong tim was in fact calculating cloud percent despite calling it sun percent just awful and so begin_quote crua6crucrutsversion_3_0dbcld hsh2cld hsh2cld convert sun hours database to cloud percent one please enter the sun hours database sun0709111032dtb data factor detected 1000 completed 1693 stations converted sun percentage database spc0711271420dtb cloud percentage database cld0711271420dtb crua6crucrutsversion_3_0dbcld hsh2cld hsh2cld convert sun hours database to cloud percent one please enter the sun hours database sun0710151817dtb data factor detected 0100 completed 2020 stations converted sun percentage database spc0711271421dtb cloud percentage database cld0711271421dtb crua6crucrutsversion_3_0dbcld end_quote so now the luxury of little experiment i merged the mcdw and climat spc databases into the existing one separately here were the results mcdw begin_quote uealogin1crucrutsversion_3_0dbcld newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name spc0312221624dtb please enter the update database name spc0711271420dtb reading in both databases master database stations 2100 update database stations 1693 new master database spc0711271504dtb update database stations 1693 matched with master stations 867 automatically 867 by operator 0 added as new master stations 826 rejected 0 end_quote climat begin_quote enter b for blind merging or ret b please enter the master database name spc0312221624dtb please enter the update database name spc0711271421dtb reading in both databases master database stations 2100 update database stations 2020 98 rejects from update process 0711271505 new master database spc0711271505dtb update database stations 2020 matched with master stations 917 automatically 917 by operator 0 added as new master stations 1005 rejected 98 rejects file spc0711271421dtbrejected end_quote so as expected few of the climat stations couldnt be matched for metadata worries whats interestng is that roughly the same ratio of stations were matched with existing in both cases 8671693 vs 9172020 slightly better for mcdw though now as our updates only start in 2003 that means weve just lost between 826 and 1005 sets of data added as new we cant be exact as we dont know the overlap between the mcdw and the climat bulletins but we will have better idea when i try the anomdtb experiment on the combined update first add the climat update again this time to the mcdwupdated database climat begin_quote enter b for blind merging or ret b please enter the master database name spc0711271504dtb please enter the update database name spc0711271421dtb reading in both databases master database stations 2926 update database stations 2020 38 rejects from update process 0711271514 new master database spc0711271514dtb update database stations 2020 matched with master stations 1736 automatically 1736 by operator 0 added as new master stations 246 rejected 38 rejects file spc0711271421dtbrejected end_quote note several bits of good news firstly rejects are down to 38 60 having matched with mcdw stations thats not that good of course those will be new and so 2003 onwards only similarly 1005246 759 climat bulletins matched mcdw ones they will also be 2003 onwards only in other words there were only 1736759 977 updates to existing stations so yes im being sidetracked again i found and downloaded all the mcdw bulletins back to 1994 begin_quote uealogin1crucrutsversion_3_0incomingmcdw mcdw2cru mcdw2cru convert mcdw bulletins to cru format enter the earliest mcdw file ssm9409fin enter the latest mcdw file or ret for single files ssm0708fin all files processed tmp0711271645dtb 2785 stations written see later runs vap0711271645dtb 2786 stations written see later runs rdy0711271645dtb 2781 stations written see later runs pre0711271645dtb 2791 stations written see later runs sun0711271645dtb 2184 stations written see later runs thanks for playing byeee end_quote now im not planning to rerun all the previous parameters hell they should have had the older data in already but for suncloud this could help enormously heres the plan 1 merge the climatsourced database into the new mcdwsourced database 2 convert this modern sun hours database into modern cloud percent database 3 add normals for 9502 4 use the new program normshiftfor to calculate 9502 normals from ts 210 cld 5 calculate difference between ts 210 6190 normls and the above 6 modify the indatabase normals step 3 with the difference step 5 7 carry on as before this wont work anomdtbfor calculates normals on the fly it would have to know too much the next opportunity comes at the output from anomdtb the normalised values in the txt files that the idl gridder reads these are just files one per month with lists of coordinates and values so ideal to add normalised values to decided that this will be the process modern sunh db hsh2cldfor modern cld db modern cld db newprogfor 6190anomaliestxt meanwhile as before normal cld db anomdtbfor 6190anomaliestxt so we then just have to merge the two 6190 anomaly sets which could just be concatenation easy then the only thing we need is the miraculous newprogfor with three days before delivery hang on lets not try and boil the ocean how about 19012002 static as published leave well alone or recalculate with better dtr 200320067 calc from modern sunh and use the suggested mods after gridding this is what was originally intended but there will be problems 1 mcdw only goes back to 2006 so whats the data density for 20032005 should this also use synthetic cloud from dtr i guess yes 2 guarantee of continuity from 2002 to 2003 this could be the real stickler moving from one system to the other this is why it might be better to rerun 19012002 as well okay normshiftfor now creates gridded set of conversion data between whatever period you choose and 19611990 such that it can be added to the gridded output of the process run with the false normalisation period so first merge your bulletins well firstly you realise that your databases dont have normals lines so you modify mcdw2crufor and climat2crufor to optionally add them then you rerun them on the bulletins ending up with begin_quote uealogin1crucrutsversion_3_0incomingmcdw mcdw2cru mcdw2cru convert mcdw bulletins to cru format enter the earliest mcdw file ssm9409fin enter the latest mcdw file or ret for single files ssm0708fin add dummy normals line yn all files processed tmp0711272156dtb 2785 stations written vap0711272156dtb 2786 stations written rdy0711272156dtb 2781 stations written pre0711272156dtb 2791 stations written sun0711272156dtb 2184 stations written thanks for playing byeee end_quote begin_quote uealogin1crucrutsversion_3_0incomingclimat climat2cru climat2cru convert mcdw bulletins to cru format enter the earliest climat file climat_data_200301txt enter the latest climat file or ret for single file climat_data_200707txt add dummy normals line yn all files processed tmp0711272219dtb 2881 stations written vap0711272219dtb 2870 stations written rdy0711272219dtb 2876 stations written pre0711272219dtb 2878 stations written sun0711272219dtb 2020 stations written tmn0711272219dtb 2800 stations written tmx0711272219dtb 2800 stations written thanks for playing byeee end_quote so now can i merge climat into mcdw as expected thank goodness begin_quote uealogin1crucrutsversion_3_0incomingmerge_climat_into_mcdw newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name sun0711272156dtb please enter the update database name sun0711272219dtb reading in both databases master database stations 2184 update database stations 2020 looking for wmo code matches 28 rejects from update process 0711272225 writing sun0711272225dtb outputs written new master database sun0711272225dtb update database stations 2020 matched with master stations 1775 automatically 1775 by operator 0 added as new master stations 217 rejected 28 rejects file sun0711272219dtbrejected end_quote wahey lots of stations to play with so next convert to cloud begin_quote crua6crucrutsversion_3_0dbcld hsh2cld hsh2cld convert sun hours database to cloud percent one please enter the sun hours database sun0711272225dtb data factor detected 1000 completed 2401 stations converted sun percentage database spc0711272230dtb cloud percentage database cld0711272230dtb end_quote so bated breath and yay begin_quote crua6crucrutsversion_3_0secondariescld anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required cld select the cts or dtb file to load cld0711272230dtb specify the startend of the normals period 19952002 specify the missing percentage permitted 125 data required for normal 7 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto cldtxt select the firstlast years ad to save 19952007 operating tmp_mntcruautocrutsversion_3_0secondariescldcld0711272230dts normals mean percent stdev percent dtb 0 00 cts 83961 493 83961 493 process decision percent ofchk latlon 95 01 01 normal 86174 506 507 outofrange 28 00 00 accepted 83933 493 dumping years 19952007 to txt files end_quote well qualified yay only half got normals but i dont like to raise the missing percentage limit to 25 because were only talking about 8 values to begin with the output files look ok between 400 and 600 values in each not lot really but hey better than nowt so onto the conversion data must stop calling em factors theyre not multiplicative begin_quote crua6crucrutsversion_3_0secondariescld normshift normshift normals from any period please enter the source file cru_ts_2_1019012002cldgrid enter the start year of this file 1901 enter the end year of this file 2002 enter the normal period start year 1995 enter the normal period end year 2002 enter the 3character parameter cld normals file will be clim9502to6190gridcld end_quote so erm now we need to create our synthetic cloud from dtr except thats the thing we cant do because pro cal_cld_gts_tdmpro needs those bloody coefficients a257190 etc that went awol frustratingly we do have some of the outputs from the program ie a25017190glo but thats obviously use so erm we need synthetic cloud for 20032007 or we wont have enough data to run with and yes its taken this long to realise that oh bugger had detailed search around mark news old disk still online thankfully found this begin_quote crua6crumark1markngtscldval ls l total 7584 lrwxrwxrwx 1 f080 cru 25 sep 12 2005 c1 cruu1f080isccpc1_mon rwrr 1 f080 cru 1290 mar 24 1998 cld_corrj rwrr 1 f080 cru 938 mar 17 1998 cld_scatj rwr 1 f080 cru 922584 mar 24 1998 cru_hahn_corrps rwr 1 f080 cru 922588 mar 24 1998 cru_isccp_corrps rwr 1 f080 cru 533 mar 27 1998 cruobs_hahn_corrj rwr 1 f080 cru 868561 mar 27 1998 cruobs_hahn_corrps rwrr 1 f080 cru 697 mar 20 1998 dtr_corrj rwr 1 f080 cru 50 mar 27 1998 foo rwr 1 f080 cru 248832 mar 27 1998 glo25cld1980 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1981 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1982 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1983 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1984 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1985 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1986 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1987 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1988 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1989 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1990 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1991 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1992 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1993 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1994 rwr 1 f080 cru 248832 mar 27 1998 glo25cld1995 rwr 1 f080 cru 922592 mar 24 1998 hahn_isccp_corrps rwr 1 f080 cru 2378 mar 24 1998 testj end_quote which looks to like the place where he calculated the coefficients the j files are idl journal files so can be run from within idl this was my first attempt begin_quote idl run cld_corrj compiled module main compiled module rd25_gts year 1981 compiled module rdbin compiled module strip foo permission denied foo permission denied foo permission denied openr error opening file unit 99 file homecruf098u1hahnhahn251981 such file or directory execution halted at rdbin 63 cruu2f080idlrdbinpro rd25_gts 11 cruu2f080idlrd25_gtspro main 1 tmp_mntcruautomark1f080gtscldvalcld_corrj idl end_quote i then had to chase around to find three sets of missing files to fulfil these five conditions if keyword_sethgrid eq 0 then rd25_gts hgridu1hahnhahn2519811991 if keyword_setrgrid eq 0 then rd25_gts rgridglo_reg_25glocld19811991 if keyword_sethgrid2 eq 0 then rd25_gts hgrid2u1hahnhahn2519831991 if keyword_setigrid eq 0 then rdisccp_gts igridc1isccp19831991 if keyword_setrgrid2 eq 0 then rd25_gts rgrid2glo_reg_25glocld19831991 i managed to find the hahn25 files on marks disk and some likelylooking isccp files also on marks disk but although there were plenty of files with glo cld and 25 in them there were none matching the filename construction above however as some of those were in the same directory ill take that chance i did try honestly very hard i found all the files and put them in directories i made local copy of the job file h_cld_corrj with the local directory refs in hell i even precompiled the correct version of rdbin all for nothing as usual it runs quite happily zipping through things until compiled module rdisccp_gts year 1983 compiled module rdisccp c1isccp830772 c1isccp830772z such file or directory c1isccp830872 c1isccp830872z such file or directory c1isccp830972 c1isccp830972z such file or directory c1isccp831072 c1isccp831072z such file or directory c1isccp831172 c1isccp831172z such file or directory c1isccp831272 c1isccp831272z such file or directory year 1984 c1isccp840172 c1isccp840172z such file or directory etc it isnt seeing the isccp files even though they are there odd if i create z files it says they arent compressed it ends with year 1991 yes filesize 248832 gridsize 250000 compiled module mark_correlate compiled module correlate i have idea what its actually done though it doesnt appear to have produced anything ah idl help at main 1 tmp_mntcruautocrutsversion_3_0cloud_syntheticsh_cld_corrj cru_hahn_corr float array144 72 12 cru_isccp_corr float array144 72 12 hgrid long array144 72 12 11 hgrid2 long array144 72 12 9 igrid long array144 72 12 9 ilat int 72 ilon int 144 im int 12 isccp_hahn_corr float array144 72 12 n long array5225 nn long 5225 rgrid long array144 72 12 11 rgrid2 long array144 72 12 9 compiled procedures main defxyz rd25_gts rdbin rdisccp rdisccp_gts compiled functions correlate mark_correlate strip idl so this is one of set of tools that you have to know how to use all the works done in the idl data space well as we dont have any instructions thats complete waste of twoandahalf days time lets forget about cld and start worrying about netcdf netdcf well now we have to make the data available in netcdf and ascii grid formats at the moment it might be best to just postprocess the final ascii grids into netcdf though more elegant to have mergegridsfor produce both as it has the data there anyway so i modified mergegridsfor into makegridsfor with added netcdf goodness as usual lots of problems getting the syntax right badc work at ral 35 december 2007 finally got netcdf fortran working on the chosen server here dampbadcrlacuk i am definitely not chamaeleonic life form when it comes to unfamiliar computer systems shame the elusive command line compile statement is gfortran iusrlocalnetcdf362include fileouto fileinf usrlocalnetcdf362liblibnetcdfa hunting for cdds i found potential problem with binary dtr used in the construction of frost days vapour pressure and eventually cloud it looks as though there was mistyping when the 25degree binaries were constructed idl quick_interp_tdm219012006dtrbindtrbin50gs25dumpbindumpbinpts_prefixdtrtxtdtr that 50 should have been 750 oh bugger well might as well see if generation does work here dtrbin25 er hang on while i try and get idl to recognise path meh as usual i find this effectively impossible so have to issue manual compile statements the suite of progs required to compile for quick_interp_tdm2pro is glimitpro area_gridpro strippro wrbinpro and of course quick_interp_tdm2pro actually others need others so i wrote generic idl script to load all of satans little helpers idl programsidlloads4idlj compiled module glimit compiled module area_grid compiled module strip compiled module wrbin compiled module rdbin compiled module defxyz compiled module frscal compiled module days compiled module rnge compiled module saveglo compiled module selectmodel compiled module tvap compiled module esat idl this is just because i still dont have idl_path working so having to issue each of the above as manual compile statements in that order was getting tedious n00b this now fixed ed anyway heres the corrected binary dtr production idl quick_interp_tdm219012006dtrbindtrbin750gs25dumpbindumpbinpts_prefixdtrtxtdtr defaults set 1901 compiled module map_set compiled module crossp compiled module mean compiled module moment compiled module stddev grid 1901 nonzero 09415 18771 18417 cells 5608 1902 grid 1902 nonzero 08608 18713 18752 cells 5569 etc and so to regenerate frs begin_quote idl frs_gtsdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixfrssynfrssyn idl quick_interp_tdm219012006frsgridfrsgrid750gs05dumpglodumpglo nostn1synth_prefixfrssynfrssyn bash300 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanfrs enter name for the gridded climatology file clim6190lanfrsdelme enter the path and stem of the glo files frsgridfrs enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files frsabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum 3 set monthly minima and maxima for wetrd0 4 set all values 0 ie positive choose 3 right erm off i jolly well go frs011901glo frs021901glo etc end_quote now looking to get makegridsfor working managed to get the data to write by declaring reals as double precision later realising i couldshould have changed the netcdf interface calls to real instead ah well still tussling with the time variable not clear how to handle observations luckily mike s knew what the standard was begin_quote i need to define the time parameter in the netcdf version of the cruts dataset i suspect i need to use gregorian which to all intents and porpoises is accurate although it reverts to julian before xxyy1582 but i wondered if there was convention in cru or wider for allocating standard timestamps to observations for the gridded temperature we use short timetime timeunits months since 187011 remember to start with zero mike end_quote and that seems to now be working heres the run with the compile statement included begin_quote bash300 gfortran iusrlocalnetcdf362include makegrids programsfortranmakegridsfor usrlocalnetcdf362liblibnetcdfa bash300 makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor writing cru_ts_3_0019011910frsdat cru_ts_3_0019011910frsnc writing cru_ts_3_0019111920frsdat cru_ts_3_0019111920frsnc writing cru_ts_3_0019211930frsdat cru_ts_3_0019211930frsnc writing cru_ts_3_0019311940frsdat cru_ts_3_0019311940frsnc writing cru_ts_3_0019411950frsdat cru_ts_3_0019411950frsnc writing cru_ts_3_0019511960frsdat cru_ts_3_0019511960frsnc writing cru_ts_3_0019611970frsdat cru_ts_3_0019611970frsnc writing cru_ts_3_0019711980frsdat cru_ts_3_0019711980frsnc writing cru_ts_3_0019811990frsdat cru_ts_3_0019811990frsnc writing cru_ts_3_0019912000frsdat cru_ts_3_0019912000frsnc writing cru_ts_3_0020012006frsdat cru_ts_3_0020012006frsnc bash300 end_quote and here for combination of posterity and boredom is curtailed dump from ncdump begin_quote bash300 ncdump cru_ts_3_0019012006frsnc head 300 netcdf cru_ts_3_0019012006frs dimensions lon 720 lat 360 time unlimited 1272 currently variables double lonlon lonlong_name longitude lonunits degrees_east double latlat latlong_name latitude latunits degrees_north int timetime timelong_name time timeunits months since 187011 timecalendar standard double frstime lat lon frslong_name ground frost frequency frsunits days frsscale_factor 000999999977648258 frscorrelation_decay_distance 750 frs_fillvalue 9999 frsmissing_value 9999 global attributes title cru ts 300 mean temperature institution badc contact badc badcrlacuk data lon 17975 17925 17875 17825 17775 17725 17675 17625 17575 17525 etc 17075 17125 17175 17225 17275 17325 17375 17425 17475 17525 17575 17625 17675 17725 17775 17825 17875 17925 17975 lat 8975 8925 8875 8825 8775 8725 8675 8625 8575 8525 8475 etc 7975 8025 8075 8125 8175 8225 8275 8325 8375 8425 8475 8525 8575 8625 8675 8725 8775 8825 8875 8925 8975 time 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 etc 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 frs 999 999 999 999 999 999 999 999 999 999 999 999 etc probably some real data there somewhere bash300 end_quote and vap begin_quote idl vap_gts_anomdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixvapsynvapsyndumpbin1 compiled module vap_gts_anom compiled module rdbin compiled module strip compiled module defxyz landsea 56016 68400 calculating tmn normal compiled module tvap calculating synthetic vap normal compiled module esat calculating synthetic anomalies compiled module moment 1901 vap xs2 167770e05 623626e06 0160509 0222689 1902 vap xs2 0000122533 346933e05 0268891 00644855 etc end_quote these numbers are different from the original runs so that was genuine mistyping eek thats not very promising is it begin_quote idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynth_prefixvapsynvapsynpts_prefixvaptxtvap compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc bash300 glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapdelme enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum 3 set monthly minima and maxima for wetrd0 4 set all values 0 ie positive choose 4 right erm off i jolly well go vap011901glo vap021901glo etc bash300 makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapmmyyyygloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeevapdat now please enter the 3ch parameter code vap enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 vapour pressure writing cru_ts_3_0019011910vapdat cru_ts_3_0019011910vapnc writing cru_ts_3_0019111920vapdat cru_ts_3_0019111920vapnc writing cru_ts_3_0019211930vapdat cru_ts_3_0019211930vapnc writing cru_ts_3_0019311940vapdat cru_ts_3_0019311940vapnc writing cru_ts_3_0019411950vapdat cru_ts_3_0019411950vapnc writing cru_ts_3_0019511960vapdat cru_ts_3_0019511960vapnc writing cru_ts_3_0019611970vapdat cru_ts_3_0019611970vapnc writing cru_ts_3_0019711980vapdat cru_ts_3_0019711980vapnc writing cru_ts_3_0019811990vapdat cru_ts_3_0019811990vapnc writing cru_ts_3_0019912000vapdat cru_ts_3_0019912000vapnc writing cru_ts_3_0020012006vapdat cru_ts_3_0020012006vapnc bash300 end_quote quick look at the vap netcdf headers data looked good so yay thats the damage repaired pity it took over day of the time at ral but i didnt have to fix it now it was an opportunity to get the process working in this environment next problem station counts i had this working fine in cru here its insisting on stopping indefinitely at january 1957 discovered after 36 hours of fretting and debugging that its popping its clogs on the south polar base 890090 900 0 2853 amundsenscott antarctica 1957 2006 101957 99900 and what dyou know when i debug it its as simple as being too close to the pole and not having any loop restrictions in the east and west hunts for valid cells just looping forever added few simple conditionals and all seems to run but outputs dont look right the jan 1957 station counts have missing values for the polar regions managed to get anomdtb compiled with gfortran after altering few lines in anomdtb and its mods where tim had shrugged off the surly bounds of strict f90 it must be compiled in programsfortran though with the line embedded in the anomdtb comments too gfortran anomdtb filenamesf90 timef90 grimfilesf90 crutsfilesf90 loadperfilesf90 saveperfilesf90 annfilesf90 cetgeneralf90 basicfunf90 wmokeyf90 gridopsf90 gridf90 ctyfilesf90 anomdtbf90 as part of the modifications i removed the unused options meaning that dts file is longer required and of course neither is falsedtsfor ran it for the temperature database and got apparentlyidentical anomaly files to the ones i generated in cru ran quick_interp_tdm2 glo2abs and makegrids ended up with grids very similar though sadly not identical to the originals could be idl could be compiler could be system scripting now this was always going to be the challenge for large suite of highlyinteractive programs in f77 f90 and idl which didnt follow universal file naming conventions so to start with i thought it might be fun to compile an exhaustiveing list of the commands needed to make complete update headings begin with notes are in brackets add mcdw updates mcdw2cru interactive newmergedb per parameter interactive add climat updates climat2cru interactive newmergedb per parameter interactive add bom updates au2cru unfinished interactive should do whole job regenerate dtr database tmnx2dtr interactive produce primary parameters tmp tmn tmx dtr pre anomdtb per parameter interactive quick_interp_tdm2 per parameter glo2abs per parameter interactive makegrids per parameter interactive prepare binary grids tmp dtr pre for synthetics quick_interp_tdm2 per parameter produce secondary parameter frs uses tmpdtr frs_gts_tdm quick_interp_tdm2 glo2abs interactive makegrids interactive produce secondary parameter vap uses tmpdtr vap_gts_anom anomdtb interactive quick_interp_tdm2 glo2abs interactive makegrids interactive produce secondary parameter wetrd0 uses pre rd0_gts_anom anomdtb interactive quick_interp_tdm2 glo2abs interactive makegrids interactive back at cru tried to compile makegridsfor on uealogin1 as crua6 is being retired got an odd error ld warning file usrlocalnetcdf361liblibnetcdfafortattioo wrong elf class elfclass64 which was cured with the addition of xarchnative64 to the compile statement f77 xarchnative64 iusrlocalnetcdf361include makegrids badc_areaprogramsfortranmakegridsfor usrlocalnetcdf361liblibnetcdfa then had to play around to try and reduce the size of the netcdf files they were bigger than the uncompressedascii ones this was because the variable was declared as double which is 64 bits or 8 bytes per datum waste since we deal with the data as integers and use factors to restore real values so redeclared as int considering reredeclaring as short which is 16 bits to ints 32 however that only gives signed 32768 to 32767 or unsigned 0 to 65535 thats enough for our datasets but only if precip has positive missing value code which i dont like the sound of reproduced all primaries and secondaries with int typing for the netcdf component simultaneously trying to work out why stncountsfor is apparently ignoring the south pole station amundsenscott even though the rest of the output looks fine eventually realised that the landsea mask is blobking it station counts work continues should the netcdf files be written as int to match the data files or short to save lot of space in fact should the station counts be in the same netcdf files as their data finished off the local regenration of vap and frs from the corrected dtrbin files dtr fix idl quick_interp_tdm219012006dtrbindtrbin750gs25dumpbindumpbinpts_prefixdtrtxtdtr vap binary regen idl vap_gts_anomdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixvapsynvapsyndumpbin1 note that as expected results are different for synthetic vap first two lines of the crua6 run 1901 vap xs2 153894e05 616462e06 0160509 0222662 1902 vap xs2 0000123921 346215e05 0268891 00261302 first two lines of the dampbadcrlacuk run 1901 vap xs2 167770e05 623626e06 0160509 0222689 1902 vap xs2 0000122533 346933e05 0268891 00644855 different compilers different architectures different whichever idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynth_prefixvapsynvapsynpts_prefixvaptxtvap paused here as waiting for completion of makegrids2for includes station counts in netcdf files one early ramification of this is that glo2absfor now saves filenames with yearmonth rather than replicating the loopy monthyear that quick_interp_tdm2pro gives this will allow file lists to be compiled with ls tmpfile so that timespan and missing files can be detected at the start have also had to amend and rerun at great length stnountsfor to do the same just realised i still havent worked out how to do the station counts for the secondaries i cant work out how tim did it either since he worked out counts at the same stage i do did he let the primary parameters counts override or backfill well we could take the approach that the gridding routine takes namely to use observed data and only refer to synthetic when that fails and only refer to normals when that fails obviously so stncounts will have to accept two sets of txt files at each timestep it will have to first count the secondary parameters stations then the primary parameters will be counted and fill in any zeros in the grid however we will need different information for the paper what use is the effective station count as some is of higher quality than the rest so will probably need the regular observedonly count as well which could be separate run of stncounts but faaar more sensible to be side effect of this run oh gods ive got to modify another program cries i think the mods to stncounts will be the turning point for all the programs so far they have all been generic but this is not tenable if the system is to be automated they need to be aware of the parameters and what they mean otherwise stncounts will have to be told how many primaries produced the synthetic grids etc etc stupid so i need to devise directory structure and file naming schema that will support the entire update process eeeeeeeek time passes other projects given higher priority back to precip it seems the variability is too low this points to problem with the percentage anomaly routines see earlier escapades will the curse of tim never be lifted reminder i started off using conventional calculation absgridiloniilati nintnormalsiimo anomsiloniilati normalsiimo 100 which is v n an100 this was shown to be delivering unrealistic values so i went back to anomdtb to see how the anomalies were contructed in the first place and found this dataaxayearxmonthxastn nint10000realdataaxayearxmonthxastn realnormmeanxmonthxastn10 which is 1000vn1 so i reverse engineered that to get this v na10001000 and that is apparently also delivering incorrect values bwaaaahh modified anomdtb to dump the precip anomaly calculation it seems to be working with raw values eg dataa 1050 normmean 71200 anom 475 dataa 270 normmean 71200 anom 621 dataa 710 normmean 71200 anom 3 dataa 430 normmean 71200 anom 396 dataa 280 normmean 71200 anom 607 dataa 830 normmean 71200 anom 166 dataa 0 normmean 71200 anom 1000 dataa 270 normmean 71200 anom 621 dataa 280 normmean 71200 anom 607 dataa 450 normmean 71200 anom 368 dataa 180 normmean 71200 anom 747 dataa 1380 normmean 71200 anom 938 however that 1000 is interesting for zero precip it looks as though the anomalies are in mm10 like the precip database raw values but these are dumped from within the program the output txt files have 100 instead of 1000 thats because of the checkvarisuffix routine which returns factor based on the parameter code including else if suffixeqpre then variableprecipitation mm factor 01 factor is then used when the anomaly files are written do xastn 1 nastn if dataaxayearxmonthxastnne9999 write 92f82f81f135i7 alatxastnalonxastnaelvxastnrealdataaxayearxmonthxastnfactorastnxastn end do so the anomalies are in real units presumably mmday so we grid these values the resulting anomalies for jan 1980 look like this max 16124 min 100 these should be applied to the climatology normals i think they can be applied to either unscaled real value normals or to normals which are mm10 results will be scaled accordingly so lets look at glo2abs again the current formula to convert to real values is absgridiloniilati nintrnormalsiimo anomsiloniilati10001000rmult v na10001000rmult not happy with that anyway the multiplicative factor should that be there at all now if these are genuine percentage anomalies ie they represent the percentage change from the mean then the formula to convert them using unscaled normals would be v n na100 for instance 100 would give v 0 and 100 would give v 2n now if the normals are 10 surely the results will be 10 too as each term has n as multiplicative factor anyway this makes wonder about the prevailing theory that the anomalies need to be 10 they are fractions of the normal so it shouldnt matter whether the normal is real or 10 the variability should be the same ie the variability of the anomalies so run just for 1980 of glo2abs then using the following formula absgridiloniilati nintrnormalsiimo anomsiloniilati rnormalsiimo 100 v n an100 this should give integer values of mm10 because the normals are mm10 and uncorrected so working backwards what should the original anomalising routine in anomdtbf90 look like it should look like this 100vnn or 100vn 100 or 100vn1 the last version is remarkably similar to the original 1000vn1 in fact i think we can call equivalence if v and n are in mm complicated the 100 is not scaling factor its the number that determines percentage calculation if we use 1000 what are we saying the percentage anomalies we would have got are now 10x higher where v0 will be 1000 meaningless percentage anomaly for precip thats where the checkvarisuffix factor pops up multiplying by 01 and getting us back where we started so tims original looks right once you understand the correction factor applied later in which case my original algorithm should have worked slightly heathrobinson attempt to verify extracted the cell for wick from the 1980 output wick is 5845n 308w i reckon thats 297353 i get 106 69 91 22 16 74 79 80 129 156 177 151 the station says 1980 763 582 718 153 95 557 587 658 987 1162 1346 1113 sigh yes they do follow similar shape its just that the original station data are much higher in terms of updown following direction station dudduuuuuud gridded dudduuuuuud so once again i dont understand statistics quel surprise given that i havent had any training in stats in my entire life unless you count alevel maths normals for the same cell gridref 353 297 1060 740 870 600 610 670 700 910 990 1070 1200 1110 now these look like mm10 the same units as the station data and what i expected if i apply the anomalies to these normals it looks like ill get what im after the trouble is that glo2absfor deliberately works with real values and so applies the factor in the clim header before using the values i just dont think that works with percentages hmm actually it does i ran through the algorithms and because the normal is multiplicative you can do the scaling before or after in other words if v is v produced with scaled normals n01 then we do end up with v 10v so i just need to include the factor in the final equation v n an100f ran it and the results were good so as its the only change i wont have to regrid precip after all just rerun from glo onwards did so then used the old but working version of makegrids to produce the gridded ascii and netcdf files so comparisons well i want to compare with both 20 and 21 because they do differ so i will need to convert 20 to regulargridded as i did with 21 if i could only remember the program i wrote to do it another problem apparently i should have derived tmn and tmx from dtr and tmp as thats what v210 did and thats what people expect i disagree with publishing datasets that are simple arithmetic derivations of other datasets published at the same time when the real data could be published instead but this introduces the problem of derivation tmn tmp dtr2 and tmx tmp dtr2 but this does not tell us what to do when either or both values tmp dtr are missing one thing to check is the climatologies here are the first two cell normals for all four parameters tmp nearsurface temperature degrees celsius gridref 1 148 270 274 269 265 259 253 246 242 248 252 261 268 gridref 1 311 187 213 195 137 30 47 90 81 33 56 132 186 dtr diurnal temperature range degrees celsius gridref 1 148 56 71 54 59 55 50 54 51 57 61 61 73 gridref 1 311 74 71 72 77 59 65 64 56 49 51 63 71 tmn nearsurface temperature minimum degrees celsius gridref 1 148 242 238 242 236 232 228 219 217 220 222 230 232 gridref 1 311 224 249 231 175 59 15 58 53 8 81 163 222 tmx nearsurface temperature maximum degrees celsius gridref 1 148 298 309 296 295 287 278 273 268 277 283 292 305 gridref 1 311 150 178 159 98 0 80 122 109 58 31 100 151 gridref 1 312 well making allowances for rounding errors they do seem to hold to the relationship wrote maketmnxfor to derive tmn and tmx from tmp and dtr grids works with the output files from glo2absfor ran makegrids to produce dat and nc files still prestation count inclusion on to precip problems tim ran some comparisons between 210 and 300 in general things are much improved but there are few hair raisers asterisked for special concern cape verde isl mam djf p galapagos all tp guinea mam 1901 p bangladesh all 19912000 p bhutan djf 1939 1945 p laosvietnam djf 1991 p looked at bangladesh first here the 1990s show sudden drop that really can only be some stations having data factor of 10 too low this ties in with the wwr station data that dl added for 19912000 which aprently was prone to scaling issues wrote stnx10for to scale file of wwr bangladesh records then manually cpd the decade over the erroneous ones in the database also fixed country name from bngladesh then laosvietnam here we have an anomalously high peak for 1991 djf used getllstationsfor to extract all stations in box around laos vietnam 8 to 25n 100 to 110e total of 96 stations from thailand vietnam laos kampuchea and china eeeek tim program only worked with boxes though also im not 100 sure which year djf belongs to in tims world hopefully its the december year as it was the fourth column in his plot table however plotted all the data as overlapping years and there is trace of spike in djf uhoh im not actually convinced that the country box approach is much cop better to examine each land cell and automagically mark any with excessions say 5 sd to begin with could then be extra clever and pull the relevant stations and find the source of the excession of course this shouldnt happen since there is 4sd limit imposed by anomdtbf90 for precip 3sd for others wrote vietlaosfor to run through the lists of vietnam and laos cells provided by tim and extract the djf precip values for each from the 19012006 gridded file it then calculates the standard deviation of each series normalises and notes any values over 60 sds 1991 onwards result some very high values up to 113 standard deviations in 19912 worst cells row column index stddev 212 571 273 1121 213 571 273 1130 214 571 273 1015 212 572 273 1111 213 572 273 1120 214 572 273 1058 212 573 273 1084 213 573 273 1110 212 574 273 1076 215 572 273 1006 214 573 273 1053 213 574 273 1094 214 574 273 1044 212 575 273 1065 213 575 273 1066 211 576 273 1096 212 576 273 1051 index 273 can be related to time as follows the series begins in 1901 and we take three values per year jfd so 1990 would be the 90th year and the 268th270th values thus 273 dec 1991 the cells are all contiguous implying single stations influence via the gridding process 570 571 572 573 574 575 576 211 na na 637 756 836 971 1096 212 na 1121 1111 1084 1076 1065 1051 213 552 1130 1120 1110 1094 1066 na 214 534 1015 1058 1053 1044 na na 215 437 997 1006 na na na na na means the cell isnt in the laos or vietnam areas the epicentre of the anomaly looks to be cell 213571 which is in the laos file box column row lon lat 205773 571 213 10575 1675 so were looking for stations in the vicinity of 10575e 1675n well the precip database has total of eight laos stations so that should be straightforward 4893000 1990 10210 304 luang prabang laos 1951 2006 999 99900 4893800 1920 10170 323 sayaboury laos 1969 2006 999 99900 4894000 1800 10260 170 vientiane laos 1941 2006 999 99900 4894600 1738 10465 152 thakhek laos 1989 2006 999 99900 4894700 1660 10480 155 savannakhet laos 1970 2006 999 99900 4894800 1670 10500 184 seno laos 1951 2006 999 99900 4895200 1568 10643 168 saravane laos 1989 2006 999 99900 4895500 1510 10580 93 pakse laos 1968 2006 999 99900 well seno has to be the prime candidate unfortunately this is from seno 4894800 1670 10500 184 seno laos 1951 2006 999 99900 snip 1989 0 09999 19109999 1010 4450 2690 2880 1340 0 0 1990 60 1560 150 420 1110 4830 3620 36909999 780 30 0 1991 0 0 400 0 690 1907 1890 5308 3238 805 0 366 1992 488 280 50 80 1883 2503 2644 2935 2039 131 0 89 1993 0 0 139 280 2324 1163 1949 4460 2145 0 29 0 most undistinguished set so the net widens 4894700 1660 10480 155 savannakhet laos 1970 2006 999 99900 snip 19899999 099999999 10809999999999999999 149099999999 1990 309999 240999999999999 19209999999999999999 0 1991 0 0 127 49 952 2508 1681 4034 4006 1690 0 338 1992 324 338 93 691 1932 2344 2048 4464 756 607 0 197 1993 0 5 335 263 2665 921 2884 2204 1834 17 23 0 nope 4894600 1738 10465 152 thakhek laos 1989 2006 999 99900 snip 19899999 099999999 20309999999999999999 149099999999 1990 109999 52099999999999999999999999999999999 0 1991 0 0 905 119 861 6058 3578 7092 2417 373 0 324 1992 105 318 125 456 2140 2978 4623 4595 3376 425 0 854 1993 0 108 52 1343 5835 2999 6285 4375 1017 467 8 0 nope unless these values are unusual lets look at the highest two decembers from each station 4893000 1990 10210 304 luang prabang laos 1951 2006 999 99900 1992 193 911 0 497 657 1246 2971 2837 929 584 95 1372 1994 0 54 1107 291 1702 2436 2025 3636 1516 316 185 816 4893800 1920 10170 323 sayaboury laos 1969 2006 999 99900 1992 411 719 0 816 754 1252 2573 1671 1686 991 351 879 1994 0 208 1695 503 2262 1607 1743 2562 3205 118 193 454 4894000 1800 10260 170 vientiane laos 1941 2006 999 99900 1971 0 70 140 340 2940 2750 2890 2260 1630 1030 0 180 1992 381 273 11 424 2372 4878 4381 3676 3091 630 0 212 1994 0 300 921 322 2685 2725 4698 1932 4000 3031 1016 166 inc for comparison with previous 4894600 1738 10465 152 thakhek laos 1989 2006 999 99900 1991 0 0 905 119 861 6058 3578 7092 2417 373 0 324 1992 105 318 125 456 2140 2978 4623 4595 3376 425 0 854 1994 0 612 952 558 1697 7092 5121 4276 2428 486 20 2 inc for comparison with previous 4894700 1660 10480 155 savannakhet laos 1970 2006 999 99900 1991 0 0 127 49 952 2508 1681 4034 4006 1690 0 338 1992 324 338 93 691 1932 2344 2048 4464 756 607 0 197 1994 0 734 390 494 1381 3377 1525 5651 1881 600 0 0 inc for comparison with previous 4894800 1670 10500 184 seno laos 1951 2006 999 99900 1971 0 880 130 370 1270 4010 2200 2860 1930 410 0 140 1991 0 0 400 0 690 1907 1890 5308 3238 805 0 366 1992 488 280 50 80 1883 2503 2644 2935 2039 131 0 89 inc for comparison with previous 1994 0 532 318 969 2065 1937 1197 4552 1934 197 0 0 inc for comparison with previous 4895200 1568 10643 168 saravane laos 1989 2006 999 99900 1992 287 33 52 222 1072 5444 2998 8899 2243 1070 0 0 inc for comparison with previous 1994 0 10 354 686 1743 3387 5829 3254 4219 408 41 4 inc for comparison with previous 1998 26 619 0 574 2386 2871 1530 2308 2680 913 463 73 2005 0 0 120 1230 1990 2860 4350 8060 3770 280 140 70 4895500 1510 10580 93 pakse laos 1968 2006 999 99900 197299999999999999999999999999999999 2610 870 280 140 1992 166 101 0 210 665 1898 2574 6448 2942 648 10 31 inc for comparison with previous 1994 0 0 134 220 2537 3596 5161 5384 7693 1513 236 94 summary luang prabang shows significant anomaly of 1372 for dec 1992 unfortunately this finds echoes both temporal 1994 has 816 and spatial sayabourys 1992 is 879 so if these values are causing the spike its genuine if exaggerated in way yet to be determined wrote vietlaos2 to gather data from the cells and stations it also gets the climatology initially it only gathered 13 stations with data in 19912 using vietnam and laos to select on country name however taking the cell 214574 in december 1991 as the peak incident we can use those coordinates 1725n 10725e to centre bounding box for station selection box 10degs square yields only 17 stations none of which have anything remotely spikey in dec 1991 box 20degs square some would say unfeasibly large yields 98 stations one of which does have bit of spike in dec 91 not impressively so though and its long way away 4855200 853 9993 3 nakhon si thammarat thailand 1912 2000 999 99900 over 105 degrees south and over 7 degrees west of the target cell not very convincing especially as closer stations are bound to have masked it one final try with vietlaos3for just looking at december now and getting the original station normals as well as the climatological ones the whole chain this proves to be surprisingly complicated on parallel track this would really have been better as blog tim has found that the binary grids of primary vars used in synthetic production of secondary parameters should be produced with binfac set to 10 for tmp and dtr this may explain the poor performance and coverage of vap in particular back to vietlaos the station output from vietlaos3for had couple of stations with missing anomaly values lat lon alt norm val anom 1715 10413 17100 2900 6200 999900 1580 10203 18200 4500 4070 999900 i eventually worked out that i hadnt collapsed universal probability it was just the 4 standard deviation screen in anomdtb 4 for precip 3 for temp to confirm i did short anomdtb run just for 1991 with the sd limit set to 10 and sure enough 1715 10413 1710 2037900024835600 1580 10203 1820 804400024840300 they both look high enough to trigger the 4sd cap however since the spike were investigating is from regular process run where that limit was in place we cant use those values program is thus amended to omit any stations without anomalies for dec 1991 next issue is to make sense of the output the first line from the station file is headings added lat lon alt norm val anom 2260 11410 2500 2900 2160 2550 remembering its percentage anomalies so 255 of 29 is 29255 7395 add that to 216 290 by contract the cell file looks like this row col lat lon val norm 220 561 2025 10075 1290 1500 there are 63 stations and 204 cells 196 when missing values sea eliminated i guess one approach would be to grid the anomalies to see if peak is visible i did it is the simple interpolation in matlab puts the peak at 1725n 10525e matches the grid peak for lat and little west for lon the nearest high station anomaly is 23692 thats from 4838300 1653 10472 138 mukdahan thailand 1934 2000 999 99900 6190 34 127 290 907 1813 2900 2271 3353 2596 886 84 13 1934 0 100 0 500 3150 2940 2460 2980 3320 350 0 20 1935 0 0 0 440 1920 1560 3220 580 1770 0 170 0 1936 0 0 820 0 2320 1900 3460 810 2120 0 0 0 1937 0 0 350 660 3640 740 1920 2890 4470 330 0 0 1938 0 0 550 1300 730 1720 2340 400 2030 810 0 0 1939 0 280 700 230 1320 420 2480 4190 2130 0 0 0 1940999999999999999999999999999999999999999999999999 1941 0 0 530 590 1800 2710 420 2790 650 750 0 0 1942 0 0 540 660 1650 3200 1200 1730 1990 0 0 0 1943 0 0 1600 1300 1960 1880 2000 2200 2600 0 0 0 1944 09999 0 320 2210 1040 1700 2500 2150 820 50 0 1945 70 600 0 340 0 2470 3400 2780 1620 20 330 500 1946 0 0 1360 09999 1720 1070 3330 2870 1260 0 0 1947 0 180 50 1390 3200 1530 3520 11509999 50 0 0 194899999999 0 1630 3520 1040 2900 3980 2160 380 10 0 1949 0 200 170 470 3000 2720 3110 4920 360 690 909999 1950 0 70 0 250 1610 2090 1040 1390 3500 1960 20 0 1951 0 340 770 1380 530 3380 1590 1950 3580 1430 20 0 1952 0 0 1170 660 1640 3160 2320 4150 3510 860 30 0 1953 260 110 430 630 1010 2200 1480 2780 1180 310 10 0 1954 460 10 30 1100 1950 2870 1120 2640 4220 620 0 0 1955 0 0 280 580 2180 4100 2900 2570 1810 270 20 0 1956 0 420 150 1000 3000 2930 3980 3840 2020 220 0 0 1957 0 30 1210 630 1690 2130 2090 3030 3240 460 0 0 1958 70 50 10 1090 1060 1690 2670 910 2750 700 0 0 1959 0 430 730 290 2300 1540 2080 2030 3910 280 0 0 1960 0 190 550 650 1230 1750 3750 5090 2190 700 90 0 1961 0 0 590 660 2190 5880 2150 4310 4030 1140 0 0 1962 0 20 120 880 2200 2690 2780 47709999 360 50 0 1963 0 0 610 600 1010 3480 2130 3410 1250 220 150 0 1964 0 0 740 910 3370 2600 630 2050 4700 1120 20 0 1965 0 250 660 780 2120 2700 2110 2810 2210 1350 0 0 1966 0 610 310 730 3340 1370 3100 4010 2020 510 40 110 1967 0 0 50 870 1810 1800 1540 1960 3270 150 130 0 1968 10 70 50 170 1770 2320 1140 2360 5140 700 0 0 1969 0 20 290 260 1850 1990 3430 2060 3470 290 30 0 1970 0 10 90 1150 2210 3620 2610 4310 1290 340 10 0 1971 0 730 570 740 2130 3580 4060 2100 3240 510 30 170 1972 0 550 460 1280 1040 3470 3250 3640 2980 2340 20 0 1973 0 0 10 1080 2650 1990 2460 2050 2090 190 0 0 1974 400 0 60 2160 1160 2520 3070 6110 1920 570 260 0 1975 20 350 360 410 2200 3340 3230 3560 940 520 20 40 1976 0 210 380 1700 1160 1460 2430 3720 3250 780 60 0 1977 20 10 90 1000 620 620 1470 3980 4010 100 0 0 1978 0 100 920 650 1710 3690 2960 4420 2190 110 0 0 1979 10 140 50 900 2000 4230 1230 2540 2910 0 0 0 1980 0 50 190 1040 1440 3490 3310 930 6130 1830 170 20 1981 0 210 220 720 2630 4730 2490 1750 610 1260 90 0 1982 0 0 290 840 1330 2160 390 4390 3400 1720 370 0 1983 90 30 0 550 1360 2700 830 5200 1380 1680 0 0 1984 10 0 350 1270 2030 2290 2900 3880 2130 1380 650 0 1985 380 50 170 860 1100 4270 1580 3350 900 1170 0 0 1986 0 0 120 1650 2120 2210 1830 2980 1760 1700 240 10 1987 0 110 290 360 1090 4210 2670 3640 2140 1040 20 0 1988 0 30 90 1170 1130 1790 1800 3580 740 1730 0 0 1989999999999999999999999999999999999999999999999999 1990999999999999999999999999999999999999999999999999 1991 09999 105 226 1370 2079 1452 4190 3799 16109999 321 1992 328 314 150 637 1968 1906 2366 4973 1287 238 0 216 19939999 5 476 768 2438 1169 3671 2463 2215 13 229999 1994 0 781 274 409 1837 2297 1625 5755 1709 21699999999 1995 0 140 834 672 1556 1606 4439 2848 681 857 69 0 1996 12 2 660 2394 1566 1526 1960 3350 4843 724 4769999 1997 35 321 458 642 1154 2832 1197 4071 1722 1800 09999 1998 0 346 154 241 2174 3348 813 2153 2231 276 85 37 1999 63 0 182 1025 3449 1207 3681 1570 2628 299 1099999 20009999 95 48 2742 2816 1852 1725 1903 2903 391 0 0 note that the dec 1991 value is anomalous but not as extreme as the 1945 datum which would get the same treatment with normals and climatologies so should produce an even bigger spike for 1945 djf unless of course its screened out by the 4sd rule which it is well value in pre194512txt for this location anyway this is the highest value in the vietnamlaos cells for dec 1991 row col lat lon val norm 198 571 925 10575 6350 13000 with normal of 130 that makes the anomaly 4885 now im confused how can an anomalously high value be well below the 6190 mean aaarrgghhhh perhaps i should look at the highest anomaly that turns out to be 80 from here 216 563 1825 10175 180 100 not exactly show stopper time to look at the glo files which glo2abs processes into absolutes heres fareastern region with spike glod3210216567573 567 568 569 570 571 572 573 216 13936 17916 17574 17232 16745 15532 14319 215 15017 18998 19273 18931 17863 1665 15053 214 16099 20079 20972 20195 18854 17128 15402 213 13594 21161 22526 20929 19203 17477 15751 212 80145 11955 17961 1882 19552 17826 1610 211 6125 36614 56399 64987 73575 82163 9075 210 59833 90333 89649 83283 76929 70576 64223 the spike is at 213569 yes i know its the nth set of coordinates you should see the plots but looking at the anomalies is the closest well get to what tims program was doing ie calculating djf standard deviations or something now the coordinates are 1675n 10475e and wouldnt you know it our prime suspect see above is on top of it 4838300 1653 10472 138 mukdahan thailand 1934 2000 999 99900 so ok here we go with the full rundown for december 1991 in the 1675n10575e region type value comment raw data 321 highest unscreened december for this station 67 years normal 13 looks right of course very low for the target data anomaly 23692 correctly calculated gridded anomaly 22526 believable interpolation gridded actual er strangely it seems to be 0 ah well had enough it looks like its an extreme but believable event in thai station lets leave it like that rerunning precip with the new updated database pre0803271802dtb begin_quote crua6crucrutsversion_3_0primariesprecip anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required pre will calculate percentage anomalies select the cts or dtb file to load pre0803271802dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 4 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto pretxt select the firstlast years ad to save 19012006 operating tmp_mntcruautocrutsversion_3_0primariesprecippre0803271802dtb normals mean percent stdev percent dtb 7315040 738 cts 299359 30 7613600 768 process decision percent ofchk latlon 17911 02 02 normal 2355275 238 238 outofrange 13249 01 02 accepted 7521017 759 dumping years 19012006 to txt files idl quick_interp_tdm219012006preglopregrid450gs05dumpglodumpglopts_prefixpretxtpre compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1902 etc 2006 idl crua6crucrutsversion_3_0primariesprecip glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanpre enter name for the gridded climatology file clim6190lanpregrid4 enter the path and stem of the glo files preglopregrid enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files preabs now concentrate addition or percentage ap p do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 1 right erm off i jolly well go pregrid011901glo etc pregrid122006glo uealogin1crucrutsversion_3_0primariesprecip makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month preabspregridyyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeepredat now please enter the 3ch parameter code pre enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 precipitation writing cru_ts_3_0019011910predat cru_ts_3_0019011910prenc writing cru_ts_3_0019111920predat cru_ts_3_0019111920prenc writing cru_ts_3_0019211930predat cru_ts_3_0019211930prenc writing cru_ts_3_0019311940predat cru_ts_3_0019311940prenc writing cru_ts_3_0019411950predat cru_ts_3_0019411950prenc writing cru_ts_3_0019511960predat cru_ts_3_0019511960prenc writing cru_ts_3_0019611970predat cru_ts_3_0019611970prenc writing cru_ts_3_0019711980predat cru_ts_3_0019711980prenc writing cru_ts_3_0019811990predat cru_ts_3_0019811990prenc writing cru_ts_3_0019912000predat cru_ts_3_0019912000prenc writing cru_ts_3_0020012006predat cru_ts_3_0020012006prenc end_quote on to the reproduction of binaries for tmp and dtr and subsequent regeneration of vap and frs tmp binaries idl quick_interp_tdm219012006tmpbintmpbin1200gs25dumpbindumpbinbinfac10pts_prefixtmp0km0705101334txttmp defaults set 1901 compiled module mean compiled module moment compiled module stddev grid 1901 nonzero 01127 09472 13993 cells 46444 compiled module strip compiled module wrbin 1902 grid 1902 nonzero 04378 10267 14712 cells 48321 1903 grid 1903 nonzero 03462 09586 13704 cells 48803 1904 grid 1904 nonzero 04288 09753 13866 cells 49493 1905 grid 1905 nonzero 02732 09620 13722 cells 49845 1906 grid 1906 nonzero 01910 09176 13323 cells 49568 1907 grid 1907 nonzero 05290 10338 14636 cells 50458 1908 grid 1908 nonzero 03546 09165 12607 cells 50449 1909 grid 1909 nonzero 04005 09998 14222 cells 50163 1910 grid 1910 nonzero 03404 09459 13879 cells 50489 1911 grid 1911 nonzero 03868 09445 13154 cells 50752 1912 grid 1912 nonzero 04441 10156 14580 cells 51731 1913 grid 1913 nonzero 03315 09125 12647 cells 51634 1914 grid 1914 nonzero 01896 09655 14205 cells 50734 1915 grid 1915 nonzero 01935 10501 15537 cells 51773 1916 grid 1916 nonzero 03523 10092 14885 cells 52042 1917 grid 1917 nonzero 05407 11470 16613 cells 54151 1918 grid 1918 nonzero 04379 10228 14534 cells 52579 1919 grid 1919 nonzero 03663 10327 15279 cells 51872 1920 grid 1920 nonzero 02173 10092 14856 cells 50540 1921 grid 1921 nonzero 01261 09004 12767 cells 52468 1922 grid 1922 nonzero 02355 09258 13934 cells 54202 1923 grid 1923 nonzero 01942 10040 14733 cells 54975 1924 grid 1924 nonzero 01418 09416 13491 cells 55664 1925 grid 1925 nonzero 01033 10121 15038 cells 55677 1926 grid 1926 nonzero 00471 09750 14242 cells 55826 1927 grid 1927 nonzero 01290 09839 14396 cells 57033 1928 grid 1928 nonzero 00254 09581 13929 cells 56950 1929 grid 1929 nonzero 02651 11120 17327 cells 58284 1930 grid 1930 nonzero 00233 10157 15554 cells 57481 1931 grid 1931 nonzero 00072 10705 16009 cells 57932 1932 grid 1932 nonzero 00407 10426 15664 cells 57752 1933 grid 1933 nonzero 02517 11010 16794 cells 59297 1934 grid 1934 nonzero 00858 10705 16510 cells 58932 1935 grid 1935 nonzero 00383 10498 15969 cells 59316 1936 grid 1936 nonzero 00118 10867 16457 cells 59676 1937 grid 1937 nonzero 01841 10572 16419 cells 59702 1938 grid 1938 nonzero 02843 10094 14853 cells 59478 1939 grid 1939 nonzero 00828 10270 15633 cells 60643 1940 grid 1940 nonzero 01223 10033 15251 cells 60381 1941 grid 1941 nonzero 00049 10253 14988 cells 63950 1942 grid 1942 nonzero 00486 10061 15799 cells 61984 1943 grid 1943 nonzero 01795 10288 15243 cells 63082 1944 grid 1944 nonzero 01993 09783 14922 cells 62327 1945 grid 1945 nonzero 00306 10840 15827 cells 62977 1946 grid 1946 nonzero 00376 10094 14989 cells 63193 1947 grid 1947 nonzero 01326 10977 17075 cells 64854 1948 grid 1948 nonzero 00276 09783 14466 cells 66490 1949 grid 1949 nonzero 00873 10422 15665 cells 68159 1950 grid 1950 nonzero 02032 10344 15841 cells 67736 1951 grid 1951 nonzero 00537 09777 14482 cells 70202 1952 grid 1952 nonzero 00112 09952 15704 cells 69668 1953 grid 1953 nonzero 02020 10140 15735 cells 70734 1954 grid 1954 nonzero 00062 10381 16387 cells 71309 1955 grid 1955 nonzero 01527 10281 16167 cells 73181 1956 grid 1956 nonzero 02183 10542 15788 cells 77564 1957 grid 1957 nonzero 00142 09929 15067 cells 77649 1958 grid 1958 nonzero 00257 10166 15491 cells 80430 1959 grid 1959 nonzero 00019 10058 15493 cells 79903 1960 grid 1960 nonzero 00661 09628 14564 cells 80353 1961 grid 1961 nonzero 00016 09440 13960 cells 81093 1962 grid 1962 nonzero 00660 09249 14273 cells 77733 1963 grid 1963 nonzero 00850 10164 15649 cells 80869 1964 grid 1964 nonzero 03518 09639 14553 cells 82284 1965 grid 1965 nonzero 02396 09097 13315 cells 82512 1966 grid 1966 nonzero 02748 10171 15915 cells 81405 1967 grid 1967 nonzero 00372 09385 14324 cells 81573 1968 grid 1968 nonzero 02106 09665 15115 cells 81706 1969 grid 1969 nonzero 01505 10751 17496 cells 81490 1970 grid 1970 nonzero 00771 08111 11569 cells 80462 1971 grid 1971 nonzero 01102 09128 13577 cells 82451 1972 grid 1972 nonzero 01992 10147 15390 cells 82070 1973 grid 1973 nonzero 00914 09087 13303 cells 81625 1974 grid 1974 nonzero 01369 09896 15273 cells 81687 1975 grid 1975 nonzero 00400 09258 13720 cells 81390 1976 grid 1976 nonzero 02595 09596 14088 cells 82439 1977 grid 1977 nonzero 00718 09855 15405 cells 80143 1978 grid 1978 nonzero 00233 09729 15545 cells 80118 1979 grid 1979 nonzero 00921 10054 16126 cells 79714 1980 grid 1980 nonzero 01600 09471 14078 cells 80417 1981 grid 1981 nonzero 04437 10207 15695 cells 81226 1982 grid 1982 nonzero 00664 09502 14287 cells 80230 1983 grid 1983 nonzero 02325 09886 14907 cells 82258 1984 grid 1984 nonzero 00904 10216 16368 cells 81431 1985 grid 1985 nonzero 00625 09590 15123 cells 81731 1986 grid 1986 nonzero 01007 08952 13674 cells 81016 1987 grid 1987 nonzero 01116 09654 14412 cells 84529 1988 grid 1988 nonzero 03365 09242 13069 cells 82070 1989 grid 1989 nonzero 02451 10428 16170 cells 79951 1990 grid 1990 nonzero 04275 10581 15828 cells 82418 1991 grid 1991 nonzero 04279 09504 13005 cells 80068 1992 grid 1992 nonzero 00265 09827 14543 cells 80204 1993 grid 1993 nonzero 01614 09820 14965 cells 78945 1994 grid 1994 nonzero 02598 09699 13958 cells 77509 1995 grid 1995 nonzero 05222 10500 15943 cells 80001 1996 grid 1996 nonzero 03733 09745 14383 cells 78304 1997 grid 1997 nonzero 03947 10250 14473 cells 80450 1998 grid 1998 nonzero 06010 11707 15968 cells 82794 1999 grid 1999 nonzero 04249 10485 15105 cells 80640 2000 grid 2000 nonzero 04574 10256 14596 cells 78883 2001 grid 2001 nonzero 05695 10596 14876 cells 78391 2002 grid 2002 nonzero 06281 11662 16404 cells 80200 2003 grid 2003 nonzero 06715 10531 13475 cells 77636 2004 grid 2004 nonzero 05362 09762 12947 cells 79600 2005 grid 2005 nonzero 08050 11350 14605 cells 80465 2006 stations found in tmp0km0705101334txttmp200611txt stations found in tmp0km0705101334txttmp200612txt grid 2006 nonzero 06621 11017 15361 cells 65396 idl dtr binaries idl quick_interp_tdm219012006dtrbindtrbin750gs25dumpbindumpbinbinfac10pts_prefixdtrtxtdtr compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module mean compiled module moment compiled module stddev grid 1901 nonzero 03357 08741 11669 cells 18526 compiled module strip compiled module wrbin 1902 grid 1902 nonzero 02560 08530 11640 cells 19088 1903 grid 1903 nonzero 02015 08514 11841 cells 19063 1904 grid 1904 nonzero 02647 08584 11827 cells 19155 1905 grid 1905 nonzero 01753 09056 12595 cells 20808 1906 grid 1906 nonzero 02458 09003 12127 cells 20892 1907 grid 1907 nonzero 02658 09124 12370 cells 21621 1908 grid 1908 nonzero 03003 08911 11912 cells 22028 1909 grid 1909 nonzero 02063 08791 11952 cells 22253 1910 grid 1910 nonzero 02524 08563 11561 cells 23297 1911 grid 1911 nonzero 02317 08808 12201 cells 24153 1912 grid 1912 nonzero 01748 09544 13196 cells 24284 1913 grid 1913 nonzero 01990 09047 12463 cells 24366 1914 grid 1914 nonzero 01395 09195 12747 cells 24431 1915 grid 1915 nonzero 00185 09405 12969 cells 26178 1916 grid 1916 nonzero 00178 08761 11904 cells 27095 1917 grid 1917 nonzero 01518 09108 12619 cells 26614 1918 grid 1918 nonzero 01303 09134 12533 cells 26447 1919 grid 1919 nonzero 01300 08856 12029 cells 25701 1920 grid 1920 nonzero 00500 08480 11650 cells 26563 1921 grid 1921 nonzero 01660 08213 11246 cells 26549 1922 grid 1922 nonzero 01133 08468 11707 cells 26701 1923 grid 1923 nonzero 01794 08962 12293 cells 27643 1924 grid 1924 nonzero 01309 08549 11583 cells 28642 1925 grid 1925 nonzero 02252 09167 12254 cells 28841 1926 grid 1926 nonzero 01076 08559 11687 cells 30671 1927 grid 1927 nonzero 01285 08715 11766 cells 30962 1928 grid 1928 nonzero 01279 08576 11773 cells 31156 1929 grid 1929 nonzero 01784 08826 11974 cells 32021 1930 grid 1930 nonzero 01344 08711 11830 cells 33360 1931 grid 1931 nonzero 00238 08470 11548 cells 32726 1932 grid 1932 nonzero 00872 08489 11546 cells 33396 1933 grid 1933 nonzero 01012 08560 11597 cells 34574 1934 grid 1934 nonzero 00295 08591 11676 cells 34203 1935 grid 1935 nonzero 01092 08682 11665 cells 34561 1936 grid 1936 nonzero 02106 08947 12055 cells 35632 1937 grid 1937 nonzero 01686 08463 11182 cells 35921 1938 grid 1938 nonzero 00845 08242 11125 cells 35718 1939 grid 1939 nonzero 01428 08362 11277 cells 37525 1940 grid 1940 nonzero 01891 08662 11493 cells 38227 1941 grid 1941 nonzero 01334 08502 11411 cells 38486 1942 grid 1942 nonzero 01176 08344 11001 cells 39312 1943 grid 1943 nonzero 01844 08476 11191 cells 40361 1944 grid 1944 nonzero 01564 08195 10904 cells 40010 1945 grid 1945 nonzero 01566 08164 10740 cells 40172 1946 grid 1946 nonzero 01648 08529 11288 cells 40305 1947 grid 1947 nonzero 00668 08305 11166 cells 41045 1948 grid 1948 nonzero 02204 08015 10473 cells 41004 1949 grid 1949 nonzero 01192 08185 11029 cells 41329 1950 grid 1950 nonzero 01349 07915 10675 cells 42803 1951 grid 1951 nonzero 01881 08003 10647 cells 47064 1952 grid 1952 nonzero 01751 07776 10556 cells 46868 1953 grid 1953 nonzero 01331 07763 10518 cells 48129 1954 grid 1954 nonzero 00824 07668 10349 cells 47912 1955 grid 1955 nonzero 00963 07733 10468 cells 49105 1956 grid 1956 nonzero 00901 07695 10440 cells 50637 1957 grid 1957 nonzero 00689 07536 10279 cells 50456 1958 grid 1958 nonzero 00050 07504 10291 cells 52013 1959 grid 1959 nonzero 00439 07329 10020 cells 52162 1960 grid 1960 nonzero 00674 07049 09542 cells 52787 1961 grid 1961 nonzero 00445 06810 09111 cells 56188 1962 grid 1962 nonzero 01297 06877 09156 cells 54897 1963 grid 1963 nonzero 01449 07088 09661 cells 55755 1964 grid 1964 nonzero 00955 06719 09029 cells 54909 1965 grid 1965 nonzero 00913 06638 08950 cells 54906 1966 grid 1966 nonzero 00878 06566 08813 cells 54751 1967 grid 1967 nonzero 00805 06626 08876 cells 54393 1968 grid 1968 nonzero 00826 06611 08923 cells 54602 1969 grid 1969 nonzero 00253 06787 09309 cells 55176 1970 grid 1970 nonzero 00576 06232 08301 cells 55444 1971 grid 1971 nonzero 00987 06340 08426 cells 54610 1972 grid 1972 nonzero 00472 06631 08979 cells 55812 1973 grid 1973 nonzero 00287 06424 08741 cells 54755 1974 grid 1974 nonzero 00119 06782 09289 cells 56105 1975 grid 1975 nonzero 00287 06259 08458 cells 54696 1976 grid 1976 nonzero 00740 06565 08966 cells 55239 1977 grid 1977 nonzero 00454 06600 09026 cells 54227 1978 grid 1978 nonzero 01045 06529 08775 cells 55036 1979 grid 1979 nonzero 00749 06510 08753 cells 54990 1980 grid 1980 nonzero 00565 06269 08300 cells 55430 1981 grid 1981 nonzero 00498 06704 08970 cells 55023 1982 grid 1982 nonzero 00828 06622 08874 cells 56028 1983 grid 1983 nonzero 01380 06808 09142 cells 55854 1984 grid 1984 nonzero 01530 06675 08850 cells 55751 1985 grid 1985 nonzero 01156 06359 08438 cells 55066 1986 grid 1986 nonzero 00822 06412 08583 cells 55111 1987 grid 1987 nonzero 00579 06599 08919 cells 55607 1988 grid 1988 nonzero 00691 06615 08752 cells 54503 1989 grid 1989 nonzero 00165 06685 09064 cells 55615 1990 grid 1990 nonzero 00655 06734 09057 cells 54497 1991 grid 1991 nonzero 00899 06602 08722 cells 53533 1992 grid 1992 nonzero 01171 06951 09349 cells 53739 1993 grid 1993 nonzero 01314 06882 09188 cells 51271 1994 grid 1994 nonzero 00480 06934 09282 cells 50211 1995 grid 1995 nonzero 00357 07596 12498 cells 52366 1996 grid 1996 nonzero 00723 07666 11579 cells 51667 1997 grid 1997 nonzero 01340 07854 11636 cells 52195 1998 grid 1998 nonzero 01627 08328 11992 cells 52907 1999 grid 1999 nonzero 01237 07134 09716 cells 51050 2000 grid 2000 nonzero 01765 07575 10412 cells 51137 2001 grid 2001 nonzero 01305 07564 10658 cells 49146 2002 grid 2002 nonzero 00984 07549 10967 cells 46178 2003 grid 2003 nonzero 01072 07128 10087 cells 46904 2004 grid 2004 nonzero 01628 08113 12574 cells 47399 2005 grid 2005 nonzero 01150 08546 13540 cells 43715 2006 stations found in dtrtxtdtr200609txt stations found in dtrtxtdtr200610txt stations found in dtrtxtdtr200611txt stations found in dtrtxtdtr200612txt grid 2006 nonzero 00087 09041 16077 cells 28592 idl vap synthetics idl vap_gts_anomdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixvapsynvapsyndumpbin1 compiled module vap_gts_anom compiled module rdbin compiled module strip compiled module defxyz landsea 56016 68400 calculating tmn normal compiled module tvap calculating synthetic vap normal compiled module esat calculating synthetic anomalies compiled module moment 1901 vap xs2 00450600 0230521 450663 492927 compiled module wrbin 1902 vap xs2 0102633 0271200 414974 492341 1903 vap xs2 0107597 0242152 574305 558190 1904 vap xs2 0123137 0221801 430042 371240 1905 vap xs2 00799978 0267905 454584 604190 1906 vap xs2 00343380 0240282 486007 645160 1907 vap xs2 0137421 0284412 506625 602255 1908 vap xs2 0105214 0234139 699258 515916 1909 vap xs2 0103285 0252210 548791 512214 1910 vap xs2 0104377 0225462 464360 719087 1911 vap xs2 0109270 0255412 435549 699751 1912 vap xs2 0127306 0287857 463037 584822 1913 vap xs2 0107747 0271437 473097 498110 1914 vap xs2 00481493 0274125 443114 619318 1915 vap xs2 00343964 0332448 531914 604190 1916 vap xs2 00947238 0293859 631417 463692 1917 vap xs2 0170714 0396007 869476 386362 1918 vap xs2 0133214 0311174 548035 619711 1919 vap xs2 00687798 0307508 614869 928416 1920 vap xs2 00619862 0262944 576398 410598 1921 vap xs2 00319013 0301257 573133 707691 1922 vap xs2 00621843 0231719 503104 418061 1923 vap xs2 00626035 0285980 570781 732851 1924 vap xs2 00720660 0281999 488423 732851 1925 vap xs2 00673457 0292218 570781 866163 1926 vap xs2 00264075 0297545 488423 607568 1927 vap xs2 00400396 0277274 426864 946017 1928 vap xs2 00376556 0250591 488423 432885 1929 vap xs2 00885709 0313796 552846 563952 1930 vap xs2 00261154 0252065 493317 576016 1931 vap xs2 000818994 0340814 513082 625571 1932 vap xs2 0000556678 0290796 436993 639834 1933 vap xs2 00732750 0299654 485280 568388 1934 vap xs2 00230768 0306463 427863 618267 1935 vap xs2 00294056 0256452 408567 528612 1936 vap xs2 00166144 0312561 476875 614991 1937 vap xs2 000628125 0273150 494706 810473 1938 vap xs2 00538196 0277858 383216 516185 1939 vap xs2 00101522 0261258 426058 609505 1940 vap xs2 00340492 0270330 528004 499802 1941 vap xs2 000272590 0359517 430990 786635 1942 vap xs2 00107379 0256225 431849 504972 1943 vap xs2 000847952 0306959 405096 509181 1944 vap xs2 00135632 0286842 632264 544941 1945 vap xs2 00348352 0339675 577718 611337 1946 vap xs2 00308651 0304056 639576 689301 1947 vap xs2 00119494 0347709 452023 791578 1948 vap xs2 000279501 0269904 420986 868827 1949 vap xs2 00392110 0341484 571766 629158 1950 vap xs2 00805553 0315878 460512 989166 1951 vap xs2 00455985 0286749 521167 509294 1952 vap xs2 00285279 0310278 619114 591316 1953 vap xs2 00164626 0328090 510127 691089 1954 vap xs2 00270003 0325794 460512 586057 1955 vap xs2 00427618 0309960 632375 567290 1956 vap xs2 0141589 0324435 533854 430108 1957 vap xs2 00322534 0290902 651552 547146 1958 vap xs2 000254215 0284311 456239 524883 1959 vap xs2 00136386 0273182 456765 710322 1960 vap xs2 00268859 0251590 474454 561688 1961 vap xs2 000428266 0256116 358335 509660 1962 vap xs2 00169736 0241635 513969 488660 1963 vap xs2 00132022 0280225 486808 625239 1964 vap xs2 00801179 0230050 437340 566511 1965 vap xs2 00818651 0255070 492358 556393 1966 vap xs2 00280720 0231274 594548 555636 1967 vap xs2 00181908 0260895 450197 560940 1968 vap xs2 00724171 0263899 734842 457032 1969 vap xs2 00251546 0277463 545023 564616 1970 vap xs2 00310875 0183015 520684 472542 1971 vap xs2 00584375 0247623 425373 545411 1972 vap xs2 00703370 0291676 458312 534509 1973 vap xs2 00333626 0249423 492304 440218 1974 vap xs2 00588555 0269075 521312 779163 1975 vap xs2 00141657 0248957 568768 699932 1976 vap xs2 0122256 0269952 663680 387281 1977 vap xs2 00307466 0242061 442668 459490 1978 vap xs2 00234150 0225811 553217 565761 1979 vap xs2 00121905 0234581 381796 811386 1980 vap xs2 00243552 0225838 495252 100661 1981 vap xs2 00730062 0273207 621452 502121 1982 vap xs2 000410785 0225016 432441 582923 1983 vap xs2 00990013 0349267 566664 711964 1984 vap xs2 00240819 0257495 472244 545411 1985 vap xs2 000794266 0232222 408511 598364 1986 vap xs2 00247494 0226368 453393 649533 1987 vap xs2 00702606 0326509 649176 565761 1988 vap xs2 0108340 0262510 471399 524402 1989 vap xs2 00558202 0259338 543051 526850 1990 vap xs2 0142205 0288092 508627 454985 1991 vap xs2 0123237 0286160 473092 781615 1992 vap xs2 000923000 0309573 460065 787882 1993 vap xs2 00506631 0270131 438424 570831 1994 vap xs2 0119075 0311620 341067 564707 1995 vap xs2 0153732 0311293 512451 616339 1996 vap xs2 00641272 0281972 707159 534453 1997 vap xs2 0171295 0432609 605247 783205 1998 vap xs2 0316044 0580134 570816 681637 1999 vap xs2 0154989 0339337 584341 500767 2000 vap xs2 0151733 0320928 567183 519904 2001 vap xs2 0207467 0427043 560383 106589 2002 vap xs2 0224772 0487041 109627 106589 2003 vap xs2 0230009 0420027 431180 660522 2004 vap xs2 0196860 0370951 688193 991745 2005 vap xs2 0294053 0485357 108553 702645 2006 vap xs2 0193683 0411812 628115 919209 idl vap gridding idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynth_prefixvapsynvapsynpts_prefixvaptxtvap compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc 2006 idl vap gridded absolutes crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid4 enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 4 right erm off i jolly well go vap011901glo etc vap122006glo vap output files uealogin1crucrutsversion_3_0secondariesvap makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapyyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeevapdat now please enter the 3ch parameter code vap enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 vapour pressure writing cru_ts_3_0019011910vapdat cru_ts_3_0019011910vapnc writing cru_ts_3_0019111920vapdat cru_ts_3_0019111920vapnc writing cru_ts_3_0019211930vapdat cru_ts_3_0019211930vapnc writing cru_ts_3_0019311940vapdat cru_ts_3_0019311940vapnc writing cru_ts_3_0019411950vapdat cru_ts_3_0019411950vapnc writing cru_ts_3_0019511960vapdat cru_ts_3_0019511960vapnc writing cru_ts_3_0019611970vapdat cru_ts_3_0019611970vapnc writing cru_ts_3_0019711980vapdat cru_ts_3_0019711980vapnc writing cru_ts_3_0019811990vapdat cru_ts_3_0019811990vapnc writing cru_ts_3_0019912000vapdat cru_ts_3_0019912000vapnc writing cru_ts_3_0020012006vapdat cru_ts_3_0020012006vapnc frs synthetics idl frs_gtsdtr_prefixdtrbindtrbintmp_prefixtmpbintmpbin19012006outprefixfrssynfrssyn compiled module rdbin compiled module strip filesize 6220800 gridsize 0500000 compiled module defxyz calculating synthetic frs normal 1961 filesize 248832 gridsize 250000 etc 1990 filesize 248832 gridsize 250000 compiled module days calculating synthetic anomalies 1901 filesize 248832 gridsize 250000 etc 2006 filesize 248832 gridsize 250000 idl frs gridding idl quick_interp_tdm219012006frsgridfrsgrid750gs05dumpglodumpglonostn1synth_prefixfrssynfrssyn compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip ls frssynfrssyn1901 not found ls frssynfrssyn1901z not found found frssynfrssyn1901gz compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 ls frssynfrssyn1902 not found ls frssynfrssyn1902z not found found frssynfrssyn1902gz etc 2006 ls frssynfrssyn2006 not found ls frssynfrssyn2006z not found found frssynfrssyn2006gz idl vap problems again this time its too high sigh tim suggested the synthfac parameter in quick_interp_tdm2 the note for it says multi factor to obtain synth file actual values so i reckon it should be 01 but was wrong the note is misleading at best since the actual code looks like this dummygriddummygridsynthfac so the factor should be 10 idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynthfac10synth_prefixvapsynvapsynpts_prefixvaptxtvap compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc 2006 idl crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid9 enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 1 right erm off i jolly well go vap190101glo etc vap200612glo uealogin1crucrutsversion_3_0secondariesvap makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapyyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeevapdat now please enter the 3ch parameter code vap enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 vapour pressure writing cru_ts_3_0019011910vapdat cru_ts_3_0019011910vapnc writing cru_ts_3_0019111920vapdat cru_ts_3_0019111920vapnc writing cru_ts_3_0019211930vapdat cru_ts_3_0019211930vapnc writing cru_ts_3_0019311940vapdat cru_ts_3_0019311940vapnc writing cru_ts_3_0019411950vapdat cru_ts_3_0019411950vapnc writing cru_ts_3_0019511960vapdat cru_ts_3_0019511960vapnc writing cru_ts_3_0019611970vapdat cru_ts_3_0019611970vapnc writing cru_ts_3_0019711980vapdat cru_ts_3_0019711980vapnc writing cru_ts_3_0019811990vapdat cru_ts_3_0019811990vapnc writing cru_ts_3_0019912000vapdat cru_ts_3_0019912000vapnc writing cru_ts_3_0020012006vapdat cru_ts_3_0020012006vapnc redoing frs as well idl quick_interp_tdm219012006frsgridfrsgrid750gs05dumpglodumpglonostn1synthfac10synth_prefixfrssynfrssyn compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc 2006 idl also redoing wetrd0 idl quick_interp_tdm219012006prebinprebin450gs25dumpbindumpbinbinfac10pts_prefixpretxtpre compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module mean compiled module moment compiled module stddev grid 1901 nonzero 02703 380775 726735 cells 36537 compiled module strip compiled module wrbin 1902 grid 1902 nonzero 18369 388160 1050312 cells 37346 etc 2006 stations found in pretxtpre200609txt stations found in pretxtpre200610txt stations found in pretxtpre200611txt stations found in pretxtpre200612txt grid 2006 nonzero 22381 388997 700935 cells 32663 idl there then followed produciton run for wet resulting in unrealistic banded output this was tracked down to the sythetic gridder rd0_gts_tdmpro using halfdegree normals with 25degree output so it was modified to read the 25 normals and rerun idl compile crucrutsversion_3_0badc_areaprogramsidlrd0_gts_tdmpro compiled module rd0_gts idl rd0_gts1901200619611990outprefixrd0synrd0synpre_prefixprebinprebin reading precip and rd0 normals compiled module rdbin compiled module strip yes filesize 248832 gridsize 250000 compiled module defxyz yes filesize 248832 gridsize 250000 compiled module days calculating synthetic rd0 normal 1961 filesize 248832 gridsize 250000 etc 1990 filesize 248832 gridsize 250000 calculating synthetic anomalies 1901 filesize 248832 gridsize 250000 compiled module wrbin 1902 etc 2006 filesize 248832 gridsize 250000 program caused arithmetic error floating divide by 0 program caused arithmetic error floating illegal operand idl which is what happened last time and again all synthetics produced apparently ok i think its just the last few empty months of 2006 idl quick_interp_tdm219012006rd0pcglord0pc450gs05dumpglodumpglosynth_prefixrd0synrd0synsynthfac10pts_prefixrd0pctxtrd0pc compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc 2006 idl crua6crucrutsversion_3_0secondarieswet glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file clim6190lanwetgrid4 enter the path and stem of the glo files rd0pcglord0pc enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0pcabs now concentrate addition or percentage ap p do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 3 right erm off i jolly well go rd0pcglord0pc011901glo rd0pcglord0pc190101glo rd0pc190101glo etc rd0pc200612glo uealogin1crucrutsversion_3_0secondarieswet makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0pcabsrd0pcyyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeewetdat now please enter the 3ch parameter code wet enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 rain days writing cru_ts_3_0019011910wetdat cru_ts_3_0019011910wetnc writing cru_ts_3_0019111920wetdat cru_ts_3_0019111920wetnc writing cru_ts_3_0019211930wetdat cru_ts_3_0019211930wetnc writing cru_ts_3_0019311940wetdat cru_ts_3_0019311940wetnc writing cru_ts_3_0019411950wetdat cru_ts_3_0019411950wetnc writing cru_ts_3_0019511960wetdat cru_ts_3_0019511960wetnc writing cru_ts_3_0019611970wetdat cru_ts_3_0019611970wetnc writing cru_ts_3_0019711980wetdat cru_ts_3_0019711980wetnc writing cru_ts_3_0019811990wetdat cru_ts_3_0019811990wetnc writing cru_ts_3_0019912000wetdat cru_ts_3_0019912000wetnc writing cru_ts_3_0020012006wetdat cru_ts_3_0020012006wetnc vap three stations deleted with unbelievable data 6450000 45 942 15 librevilleleon mba gabon 1979 2007 999 999 6451000 208 1148 599 bitam gabon 1971 2007 999 999 6275000 1400 3233 378 ed dueim sudan 1971 2007 999 999 vap then rerun with new database vap0804231150dtb crua6crucrutsversion_3_0secondariesvap anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required vap select the cts or dtb file to load vap0804231150dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 select outputs 1cts2ann3txt4stn 3 check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto vaptxt select the firstlast years ad to save 19012006 operating normals mean percent stdev percent dtb 907894 452 cts 35390 18 943284 470 process decision percent ofchk latlon 105 00 00 normal 1064261 530 530 outofrange 49 00 00 accepted 943235 470 dumping years 19012006 to txt files idl quick_interp_tdm219012006vapglovap1000gs05dumpglodumpglosynthfac10synth_prefixvapsynvapsynpts_prefixvaptxtvap compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 2006 idl crua6crucrutsversion_3_0secondariesvap glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanvap enter name for the gridded climatology file clim6190lanvapgrid2 enter the path and stem of the glo files vapglovap enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files vapabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 1 right erm off i jolly well go vapglovap011901glo vapglovap190101glo vap190101glo etc vap200612glo uealogin1crucrutsversion_3_0secondariesvap makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month vapabsvapyyyynngloabs enter gridfile with yyyy for year and mm for month vapabsvapyyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeevapdat now please enter the 3ch parameter code vap enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 vapour pressure writing cru_ts_3_0019011910vapdat cru_ts_3_0019011910vapnc writing cru_ts_3_0019111920vapdat cru_ts_3_0019111920vapnc writing cru_ts_3_0019211930vapdat cru_ts_3_0019211930vapnc writing cru_ts_3_0019311940vapdat cru_ts_3_0019311940vapnc writing cru_ts_3_0019411950vapdat cru_ts_3_0019411950vapnc writing cru_ts_3_0019511960vapdat cru_ts_3_0019511960vapnc writing cru_ts_3_0019611970vapdat cru_ts_3_0019611970vapnc writing cru_ts_3_0019711980vapdat cru_ts_3_0019711980vapnc writing cru_ts_3_0019811990vapdat cru_ts_3_0019811990vapnc writing cru_ts_3_0019912000vapdat cru_ts_3_0019912000vapnc writing cru_ts_3_0020012006vapdat cru_ts_3_0020012006vapnc next round of problems well vap finally looks ok which is good news wet looks better but variability is still too low its complicated by the synthetic elements in combination with percentage anomalies i found that i could examine the mark new binary files with matlab using ie fid fopenglo25rd06190r dc freadfidinfint16 whos name size bytes class c 1x1 8 double array d 124416x1 995328 double array fid 1x1 8 double array grand total is 124418 elements using 995344 bytes c c 124416 mind ans 0 maxd ans 303 hmeand ans 1237939 so we can deduce that the rd0 25 degree normals are in days10 similarly for the others of interest file min max mean units glo25rd06190 0 303 106 days10 glo25pre6190 0 391 21 mm glord0norm 0 310 124 days10 gloprenorm 0 1244 58 mm clim6190lanwetgrid 0 3090 1018 days100 clim6190lanpregrid 0 12430 574 mm10 my guess is that glo25pre6190 has lower max because the wider coverage of each cell is squashing the peaks so an experimental run with halfdegree synthetics first generate halfdegree binaries for pre idl quick_interp_tdm219012006prebin05prebin05450gs05dumpbindumpbinbinfac10pts_prefixpretxtpre compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module map_set compiled module crossp compiled module mean compiled module moment compiled module stddev grid 1901 nonzero 00524 380853 759241 cells 921834 etc then regenerate synthetic rd0 on halfdegree grid idl rd0_gts1901200619611990outprefixrd0syn05rd0synpre_prefixprebin05prebin05 reading precip and rd0 normals yes filesize 248832 gridsize 250000 yes filesize 248832 gridsize 250000 calculating synthetic rd0 normal 1961 yes filesize 6220800 gridsize 0500000 etc as before but with appropriately larger numbers 2006 filesize 6220800 gridsize 0500000 program caused arithmetic error floating divide by 0 program caused arithmetic error floating illegal operand idl then the gridding using the new halfdegree synthetics idl quick_interp_tdm219012006rd0pcglo05rd0pc05450gs05dumpglodumpglosynth_prefixrd0syn05rd0synsynthfac10pts_prefixrd0pctxtrd0pc compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc right stop all that tim has recalculated the 25degree binary normals for pre from half degree and wet from ts 21 so time to try out the other synthetic rd0 generator the one that reads precip anomalies idl compile badc_areaprogramsidlrd0_gts_anompro compiled module rd0_gts_anom idl compile badc_areaprogramsidl error opening file file badc_areaprogramsidl such file or directory idl compile badc_areaprogramsidlrdbinpro compiled module rdbin idl rd0_gts_anom1901200619611990outprefixrd0synrd0synpre_prefixprebinprebin reading precip and rd0 normals compiled module strip compiled module defxyz compiled module days calculating synthetic rd0 normal compiled module rd0cal calculating synthetic rd0 anomalies idl idl quick_interp_tdm219012006rd0glord0450gs05dumpglodumpglosynth_prefixrd0synrd0synsynthfac10pts_prefixrd0pctxtrd0pc compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc 2006 idl crua6crucrutsversion_3_0secondarieswet glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file clim6190lanwetgrid7 enter the path and stem of the glo files rd0glord0 enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0abs now concentrate addition or percentage ap p do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 3 right erm off i jolly well go rd0glord0011901glo rd0glord0190101glo rd0011901glo etc rd0122006glo uealogin1crucrutsversion_3_0secondarieswet makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0absrd0yyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeewetdat now please enter the 3ch parameter code wet enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 wet days writing cru_ts_3_0019011910wetdat cru_ts_3_0019011910wetnc writing cru_ts_3_0019111920wetdat cru_ts_3_0019111920wetnc writing cru_ts_3_0019211930wetdat cru_ts_3_0019211930wetnc writing cru_ts_3_0019311940wetdat cru_ts_3_0019311940wetnc writing cru_ts_3_0019411950wetdat cru_ts_3_0019411950wetnc writing cru_ts_3_0019511960wetdat cru_ts_3_0019511960wetnc writing cru_ts_3_0019611970wetdat cru_ts_3_0019611970wetnc writing cru_ts_3_0019711980wetdat cru_ts_3_0019711980wetnc writing cru_ts_3_0019811990wetdat cru_ts_3_0019811990wetnc writing cru_ts_3_0019912000wetdat cru_ts_3_0019912000wetnc writing cru_ts_3_0020012006wetdat cru_ts_3_0020012006wetnc wrong again the saga continues actually im beginning to wonder if itll still be going when i join saga this time the real areas have variability 10x too low and the synthetic areas have variability sqrt10 too low the latter can be explained by the binary precip being in age anoms 10 so rd0_gts_anompro modified to divide by 1000 when calculating instead of 100 example from the normals calculation before pregrdnlandpregrdnland100010prenormnland make pre anom into abs after pregrdnlandpregrdnland1000010prenormnland make pre anom into abs mm synthfac10 will also not be needed in the final gridding that should take care of the real area variability so idl compile badc_areaprogramsidlrd0_gts_anompro compiled module rd0_gts_anom idl compile badc_areaprogramsidlrdbinpro compiled module rdbin idl rd0_gts_anom1901200619611990outprefixrd0synrd0synpre_prefixprebinprebin reading precip and rd0 normals compiled module strip compiled module defxyz compiled module days calculating synthetic rd0 normal compiled module rd0cal calculating synthetic rd0 anomalies compiled module wrbin idl idl quick_interp_tdm219012006rd0glord0450gs05dumpglodumpglosynth_prefixrd0synrd0synpts_prefixrd0pctxtrd0pc snip that didnt work real areas 10x too small synth areas ok though so idl quick_interp_tdm219012006rd0glord0anomfac10450gs05dumpglodumpglosynth_prefixrd0synrd0synpts_prefixrd0pctxtrd0pc compiled module quick_interp_tdm2 compiled module glimit defaults set 1901 compiled module rdbin compiled module strip compiled module defxyz compiled module map_set compiled module crossp compiled module saveglo compiled module selectmodel 1902 etc 2006 idl crua6crucrutsversion_3_0secondarieswet glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file clim6190lanwetgrid9 enter the path and stem of the glo files rd0glord0 enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0abs now concentrate addition or percentage ap p do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 3 right erm off i jolly well go rd0glord0011901glo rd0glord0190101glo rd0190101glo etc rd0200612glo uealogin1crucrutsversion_3_0secondarieswet makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0absrd0yyyymmgloabs enter start year 1901 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeewetdat now please enter the 3ch parameter code wet enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 rain days writing cru_ts_3_0019011910wetdat cru_ts_3_0019011910wetnc writing cru_ts_3_0019111920wetdat cru_ts_3_0019111920wetnc writing cru_ts_3_0019211930wetdat cru_ts_3_0019211930wetnc writing cru_ts_3_0019311940wetdat cru_ts_3_0019311940wetnc writing cru_ts_3_0019411950wetdat cru_ts_3_0019411950wetnc writing cru_ts_3_0019511960wetdat cru_ts_3_0019511960wetnc writing cru_ts_3_0019611970wetdat cru_ts_3_0019611970wetnc writing cru_ts_3_0019711980wetdat cru_ts_3_0019711980wetnc writing cru_ts_3_0019811990wetdat cru_ts_3_0019811990wetnc writing cru_ts_3_0019912000wetdat cru_ts_3_0019912000wetnc writing cru_ts_3_0020012006wetdat cru_ts_3_0020012006wetnc hmmm still some problems in several areas including swathe of russia the mean values drop around 1991 just when mcdw comes in targeted the area and found several candidates uealogin1crucrutsversion_3_0dbrd0 getllstations getcellstations extracts stations from cru ts database please define the bounding box in tenths of degree ie 55 degrees north would be 550 southern edge 900 to 899 570 northern edge 570 to 900 630 western edge 1800 to 1799 900 eastern edge 900 to 1800 1050 enter the cru ts database file wet0710161148dtb and finally an output filename wet071016114857_63n90_105edat done found 7 matching stations out of 6143 2388400 6160 9000 63 bor russia asia 1936 2007 999 999 2389100 6167 9637 261 bajkit russia asia 1936 2007 999 999 2490800 6033 10227 260 vanavara russia asia 1936 2007 999 999 2926300 5845 9215 78 jenisejsk russia asia 1936 2007 999 999 2928200 5842 9740 134 bogucany russia asia 1936 2007 999 999 2398600 6047 9302 521 severojenisejsk russia asia 2004 2007 999 0 2937900 5720 9488 147 tasejeva river russia asia 2004 2007 999 0 the last two are too short to have any meaning the second and third have missing data over the entire period of concern that leaves bor jenisejsk and bogucany the latter of which well examine closer heres the series lifted directly from wet0710161148dtb 2928200 5842 9740 134 bogucany russia asia 1936 2007 999 999 6190999999999999999999999999999999999999999999999999 1936 1200 500 800 500 1100 1400 900 1200 400 1300 1600 1700 1937 1400 1000 1300 400 800 1200 1100 1300 1800 2000 1300 1000 1938 1100 1100 500 1000 1000 800 600 1300 1400 2300 1800 1500 1939 1200 700 900 700 1500 1300 1100 1600 800 1900 1800 1900 1940 800 1500 500 1400 1400 1300 1400 1600 1500 2400 2000 1600 1941 2200 1500 1800 1100 1400 1300 1700 1600 900 1600 1900 1700 1942 1100 1600 1500 1100 1000 1900 600 1600 500 2000 1700 1900 1943 1000 1000 800 0 1500 1100 1000 1100 1200 2000 2100 2100 1944 1300 1100 1100 400 1400 12009999 1100 1500 1600 2000 2900 1945 2100 900 10009999 900 2100 1700 1200 900 1700 1900 1600 1946 2400 1400 1500 1000 1800 1700 1300 1800 700 1700 2200 2300 1947 1400 1300 1700 1500 900 600 1000 700 2000 600 1300 1200 1948 1700 1100 900 1100 1100 1100 1100 1900 1400 1300 1200 1500 1949 2100 1100 1000 700 1900 1600 800 1500 1600 1100 1600 1200 1950 1500 1100 800 800 1400 600 600 800 1600 1500 1900 2500 1951 1100 1200 1400 500 1000 1400 1200 2000 1100 1400 1100 1400 1952 1500 1200 1100 700 1600 1100 1300 1200 1200 2100 1200 1300 1953 1200 600 1300 700 800 800 1100 1100 1400 2100 1500 2100 1954 1900 1300 1100 1100 800 400 1700 1100 1300 1800 2000 1500 1955 1100 1600 1100 1000 1500 1400 1000 1100 1500 1400 1600 2000 1956 1800 1200 1000 1200 800 900 1900 800 1100 2100 800 1200 1957 1200 300 700 1200 1300 900 1300 1200 1700 1700 1900 2200 1958 2000 1000 1200 900 1400 1100 800 1000 1200 2000 2200 1900 1959 2100 1000 900 1400 1800 700 1600 1300 1300 1600 2300 1900 1960 1700 1800 1000 1600 1000 1500 1400 1500 2300 1100 1900 1200 1961 1700 1400 600 500 1000 1400 1400 1700 1800 1500 1600 1800 1962 1200 1300 700 700 800 1000 1300 1200 1200 900 2100 2000 1963 900 600 700 800 1300 1000 1300 1300 1400 1300 1100 2100 1964 1000 800 1200 500 800 1400 1000 800 700 1900 1000 2300 1965 1500 1100 800 500 1000 1100 800 1500 1900 1200 1600 1400 1966 2100 2100 1400 1000 1800 1200 1000 1000 1200 2100 2700 2400 1967 1800 1700 900 900 1200 900 1100 1100 800 1100 1300 1700 1968 1000 1500 800 900 800 1700 600 1200 1600 800 2200 1400 1969 1400 1500 1000 1500 1300 1300 1100 1100 1400 1200 1500 1700 1970 2000 1300 200 1000 1100 900 1100 1700 900 1500 1500 1800 1971 2100 900 1300 700 1200 500 1000 1600 2000 1400 1600 1600 1972 1600 1600 800 500 1400 1200 600 1700 1600 1500 2400 2300 1973 1400 1200 1600 1600 1200 900 1000 1400 600 800 1700 1800 1974 1800 1400 900 1100 1500 1400 1000 1500 1500 1700 2100 2200 1975 2600 1500 1100 1000 1200 1200 1100 1700 1300 1200 2200 1200 1976 1300 1400 1000 600 1300 600 700 1300 1800 1900 1900 1800 1977 1800 1100 2000 900 1400 1400 900 1700 1000 1600 2500 1600 1978 2500 1100 1000 1300 900 1400 1100 1300 1300 1500 1600 2000 1979 2100 1700 1900 1200 1200 600 600 1500 1000 2200 2400 1500 1980 1700 1100 600 700 900 1100 1300 800 1300 1500 2100 2200 1981 1600 1800 1100 1200 1300 700 1100 1200 1200 1300 1300 1800 1982 1300 1000 1500 800 1200 1300 1700 1400 1700 1800 2800 2500 1983 2200 1200 1400 1700 1200 1000 700 1600 1200 1200 1900 2400 1984 1400 1900 1000 800 1300 700 700 200 400 1500 2400 2100 1985999999999999999999999999999999999999999999999999 1986999999999999999999999999999999999999999999999999 1987999999999999999999999999999999999999999999999999 1988999999999999999999999999999999999999999999999999 1989999999999999999999999999999999999999999999999999 19909999999999999999 1000 1100 300 700 1000 700 800 400 19919999 400 400 600 800 900 1200 600 800 700 300 700 1992 600 100 200 800 50099999999 700 500 200 1000 600 1993 100 200 200 200 700 1300 100 1100 900 800 300 900 1994 700 200 300 500 1000 700 300 600 1400 900 300 900 1995 900 900 600 900 500 1100 800 0 1000 100 1100 400 1996 600 100 300 1000 600 300 200 1100 1100 600 1000 1500 1997 700 500 600 400 600 1200 500 1500 700 1100 900 1000 1998 700 500 0 1000 1100 10009999 900 1300 1500 900 1600 1999 900 400 200 700 200 900 700 900 600 1000 800 700 2000 400 700 600 500 1400 1000 700 600 900 1000 900 1200 2001 400 700 700 300 1100 1000 1300 400 1000 900 900 1000 2002 800 1100 600 600 400 15009999 1100 900 700 1100 500 2003 800 800 400 600 500 200 400 900 1200 900 1100 500 2004 500 900 1000 600 800 900 800 1000 1500 1200 900 400 2005 700 300 100 900 600 1500 900 600 900 1600 800 500 2006 600 600 900 400 700 500 500 1000 900 1100 800 1300 2007 500 1000 900 200 1200 900 70099999999999999999999 you can see that the data after 1990 are for some months significantly lower than the period before which would be the period the normals would be based on i used matlab to calculate the normals for this series 6190 1667 1342 1063 933 1172 1080 980 1288 1272 1412 1852 1840 i then look in the 1995 anomaly files rd0pctxtrd0pc19950112txt tabulated process for 1995 raw norm anom 900 16667 460 900 13417 329 600 10625 435 900 93333 036 500 1172 573 1100 1080 019 800 980 184 0 1288 1000 1000 1272 214 100 1412 929 1100 1852 406 400 1840 783 they arent percentage anomalies they are percentage anomalies 10 this could explain why the real data areas had variability 10x too low but it shouldnt be they should be regular percentage anomalies this whole process is too convoluted and created myriad problems of this kind i really think we should change it back on the case i need to find where the post1990 data came from for these three stations i already know the geneaology of the database wet0311061611dtb rdy0709111032dtb mcdw composite rdy0710151817dtb climat composite with metadata added v v wet0710161148dtb i was going to do further backtracing but its been revealed that the same issues were in 21 meaning that i didnt add the duff data the suggested way forward is to not use any observations after 1989 but to allow synthetics to take over im not keen on this approach as its likely imo to introduce visible jumps at 1990 since were effectively introducing change of data source just after calculating the normals my compromise is to try it but to also try straight derivation from halfdegree synthetics so first we need syntheticonly from 1990 onwards that can be married with the existing glos from pre1990 actually we might as well produce full series of gridded synonly rd0 hell we can do both options in one go point in using the final gridding routine rd0_gts_anom can produce glo files itself lets give it go well not straightforward rd0_gts_anompro is quite resistant to the idea that it might produce halfdegree synthetics to the point where im really not sure whats left to modify eventually found it the glo saving routine takes second argument which is code for the grid size because just giving it the grid size just wouldnt be the same would it here it is saveglo23rd0monthcallfilesavefilecalltitlesavetitle now that 23 is the key but you have to look in quick_interp_tdm2pro to decode it if gs0 eq 05 then savegrid12 if gs0 eq 25 then savegrid22 if gs0 eq 50 then savegrid23 so actually this was saving with gridsize of 5 degrees disquietingly this isnt born out by the file sizes but well gloss over that so with 23 changed to 12 we have rd0_gts_anom_05pro produced halfdegree syntheticonly wet idl compile badc_areaprogramsidlrd0_gts_anom_05pro compiled module rd0_gts_anom idl compile badc_areaprogramsidlrdbinpro compiled module rdbin idl rd0_gts_anom1901200619611990outprefixrd0syn05glord0syn05pre_prefixprebin05prebin05 reading precip and rd0 normals compiled module strip compiled module defxyz compiled module days calculating synthetic rd0 normal compiled module rd0cal calculating synthetic rd0 anomalies compiled module saveglo compiled module selectmodel idl crua6crucrutsversion_3_0secondarieswet glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lanwet enter name for the gridded climatology file clim6190lanwetgrid14 enter the path and stem of the glo files rd0syn05glord0syn05 enter the starting year 1901 enter the ending year 2006 enter the path if any for the output files rd0syn05abs now concentrate addition or percentage ap p do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 3 right erm off i jolly well go rd0syn05glord0syn05011901glo rd0syn05glord0syn05190101glo rd0syn05190101glo etc rd0syn05200612glo there was then some copying around of decades worth chunks of abs files to make set with obssyn to 1989 and syn from 1990 onwards then uealogin1crucrutsversion_3_0secondarieswet makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month rd0abs_mixedrd0yyyymmgloabsgz enter start year 1901 enter start month 01 enter end year 2006 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeewetdat now please enter the 3ch parameter code wet enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 rain days synth 1990 on writing cru_ts_3_0019011910wetdat cru_ts_3_0019011910wetnc writing cru_ts_3_0019111920wetdat cru_ts_3_0019111920wetnc writing cru_ts_3_0019211930wetdat cru_ts_3_0019211930wetnc writing cru_ts_3_0019311940wetdat cru_ts_3_0019311940wetnc writing cru_ts_3_0019411950wetdat cru_ts_3_0019411950wetnc writing cru_ts_3_0019511960wetdat cru_ts_3_0019511960wetnc writing cru_ts_3_0019611970wetdat cru_ts_3_0019611970wetnc writing cru_ts_3_0019711980wetdat cru_ts_3_0019711980wetnc writing cru_ts_3_0019811990wetdat cru_ts_3_0019811990wetnc writing cru_ts_3_0019912000wetdat cru_ts_3_0019912000wetnc writing cru_ts_3_0020012006wetdat cru_ts_3_0020012006wetnc this is the dataset were going with now were on to statistics specifically the ones needed for the paper they include cell coverage the percentage of cells in each region that have stations are near stations or are not covered station counts the number of contributing stations in each region data sources the observedsynthetic split for secondary parameters all statistics will be required at yearly timestep and broken down by region ie europe africa asia cell coverage would ideally come from the idl gridder however as we know the approach of quick_interp_tdm2pro does not lend itself to revealing such information the best solution will be to use the paired cellcdd station counts as produced by stncountsfor station counts should be straightforward to derive from the anomaly files txt as output by anomdtbf90 this however will only work for primary parameters since secondaries are driven from synthetic data as well further the synthetic element in this is usually at 25 degrees so direct relationship with halfdegree coverage will be hard to establish data sources will not be easy see station counts above one approach could be to analyse the anomaly files for the primary parameters and make the assumption that their halfdegree coverage will carry through via the 25degree synthetic stage and the gridding to the final gridded data actually i think the most logical approach is to produce secondary station files that just record the observed contributions as opposed to the derived ones users will be free to use these in tandem with the appropriate primary counts which they can assume will have contributed to the unfilled cells but to less reliable extent both because of the indirect derivation and the lower resolution so about time we had drainsup on the update procedures ive already established logical hierarchy crucrutsfinal_structure crucrutsfinal_structuredatabase repository for databases might need subdirs crucrutsfinal_structureincoming crucrutsfinal_structureincomingbom crucrutsfinal_structureincomingclimat crucrutsfinal_structureincomingmcdw crucrutsfinal_structureincomingother crucrutsfinal_structureprimary crucrutsfinal_structureprimarytmp crucrutsfinal_structureprimarytmptxt crucrutsfinal_structureprimarytmpglo crucrutsfinal_structureprimarytmpabs crucrutsfinal_structureprimarytmpstn crucrutsfinal_structureprimarytmpstncdd0 crucrutsfinal_structureprimarytmpstncddn crucrutsfinal_structureprimarypre crucrutsfinal_structureprimarypretxt crucrutsfinal_structureprimarypreglo crucrutsfinal_structureprimarypreabs crucrutsfinal_structureprimaryprestn crucrutsfinal_structureprimaryprestncdd0 crucrutsfinal_structureprimaryprestncddn crucrutsfinal_structureprimarytmn crucrutsfinal_structureprimarytmntxt crucrutsfinal_structureprimarytmnglo crucrutsfinal_structureprimarytmnabs crucrutsfinal_structureprimarytmnstn crucrutsfinal_structureprimarytmnstncdd0 crucrutsfinal_structureprimarytmnstncddn crucrutsfinal_structureprimarytmx crucrutsfinal_structureprimarytmxtxt crucrutsfinal_structureprimarytmxglo crucrutsfinal_structureprimarytmxabs crucrutsfinal_structureprimarytmxstn crucrutsfinal_structureprimarytmxstncdd0 crucrutsfinal_structureprimarytmxstncddn crucrutsfinal_structureprimarydtr crucrutsfinal_structureprimarydtrtxt crucrutsfinal_structureprimarydtrglo crucrutsfinal_structureprimarydtrabs crucrutsfinal_structureprimarydtrstn crucrutsfinal_structureprimarydtrstncdd0 crucrutsfinal_structureprimarydtrstncddn crucrutsfinal_structuresecondary crucrutsfinal_structuresecondaryvap crucrutsfinal_structuresecondaryvapsyn crucrutsfinal_structuresecondaryvaptxt crucrutsfinal_structuresecondaryvapglo crucrutsfinal_structuresecondaryvapabs crucrutsfinal_structuresecondaryvapstn crucrutsfinal_structuresecondaryvapstnobserved_only crucrutsfinal_structuresecondaryvapstnobserved_onlycdd0 crucrutsfinal_structuresecondaryvapstnobserved_onlycddn crucrutsfinal_structuresecondaryvapstnall might not do these crucrutsfinal_structuresecondaryvapstnallcdd0 crucrutsfinal_structuresecondaryvapstnallcddn crucrutsfinal_structuresecondarywet crucrutsfinal_structuresecondarywetsyn crucrutsfinal_structuresecondarywettxt crucrutsfinal_structuresecondarywetglo crucrutsfinal_structuresecondarywetabs crucrutsfinal_structuresecondarywetstn crucrutsfinal_structuresecondarywetstnobserved_only crucrutsfinal_structuresecondarywetstnobserved_onlycdd0 crucrutsfinal_structuresecondarywetstnobserved_onlycddn crucrutsfinal_structuresecondarywetstnall might not do these crucrutsfinal_structuresecondarywetstnallcdd0 crucrutsfinal_structuresecondarywetstnallcddn crucrutsfinal_structuresecondaryfrs crucrutsfinal_structuresecondaryfrssyn crucrutsfinal_structuresecondaryfrstxt crucrutsfinal_structuresecondaryfrsglo crucrutsfinal_structuresecondaryfrsabs crucrutsfinal_structuresecondaryfrsstn crucrutsfinal_structuresecondaryfrsstnobserved_only crucrutsfinal_structuresecondaryfrsstnobserved_onlycdd0 crucrutsfinal_structuresecondaryfrsstnobserved_onlycddn crucrutsfinal_structuresecondaryfrsstnall might not do these crucrutsfinal_structuresecondaryfrsstnallcdd0 crucrutsfinal_structuresecondaryfrsstnallcddn crucrutsfinal_structuresecondarycld crucrutsfinal_structuresecondarycldsyn crucrutsfinal_structuresecondarycldtxt crucrutsfinal_structuresecondarycldglo crucrutsfinal_structuresecondarycldabs crucrutsfinal_structuresecondarycldstn crucrutsfinal_structuresecondarycldstnobserved_only crucrutsfinal_structuresecondarycldstnobserved_onlycdd0 crucrutsfinal_structuresecondarycldstnobserved_onlycddn crucrutsfinal_structuresecondarycldstnall might not do these crucrutsfinal_structuresecondarycldstnallcdd0 crucrutsfinal_structuresecondarycldstnallcddn crucrutsfinal_structurestatic crucrutsfinal_structurestaticclimatology crucrutsfinal_structurestaticmask then theres the list of procedures which probably need checking add mcdw updates mcdw2cru interactive newmergedb per parameter interactive add climat updates climat2cru interactive newmergedb per parameter interactive add bom updates au2cru unfinished interactive should do whole job regenerate dtr database tmnx2dtr interactive produce primary parameters tmp tmn tmx dtr pre anomdtb per parameter interactive quick_interp_tdm2 per parameter glo2abs per parameter interactive makegrids per parameter interactive prepare binary grids tmp dtr pre for synthetics quick_interp_tdm2 per parameter produce secondary parameter frs uses tmpdtr frs_gts_tdm quick_interp_tdm2 glo2abs interactive makegrids interactive produce secondary parameter vap uses tmpdtr vap_gts_anom anomdtb interactive quick_interp_tdm2 glo2abs interactive makegrids interactive produce secondary parameter wetrd0 uses pre rd0_gts_anom anomdtb interactive quick_interp_tdm2 glo2abs interactive makegrids interactive now in terms of methodology we obviously need this to be portable so either system parameter or text file with local info is going to be needed since reading system parameters is less than easy syntax differs between platforms text file might be the way forward at pinch all it would need to contain would be the root to the hierarchy ie crucrutsfinal_structure in the above example might be an idea to provide sandbox for users to compile into and file of compile lines i wonder how far off i am from makefile that would help with the frightening anomdtbf linkages tried make with anomdtb and it doesnt automatically find the includes even when theyre in the same directory i guess i need to finish the fortran gridder program that would allow steamlining notes on that work are mainly in the file griddersandpit suffice to say it works needs tweaking and few philosophical questions resolving but apart from that so you release dataset that people have been clamouring for and the buggers only start using it and finding problems for instance quote hi tim good start ed i realise you are likely to be very busy at the moment but we have come across something in the cru ts 30 data set which i hope you can help out with we have been looking at the monthly precipitation totals over southern africa angola to be precise and have found some rather large differences between precipitation as specified in the ts 21 data set and the new ts 30 version specifically april 1967 for the cell 1275 south 1625 east the monthly total in the ts 21 data set is 251mm whereas in ts 30 it is 476mm the anomaly does not only appear in this cell but also in number of neighbouring cells this is quite large difference and the new ts 30 value doesnt entirely tie in with what we might have expected from the stationbased precip data we have for this area would it be possible for you could have quick look into this issue many thanks daniel dr daniel kingston post doctoral research associate department of geography university college london gower street london wc1e 6bt uk email dkingstonuclacuk tel 44 020 7679 0510 end well its good question and it took over two weeks to answer i wrote angolam which pretty much established that three local stations had been augmented for 30 and that april 1967 was anomalously wet lots of nonreporting stations ie too few years to form normals also had high values as part of this i also wrote angola3m which added two rather interesting plots the climatology and the output from the fortran gridder id just completed this raised couple of points of interest 1 the 210 output doesnt look like the climatology despite there being stations in the area it ought to have simply relaxed to the clim instead its wetter 2 the gridder output is lower than 30 and much lower than the stations i asked tim and phil about 1 they couldnt give definitive opinion as for 2 their guesses were correct i needed to mod the distance weighting as usual see griddersandpit for the full info so to cloud for over year rumours have been circulating that money had been found to pay somebody for month to recreate mark news coefficients but it never quite gelled now at last someones producing them unfortunately its the idea is to derive the coefficients for the regressing of cloud against dtr using the published 210 data well use 5degree blocks and years 19512002 then produce coefficients for each 5degree latitude band and month finally well interpolate to get halfdegree coefficients apparently lots of issues we need to exclude background stations those that were relaxed to the climatology this is hard to detect because the climatology consists of valid values so testing for equivalence isnt enough it might have to be the station files shudder using station files was ok actually bigger problem was the inclusion of strings of consecutive identical values for cloud andor dtr not sure what the source is as they are not to the climatology ie the anoms are not 0 discussed with phil decided to try excluding any cell with string like that of 10 values cloud only for now the result of that was unfortunately the loss of several output values ie lat band 19 month 7 300 3800 300 3800 300 3800 300 3600 300 3800 300 3800 300 3800 300 3800 300 3700 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 4100 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 4300 300 3800 300 3800 300 4100 300 3800 300 3900 300 3800 300 3800 300 3800 300 3800 300 3800 300 4300 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 300 4400 300 3800 300 3800 300 3800 300 3800 300 3800 300 3800 results n 52 nan nan as can be seen neither the dtr left nor the cloud right look sensible even as anomalies several other months in lat band 19 are either nan or 999 count0 however if we push the duplicates limit up to say 20 we get lat band 19 month 7 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5350 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1350 5000 1700 6500 850 4200 1150 4900 1800 7100 100 3350 100 4000 100 3200 100 4250 100 3800 100 3800 100 3250 100 5250 100 4400 100 3650 100 4100 100 3050 100 3800 100 3600 100 3800 100 3850 100 3900 100 3150 100 4000 100 3800 100 3100 100 4400 100 4300 100 3700 100 3100 100 3100 100 3050 results n 988 3759707 605338 so we can have proper result but only by including load of garbage in fact i might print out this cell as an example lets see limit nvals factor intercept 10 52 nan nan 20 728 768581 3330551 none 1716 832450 3428972 hmm also tried just removing duplicate strings rather than whole cells limit nvals factor intercept 10 1160 699748 2631960 this looks better not so steep and the intercept is shade closer to 0 the matlab script plotcldm allows comparison of scatter diagrams these are fed from example data files manually extracted from the cloudreglog file after varying the duplicate limit andor strategy showed phil and now sidetracked into producing global mean series from the 30 parameters dtr first ok got cloud working have to generate it now but distracted by starting on the mythical update program as usual its much more complicated than it seems so lets work out the order of events well first some ground rules should this be dumb should the operator say what they want to happen and walk away coming back later to check it worked or should it be interactive to the extent of the operator deciding on station matches and so forth at the moment the introduction of new data mcdw climat bom is highly interactive and though bom should be fully automatic in the future the same cannot be said for mcdw and climat hmmm well i guess there are two possibilities 1 operator selects interactive additions script proceeds calling merge programs as necessary some of which may ask the operator to decide on matches this could take hours or even days depending on the quality of the incoming metadata 2 operator selects automatic additions script proceeds calling special versions of the merge programs these have fixed threshold of confidence for adding new data to exisitng databases when the threshold is crossed the data is not added but stored in new database which might of course be later added under option 1 note that the threshold would be higher than that in 1 that initiates operator involvement is this sufficient it certainly means more coding but not huge amount in worst case scenario where the operator always chooses 2 we still have the unused data updates that can be interactively merged in at any time even yaesr in the future this all avoids the big questions of course when do updates happen and how far back do they go for instance lets say there are sixmonth published updates so say the full 1901present files are published yearly with sixmonth update files as interims what happens in any of the following circumstances updates for say 1965 are available b the data used in the januarytojune update is further updated after publication and is present in the next full release so that the early janjun grids differ from those in the 1901present publication in both and b it would usually be mcdw updates that carried retrospective data this is marked as overdue luckily this isnt really up to or is it if the operator specifies time period to update it ought to warn if it finds earlier updates in those files so further mods to mcdw2cruauto are required its results file must list extras or ooh how about second output database for the mcdw updates containing just the overdue stuff back think even more complicated my head hurts it actually does and i ought to be on my way home but look we create new master database for each parameter every time we update dont we what we ought to do is provide log file for each new database identifying which data have been added oh god ok lets go new data process 1 ops runs update and chooses new data 2 ops selects mcdw climat andor bom data and gives update dates 3 ops selects interactive or automatic database merging 4 update checks source files are present and initiates conversion to cru format 5 update runs the merging program to join the new data to the existing databases creating new databases if data for previous periods is included in the update files it will be included 5a if ops selected automatic merging program asks for decisions on difficult matches these are all logged of course 6 merge program creates log of changes between old databases and new ones inc source of the data update process 1 ops runs update and chooses update yes i know 2 ops gives parameters and time period to update 3 ops specifies sixmonth interim or full update 4 update provides candidate databases for the update ops chooses 5 update runs the anomaly and gridding programs for the specified period note the following system command will find the number of stations reporting in given year from given database grep 2006 tmptmp0710011359dtb grep v 999999999999999999999999999999999999999999999999 wc l discovered remembered would be better sadly i didnt that i never got round to writing bomtocru converter it got overtaken by the drastic need to get the tmin and tmax databases synchronised see above somewhere there was barelystarted thing so i cannibalised it for bom2cruautofor which eventually worked in fact it was good entry into the fraught world of automatic scriptfed programs got bom2cruautofor working then climat2cruautofor and mcdw2cruautofor in quick succession the latter two having their output databases compared successfully with those generated in nov 2007 next i suppose its the next in the sequence mergedb this is where im anxious i want it all to be plain sailing and automatic but i dont think theres any practical way to obviate the operator from the need to make judgements on the possible mapping of stations back to get cld sorted out need break from the updater though much the same difficulties trying to work out the process its anything but straightforward for cloud seeing as the incoming updates are in sun hours and we have to apply our own regressions to dtr knocked up subroutine sh2cp to convert sun hours to cloud percentage on the fly and added it to mcdw2cruauto and climat2cruauto of course one of the problems is that you need latitude value to perform the conversion so the climat bulletins lose the value if they cant be matched in the wmo list not much i can do about that and lets face it those stations are going to end up as new stations with possibility of 6190 normal so using the new converters which are built to be driven by the update program i set about converting mcdw and climat bulletins uealogin1crucrutsversion_3_0update_top mcdw2cruauto uealogin1crucrutsversion_3_0update_top cat resultsresults0901101032mcdw0901101032res ok uealogin1crucrutsversion_3_0update_top uealogin1crucrutsversion_3_0update_top climat2cruauto uealogin1crucrutsversion_3_0update_top cat resultsresults0901101032climat0901101032res ok uealogin1crucrutsversion_3_0update_top gotta love silent running the output cld databases both look ok and pretty much equivalent except that mcdw goes back further to 1994 climat is 2000 onwards because thats whats on phil brohans website now we have to merge this is where it gets hairy looking at existing cld databases we have the originals cld0301081434dtb and cld0312181428dtb and the 2007 version cld0711272230dtb looking back through the notes this was the product of processing the mcdw and climat bulletins into sun hours databases sun0711272156dtb and sun0711272219dtb respectiverly then merging those to form sun0711272225dtb then converting to cloud using hsp2cldfor giving us cld0711272230dtb so the new cloud databases ive just produced should be if not identical very similar oh dear there is passing similarity though this seems to break down in winter i dont have time to do detailed comparisons of course so well just run with the new one after all i have tested the conversion for the latest programs im not sure how much testing was done last time the procedure last time that is when i was trying to reproduce ts 210 we have idea what the procedure was for its initial production was to incorporate the sun percent data from the bulletins into the existing sun percent db spc0312221624dtb the trouble is the existing cloud dbs are bigger they stop at 1996 but thats problem since we have mcdw from then 228936 cld0301081434dtb 104448 cld0312181428dtb 111989 comboclddtb 57395 spc0301201628dtb 51551 spc0312221624dtb 51551 spc94000312221624dtb so how about merging our new mcdw cloud database into cld0312181428dtb then merging the climat one into that the logic here is that the cloud must be from observations because the sun databases are much smaller well the ones we know about it might be worth checking the station numbers for each year though unfortunately we dont have lot of luck merging mcdw updates into the dec 2003 cld database uealogin1crucrutsversion_3_0dbcld newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name cld0312181428dtb please enter the update database name mcdwcld0901101032dtb reading in both databases master database stations 3605 update database stations 2204 looking for wmo code matches 5 rejects from update process 0902101404 writing cld0902101404dtb outputs written new master database cld0902101404dtb update database stations 2204 matched with master stations 858 automatically 858 by operator 0 added as new master stations 1341 rejected 5 rejects file mcdwcld0901101032dtbrejected uealogin1crucrutsversion_3_0dbcld of course as we are only generating from 1996 onwards this probably isnt of much significance luckily next merge climat into the new database well of course this is much more satisfactory because it matches with the mcdw stations uealogin1crucrutsversion_3_0dbcld newmergedb welcome to the database updater before we get started an important question if you are merging an update climat mcdw australian do you want the quick and dirty approach this will blindly match on wmo codes alone ignoring datametadata checks and making any unmatched updates into new stations metadata permitting enter b for blind merging or ret b please enter the master database name cld0902101404dtb please enter the update database name climatcld0901101032dtb reading in both databases master database stations 4946 update database stations 2038 looking for wmo code matches 2 rejects from update process 0902101409 writing cld0902101409dtb outputs written new master database cld0902101409dtb update database stations 2038 matched with master stations 1858 automatically 1858 by operator 0 added as new master stations 178 rejected 2 rejects file climatcld0901101032dtbrejected uealogin1crucrutsversion_3_0dbcld so we now have cld0902101409dtb database consisting of cld0312181428dtb updated first with derivedcloud data from mcdw 19942008 then with derivedcloud data from climat 20002008 this should be anomalised then fed into quick_interp_tdm2pro along with synthetic dtrderived cloud so that is the next hurdle well we have the program and weve played with it but forgot to cp those runs into here well they were only few days ago so here they are now crua6crucrutsversion_3_0secondariescldcldfromdtrtxt dtr2cld please enter the pathfile of the first dtr txt file crucrutsversion_3_0primariesdtrdtrtxtdtr190101txt please enter the pathfile of the last dtr txt file crucrutsversion_3_0primariesdtrdtrtxtdtr200612txt crua6crucrutsversion_3_0secondariescldcldfromdtrtxt then an experimental idl gridding using half degree and glo output it was late at night i think i had an idea of visualising or comparing such luck crua6crucrutsversion_3_0secondariescld idl idl version 54 osf alpha c 2000 research systems inc installation number 66286 licensed for use by climatic research unit idl quick_interp_tdm219952006cld750gs05dumpglodumpglopts_prefixcldfromdtrtxtcld compiled module quick_interp_tdm2 compiled module glimit defaults set 1995 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 stations found in cldfromdtrtxtcld200609txt stations found in cldfromdtrtxtcld200610txt stations found in cldfromdtrtxtcld200611txt stations found in cldfromdtrtxtcld200612txt idl so now we need to try that last step again this time going for 25degree binary outputs suitable for feeding back into it for the full cloud gridding oh my idl quick_interp_tdm219962006cldfromdtr25bincld750gs25dumpbindumpbinpts_prefixcldfromdtrtxtcld output removed as redone below with cdd600 okay thats the synthetic binary cloud ready now we need to run anomdtb on the observed cloud database crua6crucrutsversion_3_0secondariescld anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required eg tmp cld select the dtb file to load cld0902101409dtb cld0902101409dtb tmp_mntcruautocrutsversion_3_0secondariescldcld0902101409dtb specify the startend of the normals period 19611990 specify the missing percentage permitted 25 data required for normal 23 specify the of stdevs at which to reject data 3 the output selection is tied to 3 ungridded anomalies check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto cldnewtxt select the firstlast years ad to save 19962006 operating tmp_mntcruautocrutsversion_3_0secondariescldcld0902101409dtb tmp_mntcruautocrutsversion_3_0secondariescldcld0902101409dtb normals mean percent stdev percent dtb 0 00 cts 288328 222 288328 222 process decision percent ofchk latlon 0 00 00 normal 1010030 778 778 outofrange 24 00 00 accepted 288304 222 dumping years 19962006 to txt files crua6crucrutsversion_3_0secondariescld unfortunately that isnt working too many stations outside the usual normals period 19611990 my notes from the last attempt are less than inspiring it looks as though we need the program normshiftfor and normalise 9502 so crua6crucrutsversion_3_0secondariescld anomdtb anomdtb converts dtb to anom txt for gridding enter the suffix of the variable required eg tmp cld select the dtb file to load cld0902101409dtb cld0902101409dtb tmp_mntcruautocrutsversion_3_0secondariescldcld0902101409dtb specify the startend of the normals period 19952002 specify the missing percentage permitted 25 data required for normal 6 specify the of stdevs at which to reject data 3 the output selection is tied to 3 ungridded anomalies check for duplicate stns after anomalising 0no0km range 0 select the generic txt file to save yymmauto cldupdatetxt select the firstlast years ad to save 19962006 operating tmp_mntcruautocrutsversion_3_0secondariescldcld0902101409dtb tmp_mntcruautocrutsversion_3_0secondariescldcld0902101409dtb normals mean percent stdev percent dtb 0 00 cts 271495 209 271495 209 process decision percent ofchk latlon 0 00 00 normal 1026863 791 791 outofrange 474 00 02 accepted 271021 209 dumping years 19962006 to txt files crua6crucrutsversion_3_0secondariescld hmm thats giving us between 670 and 790 stations per month not too bad i suppose seeing as its secondary parameter now for normshift which has already been run search back in this file producing clim9502to6190gridcld which is your standard 12grids360rx720c giving the diffs between 19952002 normals and 19611990 normals so after gridding we could add these except that after gridding well have incorporated the dtr_derived synthetic cloud which is of course based on the 19611990 normals as its derived from dtr arrrrggghh so sigh another problem well we cant change the updates side that has to use 19952002 normals but maybe well have to adjust the station anomalies prior to gridding i dont see an alternative wrote movenormsfor using the engine of dtr2cld as its processing the same kind of files and also needs to map stations to cells however we quickly hit problem crua6crucrutsversion_3_0secondariescld movenorms please enter the adjustment file clim9502to6190gridcld please enter generic source file with mm for month and yyyy for year cldupdatetxtcldupdateyyyymmtxt start year 1996 start month 01 end year 2006 end month 12 please enter generic destination file with mm for month and yyyy for year cldupdate6190cldupdate6190yyyymmtxt error station in sea file cldupdate6190cldupdate6190199601txt offending line 1854 7249 110 6600004305700 resulting indices ilatilon 218 505 crua6crucrutsversion_3_0secondariescld this is station on the west coast of india probably mumbai unfortunately as coastal station it runs the risk of missing the nearest land cell the simple movenorms program is about to become less simple but was doable the log file was empty at the end indicating that all damp stations had found dry land crua6crucrutsversion_3_0secondariescld movenorms please enter the adjustment file clim9502to6190gridcld please enter generic source file with mm for month and yyyy for year cldupdatetxtcldupdateyyyymmtxt start year 1996 start month 1 end year 2006 end month 12 please enter generic destination file with mm for month and yyyy for year cldupdate6190cldupdate6190yyyymmtxt crua6crucrutsversion_3_0secondariescld wc l movenormslog 0 movenormslog crua6crucrutsversion_3_0secondariescld so now i should be able to do the final gridding of cloud for 19962006 idl quick_interp_tdm219962006cloudcomboglocld750gs05dumpglodumpglosynth_prefixcldfromdtr25bincldpts_prefixcldupdate6190cldupdate6190 output removed as redone below with cdd600 crua6crucrutsversion_3_0secondariescld glo2abs output removed as redone below with cdd600 uealogin1crucrutsversion_3_0secondariescld makegrids output removed as redone below with cdd600 all files look alright but the netcdf attributes which are still bad do say that the cdd for cloud is 600 if it is i will eat my screen because ill have to do all the gridding ops again and it is so binary reproduction idl quick_interp_tdm219962006cldfromdtr25bincld600gs25dumpbindumpbinpts_prefixcldfromdtrtxtcld compiled module quick_interp_tdm2 compiled module glimit defaults set 1996 compiled module map_set compiled module crossp compiled module mean compiled module moment compiled module stddev grid 1996 nonzero 222967 465119 1346274 cells 53787 compiled module strip compiled module wrbin 1997 grid 1997 nonzero 227474 471535 1316472 cells 53374 1998 grid 1998 nonzero 243090 505343 1552392 cells 53557 1999 grid 1999 nonzero 210658 462280 1279565 cells 52391 2000 grid 2000 nonzero 233182 504612 1543142 cells 51948 2001 grid 2001 nonzero 254712 503292 1475332 cells 50464 2002 grid 2002 nonzero 226252 498823 1533252 cells 46980 2003 grid 2003 nonzero 218382 483537 1365305 cells 48279 2004 grid 2004 nonzero 239221 479721 1454819 cells 48179 2005 grid 2005 nonzero 260049 488422 1453165 cells 44448 2006 stations found in cldfromdtrtxtcld200609txt stations found in cldfromdtrtxtcld200610txt stations found in cldfromdtrtxtcld200611txt stations found in cldfromdtrtxtcld200612txt grid 2006 nonzero 173353 455259 1357803 cells 29194 idl and finals reproduced idl quick_interp_tdm219962006cloudcomboglocld600gs05dumpglodumpglosynth_prefixcldfromdtr25bincldpts_prefixcldupdate6190cldupdate6190 defaults set 1996 compiled module rdbin compiled module defxyz compiled module saveglo compiled module selectmodel 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 idl crua6crucrutsversion_3_0secondariescld glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lancld enter name for the gridded climatology file clim6190lancldtoothbrush enter the path and stem of the glo files cloudcomboglocld enter the starting year 1996 enter the ending year 2006 enter the path if any for the output files cloudcomboabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 2 enter minimum value 0 enter maximum value 1000 right erm off i jolly well go cloudcomboglocld011996glo cloudcomboglocld199601glo cld199601glo cld199602glo etc cld200611glo cld200612glo crua6crucrutsversion_3_0secondariescld uealogin1crucrutsversion_3_0secondariescld makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month cloudcomboabscldyyyymmgloabs enter start year 1996 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeeclddat now please enter the 3ch parameter code cld enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 percentage cloud cover writing cru_ts_3_0019962000clddat cru_ts_3_0019962000cldnc writing cru_ts_3_0020012006clddat cru_ts_3_0020012006cldnc uealogin1crucrutsversion_3_0secondariescld the question is is this any good well we currently have published cloud data to 2002 so we can make comparisons between 1996 and 2002 oh my i am sure ive written plenty of comparison routines but as to their location or nameah there is cmpmgridsm which i modified away from its precipitationonly mentality i used mmeangridfor to calculate monthly mean fields 19962002 for both 210 and 300 cloud the resulting mean files cru_ts_2_1019962002clddatmmeans and cru_ts_3_0019962002clddatmmeans were fed into cmpmgridsm the results were less than ideal though they could have been much worse essentially north america is totally different cloudier in febmarapr sunnier the rest of the year there are other differences particularly in northern asia but these are oatchier and dont extend throughout the year so the obvious cause would be the inclusion of dtrderived cloud since that would have significant station counts in north america compared to cld also there seems to be horizontal banding not good sign given the nature of the dtrtocld conversion naturally the way to test this is to make comparisons between five different datasets 1 cru ts 210 19962002 monthly means 2 cru ts 300 19962002 monthly means 3 cru ts 300 19962002 synthetic only monthly means 4 cru ts 300 19962002 observed only monthly means 5 cld climatology the inclusion of 5 will show the extent of missing data perhaps so im suggesting the following tests 21 basic comparison of old and new already done 31 how the dtrderived synthetic cld relates to 21 41 how the sunhoursderived observed cld relates to 21 32 how the dtrderived synthetic cld relates to the combo cld 15 how 21 relates to the climatology 25 how 30 relates to the climatology so to making datasets 3 and 4 idl quick_interp_tdm219962002cldfromdtrglo05cld600gs05dumpglodumpglopts_prefixcldfromdtrtxtcld compiled module quick_interp_tdm2 compiled module glimit defaults set 1996 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 stations found in cldfromdtrtxtcld200609txt stations found in cldfromdtrtxtcld200610txt stations found in cldfromdtrtxtcld200611txt stations found in cldfromdtrtxtcld200612txt idl quick_interp_tdm219962002cldfromupdate6190glocld600gs05dumpglodumpglopts_prefixcldupdate6190cldupdate6190 defaults set 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 idl crua6crucrutsversion_3_0secondariescld glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lancld enter name for the gridded climatology file clim6190lanclddunconvertin enter the path and stem of the glo files cldfromdtrglo05cld enter the starting year 1996 enter the ending year 2002 enter the path if any for the output files cldfromdtrglo05abs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 2 enter minimum value 0 enter maximum value 1000 right erm off i jolly well go cldfromdtrglo05cld011996glo cldfromdtrglo05cld199601glo cld199601glo cld199602glo etc cld200211glo cld200212glo crua6crucrutsversion_3_0secondariescld glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lancld enter name for the gridded climatology file clim6190lancldnotuagain enter the path and stem of the glo files cldfromupdate6190glocld enter the starting year 1996 enter the ending year 2002 enter the path if any for the output files cldfromupdate6190gloabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 2 enter minimum value 0 enter maximum value 1000 right erm off i jolly well go cldfromupdate6190glocld011996glo cldfromupdate6190glocld199601glo cld199601glo cld199602glo etc cld200211glo cld200212glo crua6crucrutsversion_3_0secondariescld uealogin1crucrutsversion_3_0secondariescld makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month cldfromdtrglo05abscldyyyymmgloabs enter start year 1996 enter start month 01 enter end year 2002 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeecld_from_dtr_onlydat now please enter the 3ch parameter code cld enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 percentage cloud cover from dtr only writing cru_ts_3_0019962000cld_from_dtr_onlydat cru_ts_3_0019962000cld_from_dtr_onlync writing cru_ts_3_0020012002cld_from_dtr_onlydat cru_ts_3_0020012002cld_from_dtr_onlync uealogin1crucrutsversion_3_0secondariescld makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month cldfromupdate6190gloabscldyyyymmgloabs enter start year 1996 enter start month 01 enter end year 2002 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeecld_from_sunobs_onlydat now please enter the 3ch parameter code cld enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 percentage cloud cover from sun obs only writing cru_ts_3_0019962000cld_from_sunobs_onlydat cru_ts_3_0019962000cld_from_sunobs_onlync writing cru_ts_3_0020012002cld_from_sunobs_onlydat cru_ts_3_0020012002cld_from_sunobs_onlync uealogin1crucrutsversion_3_0secondariescld mmeangrid mmeangrid calculate monthly means for cru_ts grids please enter the gridded data filename cru_ts_3_0019962002cld_from_dtr_onlydat writing monthly mean grids to cru_ts_3_0019962002cld_from_dtr_onlydatmmeans uealogin1crucrutsversion_3_0secondariescld mmeangrid mmeangrid calculate monthly means for cru_ts grids please enter the gridded data filename cru_ts_3_0019962002cld_from_sunobs_onlydat writing monthly mean grids to cru_ts_3_0019962002cld_from_sunobs_onlydatmmeans uealogin1crucrutsversion_3_0secondariescld giving us numbering from before 1 cru_ts_2_1019962002clddatmmeans 2 cru_ts_3_0019962002clddatmmeans 3 cru_ts_3_0019962002cld_from_dtr_onlydatmmeans 4 cru_ts_3_0019962002cld_from_sunobs_onlydatmmeans 5 clim6190lancldgrid and here are our target comparisons again this time with notes 21 basic comparison of old and new already done major diffs in n america all months lat striping 31 how the dtrderived synthetic cld relates to 21 major diffs globally all months lat striping 41 how the sunhoursderived observed cld relates to 21 minor patchy diffs globally all months 32 how the dtrderived synthetic cld relates to the climatology major diffs globally all months lat striping cw 31 15 how 21 relates to the climatology minor patchy diffs globally equiv for 25 how 30 relates to the climatology pretty much as for 21 the deduction so far is that the dtrderived cld is waaay off the dtr looks ok well ok in the sense that it doesnt have prominent bands so its either the factors and offsets from the regression or the way theyve been applied in dtr2cld well dtr2cld is not the worlds most complicated program wheras cloudreg is and i immediately found mistake scanning forward to 1951 was done with loop that for completely unfathomable reasons didnt include months so we read 50 grids instead of 600 that may have had something to do with it i also noticed as i was correcting that that i reopened the dtr and cld data files when i should have been opening the bloody station files i can only assume that i was being interrupted continually when i was writing this thing running with those bits fixed improved matters somewhat though now theres problem in that one 5degree band 10s to 5s has stations this will be due to low station counts in that region plus removal of duplicate values had think phil advised averaging the bands either side to fill the gap but yuk and also the band to the north ie 5s to equator is noticeably lower extreme even so after some investigation i found that well heres the email mail quote phil ive looked at why were getting low counts for valid cloud cells in certain 5degree latitude bands the filtering algorithm omits any cell values where the station count is zero for either cld or dtr in general its the cld counts that are zero and losing us the data however in many cases the cloud value in that cell on that month is not equal to the climatology and there is plenty of dtr data so im wondering how accurate the station counts are for secondary variables given that they have to reflect observed and synthetic inputs heres brief example all values are x10 cld dtr val stn anom val stn anom 55300 000 1000 13400 2000 100 55800 000 1700 13900 2000 200 56500 000 2300 13700 2000 500 58100 000 3200 13900 1600 800 58700 000 3800 13700 1600 900 56700 000 4600 12700 1500 600 56400 000 4900 12000 1400 300 55200 000 4800 11100 1200 000 54300 000 4500 10500 1200 100 53500 000 4000 9900 1000 100 so im proposing to filter on only the dtr counts on the assumption that pre was probably available if dtr was so synthesis of cld was likely to have happened just not shown in the station counts which are probably conservative end mail quote i didnt get an email back but he did verbally consent so away we go running with dtrstationonly screening gives us lots of station values even with duplicate filtering turned back on niiice its still not exactly smooth but it might be enough to fix the synthetic cloud so moved all existing directories to name_old_badcoeffs and reproduced the synthetic cloud crua6crucrutsversion_3_0secondariescld dtr2cld please enter the pathfile of the first dtr txt file crucrutsversion_3_0primariesdtrdtrtxtdtr199601txt please enter the pathfile of the last dtr txt file crucrutsversion_3_0primariesdtrdtrtxtdtr200612txt crua6crucrutsversion_3_0secondariescld binary 25 grid production idl quick_interp_tdm219962006cldfromdtr25bincld600gs25dumpbindumpbinpts_prefixcldfromdtrtxtcld defaults set 1996 grid 1996 nonzero 280336 352211 1555659 cells 35824 1997 grid 1997 nonzero 287817 355387 1552398 cells 36027 1998 grid 1998 nonzero 316090 417502 1828359 cells 36481 1999 grid 1999 nonzero 268934 356123 1513076 cells 34127 2000 grid 2000 nonzero 283765 411417 1807935 cells 34846 2001 grid 2001 nonzero 317763 409542 1720433 cells 33724 2002 grid 2002 nonzero 296498 426404 1827383 cells 31683 2003 grid 2003 nonzero 278828 388903 1619822 cells 32227 2004 grid 2004 nonzero 305593 384767 1740231 cells 32315 2005 grid 2005 nonzero 332088 401841 1708421 cells 30951 2006 stations found in cldfromdtrtxtcld200609txt stations found in cldfromdtrtxtcld200610txt stations found in cldfromdtrtxtcld200611txt stations found in cldfromdtrtxtcld200612txt grid 2006 nonzero 272999 362585 1619338 cells 20383 idl final gridding with obs as well idl quick_interp_tdm219962006cloudcomboglocld600gs05dumpglodumpglosynth_prefixcldfromdtr25bincldpts_prefixcldupdate6190cldupdate6190 defaults set 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 idl crua6crucrutsversion_3_0secondariescld glo2abs welcome this is the glo2abs program i will create set of absolute grids from set of anomaly grids in glo format also gridded version of the climatology enter the path and name of the normals file clim6190lancld enter name for the gridded climatology file clim6190lancldspeeeeew enter the path and stem of the glo files cloudcomboglocld enter the starting year 1996 enter the ending year 2006 enter the path if any for the output files cloudcomboabs now concentrate addition or percentage ap do you wish to limit the output values yn 1 set minimum to zero 2 set single minimum and maximum values 3 set minima and maxima based on days in month 4 set integer values 1 ie positive 5 changed my mind limits choose 2 enter minimum value 0 enter maximum value 1000 right erm off i jolly well go cloudcomboglocld011996glo cloudcomboglocld199601glo cld199601glo cld199602glo etc cld200611glo cld200612glo crua6crucrutsversion_3_0secondariescld uealogin1crucrutsversion_3_0secondariescld makegrids welcome this is the makegrids program i will create decadal and full gridded files in both ascii text and netcdf formats from the output files of eg glo2absfor enter gridfile with yyyy for year and mm for month cloudcomboabscldyyyymmgloabs enter start year 1996 enter start month 01 enter end year 2006 enter end month 12 please enter sample output filename replacing start year with ssss and end year with eeee and ending with dat eg cru_ts_3_00sssseeeetmpdat cru_ts_3_00sssseeeeclddat now please enter the 3ch parameter code cld enter generic title for this dataset eg cru ts 300 mean temperature cru ts 300 percentage cloud cover writing cru_ts_3_0019962000clddat cru_ts_3_0019962000cldnc writing cru_ts_3_0020012006clddat cru_ts_3_0020012006cldnc uealogin1crucrutsversion_3_0secondariescld uealogin1crucrutsversion_3_0secondariescld head 30240 cru_ts_3_0019962006clddat cru_ts_3_0019962002clddat uealogin1crucrutsversion_3_0secondariescld mmeangrid mmeangrid calculate monthly means for cru_ts grids please enter the gridded data filename cru_ts_3_0019962002clddat writing monthly mean grids to cru_ts_3_0019962002clddatmmeans uealogin1crucrutsversion_3_0secondariescld back with cmpmgridsm and things look much better differences with the climatology or with the 210 release are patchy and generally below 30 of course it would be nice if the differences with the 210 release were negligable since our regression coefficients were based on 210 dtr and cld though of course the sun hours component is an unknown there as is the fact that 210 used pre as well as dtr for the synthetics anyway it gets the thumbsup the strategy will be to just produce it for 2003200606 to tie in with the rest of the 300 release so i just need to argh i dont have any way to create netcdf files 19012006 without the gloabs files to work from id have to specially code version that swallowed the existing 19012002 then added ours meh well its problem to release concatenated ascii file so ill do that crua6crucrutsversion_3_0secondariescldcld_final ls l total 2414884 rw 1 f098 cru 1904005440 feb 13 1035 cru_ts_2_1019012002cldgrid rw 1 f098 cru 7542905 feb 12 1750 cru_ts_3_0019962000clddatgz rw 1 f098 cru 62217668 feb 12 1750 cru_ts_3_0019962000cldnc rw 1 f098 cru 273762720 feb 12 1751 cru_ts_3_0019962006clddat rw 1 f098 cru 136867556 feb 12 1751 cru_ts_3_0019962006cldnc rw 1 f098 cru 8893264 feb 12 1751 cru_ts_3_0020012006clddatgz rw 1 f098 cru 74659316 feb 12 1751 cru_ts_3_0020012006cldnc crua6crucrutsversion_3_0secondariescldcld_final gunzip cru_ts_3_0020012006clddatgz crua6crucrutsversion_3_0secondariescldcld_final wc l cru_ts_3_0020012006clddat 25920 cru_ts_3_0020012006clddat crua6crucrutsversion_3_0secondariescldcld_final tail 17280 cru_ts_3_0020012006clddat cru_ts_3_0020032006clddat crua6crucrutsversion_3_0secondariescldcld_final wc l cru_ts_3_0020032006clddat 17280 cru_ts_3_0020032006clddat crua6crucrutsversion_3_0secondariescldcld_final mv cru_ts_2_1019012002cldgrid cru_ts_30019012006clddat crua6crucrutsversion_3_0secondariescldcld_final cat cru_ts_3_0020032006clddat cru_ts_30019012006clddat crua6crucrutsversion_3_0secondariescldcld_final wc l cru_ts_30019012006clddat 457920 cru_ts_30019012006clddat crua6crucrutsversion_3_0secondariescldcld_final cmp cru_ts_2_1019012002cldgrid cru_ts_30019012006clddat cmp eof on cru_ts_2_1019012002cldgrid crua6crucrutsversion_3_0secondariescldcld_final done and tested so back to the update process well to take slightly different tack i thought id look at the gridding end of things specifically how to run idl in batch mode i think ive got it you create batch file with the commands in then setenv idl_startup name of batch file when you type idl it runs the batch file unfortunately it doesnt quit afterwards though adding an exit line to the batch file does the trick of course there is easy way to check its working properly since the random element used when relaxing to the climatology ensures that each run gives different results crua6crucrutsversion_3_0secondariescld cmp testglocld200411glo testglo2cld200411glo testglocld200411glo testglo2cld200411glo differ char 9863 line 104 crua6crucrutsversion_3_0secondariescld still the mechanism is so similar to that used to run other fortran progs that we can carry on i guess naturally i would prefer to use the gridder i wrote partly because it does much better documentable job but mainly because i dony want all that effort wasted also looked at netcdf production as its still looming ncgen looks quite good it can work from cdl file format is the same as the output from ncdump it can even produce fortran code to reproduce the file ah well back to the incoming data process the fact that the mcdw2cruauto and climat2cruauto programs worked fine for cld is big bonus they read their runs and date files andthey wrote their results though the results didnt include the names of the output databases ive had second thoughts about that i want the update program to be in charge so it should know what files have been produced assuming the result is ok if the conversion program sends back list then the update program will have to parse it to find out which parameter is which and thats silly when it should know anyway the situation is different for merging i dont have full strategy for file naming yet lets look at typical process for an unnamed not tmn or tmx primary parameter ie simple case files process mcdw updates convert mcdw mcdw db current db merge mcdw into current currentmcdw db climat updates convert climat climat db merge climat into currentmcdw currentmcdwclimat db anomalise anomaly files grid gridded anomalies climatology actualise gridded actuals reformat into dat and nc final output files so naming well the governing principle of the update process is that all files have the same 10digit datestamp so the run can be uniquely identified as can all its files data log etc i am not changing that main problem is that we will have to depart from the rigid database naming schema tladatestrdtb because we will have lots of databases in single run in the above example four databases will all have the same datestamp heres possible name system mcdw db mcdwtladatestrdtb currentmcdw db int1tladatestrdtb climat db clmttladatestrdtb currentmcdwclimat db int2tladatestrdtb the final db would then be copied or renamed to tladatestrdtb pre0902161401dtb for secondary parameters its even worse im not superkeen on the use of int1 interim 1 and so on they give useful information but more complicated schema isnt going to be uderstood by anyone else anyway and we should have the database master list to refer to at all times okay all interim databases will be labeled int1 int2 and so forth the update program will have to keep track of numbering and of course it will have to tell the merging program what to call the output database bah it gets worse the update program has to know which master database to pass to the merge program for mcdw its going to be the current database for that parameter but for climat and bom it depends on whether mcdw or climat respectively merges have gone before and only for those parameters that are precursored more complexity well i suppose i can take one of two approaches 1 test at each stage for each parameter ie for bom test whether climat tmxtmn have just been done this could be done by testing for the filenames or by setting flags 2 maintain list in memory of latest databases for each parameter bit less elegant but easier to understand and use well as we already have 2 well go with that one 0 okay because it is so complicated well for my brain anyway im going to write out the filenames that update is using and expecting so i can check that the conversion and merging programs tie in initsassumptions dtstr 0902161655 par tmp source mcdw prev db dbtmptmp0809111204dtb conversion runsruns0902161655convmcdw0902161655dat run information updatesmcdwdbdb0902161655 dir for output dbs resultsresults0902161655convmcdw0902161655res expected results file updatesmcdwdbdb0902161655mcdwtmp0902161655dtb expected output db logslogs0902161655convmcdw0902161655log expected log file merging dbtmptmp0809111204dtb currentlatest db updatesmcdwdbdb0902161655mcdwtmp0902161655dtb new db to be merged in updatesmcdwdbdb0902161655int1tmp0902161655dtb interim output db runfilelatestdat contains name of current run file runsruns0902161655mergmcdw0902161655dat run information read from above resultsresults0902161655mergmcdw0902161655res expected results file updatesmcdwdbdb0902161655int1tmp0902161655dtb expected output db logslogs0902161655mergmcdw0902161655log expected log file these all seem to match up with the respective programs not sure that all the necessary directories are being created yet though they are now some modifications to the above have been made and retrospectively updated so with half of the update program written i got it all compiled reset all the incoming data to unprocessed and got it working of course i immediately realised that id missed out the dtr conversion at the end and that didnt go any better than the rest of it despite quick conversion of tmnx2dtrautofor well keeneyed viewers will remember that all the tmintmaxdtrbacktotminandtmax stuff revolves around the tmin and tmax databases being kept in absolute step that is same stations same coordinates and names same data spans otherwise the job of synching and of converting to dtr becomes horrendous but look at what happens to the line counts of the databases as theyre mangled through the system originals identical metadata 606244 tmntmn0708071548dtb 606244 tmxtmx0708071548dtb climat conversions 27090 climattmn0902192248dtb 27080 climattmx0902192248dtb climat merged interims 607692 int2tmn0902192248dtb 604993 int2tmx0902192248dtb bom conversions identical metadata 5388 bomtmn0902192248dtb 5388 bomtmx0902192248dtb bom merged into climat interims interims 607692 int3tmn0902192248dtb 604993 int3tmx0902192248dtb sometimes life is just too hard its after midnight again and im doing all this over vnc in 256 colours which hurts anyway the above line counts i dont know which is the more worrying the fact that adding the climat updates lost us 1251 lines from tmax but gained us 1448 for tmin or that the bom additions added sod all and yes ive checked the int2 and int3 databases are identical aaaarrgghhhhh i guess i am going to need one of those programs i wrote to sync the tmin and tmax databases arent i actually its worse than that the climat merges for tmn and tmx look very similar quote climat tmn merge into latest db new master database updatesclimatdbdb0902192248int2tmn0902192248dtb update database stations 2922 matched with master stations 2227 automatically 2227 by operator 0 added as new master stations 566 rejected 129 rejects file updatesclimatdbdb0902192248climattmn0902192248dtbrejected end quote quote climat tmx merge into latest db new master database updatesclimatdbdb0902192248int2tmx0902192248dtb update database stations 2921 matched with master stations 2226 automatically 2226 by operator 0 added as new master stations 566 rejected 129 rejects file updatesclimatdbdb0902192248climattmx0902192248dtbrejected end quote i dont see how we end up with such drastic differences in line counts well the first thing to do was to fix climat2cruauto so that it treated tmin and tmax as inseparable thus the climat databases for these two should be identical um apart from the data values ok this is getting silly now the bom and climat conversions are in sync and the original databases are in synch yet the processing creates massive divergence originals 606244 dbtmntmn0708071548dtb 606244 dbtmxtmx0708071548dtb climat conversions 27080 updatesclimatdbdb0902201023climattmn0902201023dtb 27080 updatesclimatdbdb0902201023climattmx0902201023dtb climat merged interims 607687 updatesclimatdbdb0902201023int2tmn0902201023dtb 604987 updatesclimatdbdb0902201023int2tmx0902201023dtb bom conversions identical metadata 5388 updatesbomdbdb0902201023bomtmn0902201023dtb 5388 updatesbomdbdb0902201023bomtmx0902201023dtb bom merged into climat interims interims 607687 updatesbomdbdb0902201023int3tmn0902201023dtb 604987 updatesbomdbdb0902201023int3tmx0902201023dtb so the behaviour of newmergedbauto is for want of better word unpredictable oh joy and as indicated the bom updates are totally rejected quote bom tmn merge into interim db new master database updatesbomdbdb0902201023int3tmn0902201023dtb update database stations 898 matched with master stations 0 automatically 0 by operator 0 added as new master stations 0 rejected 898 rejects file updatesbomdbdb0902201023bomtmn0902201023dtbrejected end quote quote bom tmx merge into interim db update database stations 898 matched with master stations 0 automatically 0 by operator 0 added as new master stations 0 rejected 898 rejects file updatesbomdbdb0902201023bomtmx0902201023dtbrejected end quote i really thought i was cracking this project but every time it ends up worse than before ok lets try and work out the order of events im using getheads to look at metadata only 1 climat conversions these seem to be working fine crua6crucrutsclimatdbdb0902201023 cmp climattmn0902201023hds climattmx0902201023hds crua6crucrutsclimatdbdb0902201023 2 original databases they look ok crua6crucrutsversion_3_0update_topdb cmp tmntmn0708071548hds tmxtmx0708071548hds crua6crucrutsversion_3_0update_topdb 3 climat merging into original databases bad bad bad crua6crucrutsclimatdbdb0902201023 diff int2tmn0902201023hds int2tmx0902201023hds wc l 4848 crua6crucrutsclimatdbdb0902201023 something is very poorly its my programming skills isnt it looking at the log files for the climat merging they give identical stats what differ are the dates ie quote diffs between climat merge logs crua6crucrutsversion_3_0update_toplogslogs0902201023 diff mergclimattmn0902201023log mergclimattmx0902201023log more 12c12 master file dbtmntmn0708071548dtb update file updatesclimatdbdb0902201023climattmn0902201023dtb master file dbtmxtmx0708071548dtb update file updatesclimatdbdb0902201023climattmx0902201023dtb 281c281 code match with 1033800 5247 970 55 hannover dl gm 1927 2006 999 0 code match with 1033800 5247 970 55 hannover dl gm 1930 2006 999 0 287c287 code match with 1038400 5247 1340 49 berlintempelhof germany 1991 2006 999 0 code match with 1038400 5247 1340 49 berlintempelhof germany 1929 2006 999 0 end quote and so on whats got stumped is that the headers of both pairs of input databases are identical these dates are spurious look crua6crucrutsversion_3_0update_topdb grep 55 hannover tmntmn0708071548dtb 1033800 5247 970 55 hannover dl gm 1927 2006 999 0 crua6crucrutsversion_3_0update_topdb grep 55 hannover tmxtmx0708071548dtb 1033800 5247 970 55 hannover dl gm 1927 2006 999 0 crua6crucrutsversion_3_0update_topdb grep 49 berlintempelhof tmntmn0708071548dtb 1038400 5247 1340 49 berlintempelhof germany 1929 2006 999 0 crua6crucrutsversion_3_0update_topdb grep 49 berlintempelhof tmxtmx0708071548dtb 1038400 5247 1340 49 berlintempelhof germany 1929 2006 999 0 crua6crucrutsversion_3_0update_topdb you see the hannover 1930 date and the berlintempelhof 1991 date are wrong christ thats not even consistent ones supposedly in the tmin file the other the tmax one so an apparentlyrandom pollution of the start dates and found it as usual the program is doing exactly what i asked it to do when i wrote it i simply didnt consider the possibility of tmin and tmax needing to sync so one of the first things it does when reading in the exisitng database is to truncate station data series where whole years are missing values and for hannover tmax has 19271929 missing but tmin has some data in those years aha what to do i guess the logical thing to do is to not truncate for tmin and tmax so i added flag to newmergedbauto that it passes to the getmos subroutine that stops it from replacing start and end years and it worked hurrah or well it ran without giving any errors or crashing horribly yes thats it and here are all the 142 files and directories it created crua6crucrutsversion_3_0update_top find name 0902201545 resultsresults0902201545 resultsresults0902201545convmcdw0902201545res resultsresults0902201545mergmcdwtmp0902201545res resultsresults0902201545mergmcdwpre0902201545res resultsresults0902201545mergmcdwvap0902201545res resultsresults0902201545mergmcdwwet0902201545res resultsresults0902201545mergmcdwcld0902201545res resultsresults0902201545convclimat0902201545res resultsresults0902201545mergclimattmp0902201545res resultsresults0902201545mergclimatvap0902201545res resultsresults0902201545mergclimatwet0902201545res resultsresults0902201545mergclimatpre0902201545res resultsresults0902201545mergclimatcld0902201545res resultsresults0902201545mergclimattmn0902201545res resultsresults0902201545mergclimattmx0902201545res resultsresults0902201545convbom0902201545res resultsresults0902201545mergbomtmn0902201545res resultsresults0902201545mergbomtmx0902201545res resultsresults0902201545mdtr0902201545res runsruns0902201545 runsruns0902201545convmcdw0902201545dat runsruns0902201545mergmcdw0902201545dat runsruns0902201545convclimat0902201545dat runsruns0902201545mergclimat0902201545dat runsruns0902201545convbom0902201545dat runsruns0902201545mergbom0902201545dat runsruns0902201545mdtr0902201545dat dbtmptmp0902201545dtb dbtmntmn0902201545dtb dbtmxtmx0902201545dtb dbdtrdtr0902201545dtb dbprepre0902201545dtb dbvapvap0902201545dtb dbwetwet0902201545dtb dbcldcld0902201545dtb updatesbomdbdb0902201545 updatesbomdbdb0902201545bomtmn0902201545dtb updatesbomdbdb0902201545bomtmx0902201545dtb updatesbomdbdb0902201545int3tmn0902201545dtb updatesbomdbdb0902201545bomtmn0902201545dtbrejected updatesbomdbdb0902201545int3tmx0902201545dtb updatesbomdbdb0902201545bomtmx0902201545dtbrejected updatesbomdbdb0902201545int3dtr0902201545dtb updatesbommergefilesmergbomtmn0902201545mat updatesbommergefilesmergbomtmn0902201545act updatesbommergefilesmergbomtmn0902201545xrf updatesbommergefilesmergbomtmx0902201545mat updatesbommergefilesmergbomtmx0902201545act updatesbommergefilesmergbomtmx0902201545xrf updatesclimatmergefilesmergclimattmp0902201545mat updatesclimatmergefilesmergclimattmp0902201545act updatesclimatmergefilesmergclimattmp0902201545xrf updatesclimatmergefilesmergclimatvap0902201545mat updatesclimatmergefilesmergclimatvap0902201545act updatesclimatmergefilesmergclimatvap0902201545xrf updatesclimatmergefilesmergclimatwet0902201545mat updatesclimatmergefilesmergclimatwet0902201545act updatesclimatmergefilesmergclimatwet0902201545xrf updatesclimatmergefilesmergclimatpre0902201545mat updatesclimatmergefilesmergclimatpre0902201545act updatesclimatmergefilesmergclimatpre0902201545xrf updatesclimatmergefilesmergclimatcld0902201545mat updatesclimatmergefilesmergclimatcld0902201545act updatesclimatmergefilesmergclimatcld0902201545xrf updatesclimatmergefilesmergclimattmn0902201545mat updatesclimatmergefilesmergclimattmn0902201545act updatesclimatmergefilesmergclimattmn0902201545xrf updatesclimatmergefilesmergclimattmx0902201545mat updatesclimatmergefilesmergclimattmx0902201545act updatesclimatmergefilesmergclimattmx0902201545xrf updatesclimatdbdb0902201545 updatesclimatdbdb0902201545climattmp0902201545dtb updatesclimatdbdb0902201545climatvap0902201545dtb updatesclimatdbdb0902201545climatwet0902201545dtb updatesclimatdbdb0902201545climatpre0902201545dtb updatesclimatdbdb0902201545climatcld0902201545dtb updatesclimatdbdb0902201545climattmn0902201545dtb updatesclimatdbdb0902201545climattmx0902201545dtb updatesclimatdbdb0902201545int2tmp0902201545dtb updatesclimatdbdb0902201545climattmp0902201545dtbrejected updatesclimatdbdb0902201545int2vap0902201545dtb updatesclimatdbdb0902201545climatvap0902201545dtbrejected updatesclimatdbdb0902201545int2wet0902201545dtb updatesclimatdbdb0902201545climatwet0902201545dtbrejected updatesclimatdbdb0902201545int2pre0902201545dtb updatesclimatdbdb0902201545climatpre0902201545dtbrejected updatesclimatdbdb0902201545int2cld0902201545dtb updatesclimatdbdb0902201545climatcld0902201545dtbrejected updatesclimatdbdb0902201545int2tmn0902201545dtb updatesclimatdbdb0902201545climattmn0902201545dtbrejected updatesclimatdbdb0902201545int2tmx0902201545dtb updatesclimatdbdb0902201545climattmx0902201545dtbrejected updatesmcdwmergefilesmergmcdwtmp0902201545mat updatesmcdwmergefilesmergmcdwtmp0902201545act updatesmcdwmergefilesmergmcdwtmp0902201545xrf updatesmcdwmergefilesmergmcdwpre0902201545mat updatesmcdwmergefilesmergmcdwpre0902201545act updatesmcdwmergefilesmergmcdwpre0902201545xrf updatesmcdwmergefilesmergmcdwvap0902201545mat updatesmcdwmergefilesmergmcdwvap0902201545act updatesmcdwmergefilesmergmcdwvap0902201545xrf updatesmcdwmergefilesmergmcdwwet0902201545mat updatesmcdwmergefilesmergmcdwwet0902201545act updatesmcdwmergefilesmergmcdwwet0902201545xrf updatesmcdwmergefilesmergmcdwcld0902201545mat updatesmcdwmergefilesmergmcdwcld0902201545act updatesmcdwmergefilesmergmcdwcld0902201545xrf updatesmcdwdbdb0902201545 updatesmcdwdbdb0902201545mcdwtmp0902201545dtb updatesmcdwdbdb0902201545mcdwvap0902201545dtb updatesmcdwdbdb0902201545mcdwwet0902201545dtb updatesmcdwdbdb0902201545mcdwpre0902201545dtb updatesmcdwdbdb0902201545mcdwsun0902201545dtb updatesmcdwdbdb0902201545mcdwcld0902201545dtb updatesmcdwdbdb0902201545int1tmp0902201545dtb updatesmcdwdbdb0902201545mcdwtmp0902201545dtbrejected updatesmcdwdbdb0902201545int1pre0902201545dtb updatesmcdwdbdb0902201545int1vap0902201545dtb updatesmcdwdbdb0902201545mcdwvap0902201545dtbrejected updatesmcdwdbdb0902201545int1wet0902201545dtb updatesmcdwdbdb0902201545mcdwwet0902201545dtbrejected updatesmcdwdbdb0902201545int1cld0902201545dtb updatesmcdwdbdb0902201545mcdwcld0902201545dtbrejected logslogs0902201545 logslogs0902201545convmcdw0902201545log logslogs0902201545mergmcdwtmp0902201545log logslogs0902201545mergmcdwpre0902201545log logslogs0902201545mergmcdwvap0902201545log logslogs0902201545mergmcdwwet0902201545log logslogs0902201545mergmcdwcld0902201545log logslogs0902201545convclimat0902201545log logslogs0902201545mergclimattmp0902201545log logslogs0902201545mergclimatvap0902201545log logslogs0902201545mergclimatwet0902201545log logslogs0902201545mergclimatpre0902201545log logslogs0902201545mergclimatcld0902201545log logslogs0902201545mergclimattmn0902201545log logslogs0902201545mergclimattmx0902201545log logslogs0902201545convbom0902201545log logslogs0902201545mergbomtmn0902201545log logslogs0902201545mergbomtmx0902201545log logslogs0902201545mdtr0902201545log crua6crucrutsversion_3_0update_top so this leaves the new databases in the dbxxx directories and dblatestversionsdat telling us which ones they are which should be all the next suite of programs needs to create the final output files eeeeeeeek well for this half of the process its going to be 90 planning and strategy because thats how the first half ended up lets revisit the process list from earlier just the databaseonwards bits and interactivity removed produce primary parameters tmp tmn tmx dtr pre anomdtb per parameter quick_interp_tdm2 per parameter glo2abs per parameter makegrids per parameter prepare binary grids tmp dtr pre for synthetics quick_interp_tdm2 per parameter produce secondary parameter frs uses tmpdtr frs_gts_tdm quick_interp_tdm2 glo2abs makegrids produce secondary parameter vap uses tmpdtr vap_gts_anom anomdtb quick_interp_tdm2 glo2abs makegrids produce secondary parameter wetrd0 uses pre rd0_gts_anom anomdtb quick_interp_tdm2 glo2abs makegrids produce secondary parameter cld uses dtr anomdtb 9502 norm period movenorms dtr2cld quick_interp_tdm2 glo2abs makegrids having drawn out the process flowchart i wondered if quick_interp_tdm2pro would be kind enough to output both glo and binary gridded files simultaneously this would simplify and speed things up bit so with absolutely alarm bells ringing at all i decided to make sample run for dtr just for 2006 to compare simultaneous outputs with the original ones you idiot idl quick_interp_tdm220062006testdtrglodtr750gs05pts_prefixdtrtxtdtrdumpglodumpglodumpbindumpbin compiled module quick_interp_tdm2 compiled module glimit defaults set 2006 compiled module map_set compiled module crossp compiled module strip compiled module saveglo compiled module selectmodel stations found in dtrtxtdtr200609txt stations found in dtrtxtdtr200610txt stations found in dtrtxtdtr200611txt stations found in dtrtxtdtr200612txt compiled module mean compiled module moment compiled module stddev grid 2006 nonzero 01125 21122 29219 cells 202010 compiled module wrbin idl exit crua6crucrutsversion_3_0primariesdtr ls l testdtrglo total 43048 rw 1 f098 cru 6220800 feb 23 1106 dtr2006 rw 1 f098 cru 3142986 feb 23 1106 dtr200601glo rw 1 f098 cru 3142986 feb 23 1106 dtr200602glo rw 1 f098 cru 3142986 feb 23 1106 dtr200603glo rw 1 f098 cru 3142986 feb 23 1106 dtr200604glo rw 1 f098 cru 3142986 feb 23 1106 dtr200605glo rw 1 f098 cru 3142986 feb 23 1106 dtr200606glo rw 1 f098 cru 3142986 feb 23 1106 dtr200607glo rw 1 f098 cru 3142986 feb 23 1106 dtr200608glo rw 1 f098 cru 3142986 feb 23 1106 dtr200609glo rw 1 f098 cru 3142986 feb 23 1106 dtr200610glo rw 1 f098 cru 3142986 feb 23 1106 dtr200611glo rw 1 f098 cru 3142986 feb 23 1106 dtr200612glo crua6crucrutsversion_3_0primariesdtr so there as hopedfor binary and text output files but comparisons with earlier versions from the same database are depressingly awful crua6crucrutsversion_3_0primariesdtr diff dtr200601glo testdtrglodtr200601glo wc l 33484 crua6crucrutsversion_3_0primariesdtr sample comparison of lines 700710 from old and new glo files crua6crucrutsversion_3_0primariesdtr head 710 dtr200601glo tail 11 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 39705e04 11257e02 22117e02 31641e02 89739e03 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 crua6crucrutsversion_3_0primariesdtr head 710 testdtrglodtr200601glo tail 11 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 17088e03 85614e04 34384e06 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 crua6crucrutsversion_3_0primariesdtr theyre nothing like each other i really do hate this whole project ran the gridder again just for text output and crua6crucrutsversion_3_0primariesdtr head 710 testdtrglo2dtr200601glo tail 11 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 31268e03 65528e03 99787e03 13405e02 16831e02 97796e03 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 00000e00 crua6crucrutsversion_3_0primariesdtr different again can this just be the random seed used in the gridding algorithm if so why arent we seeing consistent pattern of 00 vs non00 values another reason if one were needed why we should dump this gridding approach altogether but er not yet time to finish and test the fortran gridder which will doubtless sink to some depth and never be seen again well carry on with this mediocre approach spent whole day knocking up an anomaly program as i felt anomdtb was vastly overweight and supremely complicated to compile unfortunately i got stuck trying to work out data and latlon factors for different parameters argh why and what percentage anomalies really were and in the end gave up and now i have to modify anomdtb after all actually that looked even worse so went back to anomauto and finished it off and it works actually bit too well for example when deriving anomalies from the cld database this was the original few weeks ago uealogin1crucrutsversion_3_0update_top wc l cld200011txt 606 cld200011txt and this is the new one from the same source database of course uealogin1crucrutsversion_3_0update_top wc l interim_dataanomsanoms0902201545cldcld200011txt 1282 interim_dataanomsanoms0902201545cldcld200011txt so um more than twice as many got through erk screening not tough enough results also not exactly identical indicates potential match old uealogin1crucrutsversion_3_0update_top head 10 cld200011txt 6827 2230 3270 2120000 208000 6583 2415 60 4100000 219600 6318 1450 3700 4530000 222600 5937 1347 550 4390000 241800 5778 1188 530 3550000 251200 5767 1835 470 4210000 259000 6975 2703 1010 2380000 280500 6737 2665 1790 2430000 283600 6493 2537 150 3340000 287500 6240 2568 1450 080000 293500 new uealogin1crucrutsversion_3_0update_topinterim_dataanomsanoms0902201545cld head 10 cld200011txt 6727 1437 130 485715 115200 6827 2230 3270 856250 208000 6583 2415 60 1659999 219600 6318 1450 3700 326250 222600 5937 1347 550 1533749 241800 5778 1188 530 893749 251200 5767 1835 470 658749 259000 6013 118 840 702500 300500 5822 632 130 122501 302600 5720 222 650 780000 309100 ok lets look at the means being used heres an example lat lon alt anom wmo mean 6827 2230 3270 856250 208000 9014 and the actual nov 2000 value for this station karesuando sweden is 987 2000 887 800 90099999999 812 762 825 625 825 9879999 ok so we read in 987 then we multiply by the factor which should be 01 giving us 987 then we subtract the mean giving us 9879014 856 which is what were getting so mismatches between data time and metadata good and the 9502 mean is right too 901375 so er ah solved it looking at the wrong old cloud text files tadaa old but correct crua6crucrutsversion_3_0update_top head 10 secondariescldcldupdatetxtcldupdate200011txt 6827 2230 3270 850000 208000 6583 2415 60 1660000 219600 6318 1450 3700 320000 222600 5937 1347 550 1530000 241800 5778 1188 530 890000 251200 5767 1835 470 650000 259000 6975 2703 1010 890000 280500 6737 2665 1790 940000 283600 6493 2537 150 1120000 287500 6240 2568 1450 590000 293500 hurrah now i need to know why im producing too many its not as bad though old but correct crua6crucrutsversion_3_0update_top wc l secondariescldcldupdatetxtcldupdate200011txt 760 secondariescldcldupdatetxtcldupdate200011txt new uealogin1crucrutsversion_3_0update_top wc l interim_dataanomsanoms0902201545cldcld200011txt 1282 interim_dataanomsanoms0902201545cldcld200011txt lets look at the first example station we let through that anomdtb kicked back 0115200 6727 1437 13 bodo vi civmil norway 1995 2008 999 0 6190999999999999999999999999999999999999999999999999 1995999999999999999999999999999999999999 87599999999 1996999999999999999999999999999999999999999999999999 1997999999999999999999999999999999999999999999999999 19989999999999999999 575 675 762 762 675 837 7759999 1999 1000 812 762 750 550 750 862 775 637 825 10009999 2000 1000 912 800 750 812 850 737 825 700 737 8629999 2001 875 750 475 650 775 775 825 825 750 900 10009999 2002 800 862 750 737 612 6129999 562 800 462 7629999 2003 850 825 862 550 7129999 525 775 762 750 8259999 2004 937 875 762 525 637 725 787 675 837 750 10009999 2005 1000 812 762 700 737 775 687 800 850 85099999999 20069999 850 500 61299999999 800 575 812 750 9629999 2007 1000 712 750 837 762 687 675 812 850 975 9509999 2008 1000 887 6879999 750 775 675 612 725 88799999999 now our limit for valid normal is 75 which for 19952002 should mean 6 bodo vi has five valid values in november so our limit is either wrong or not being applied yup uealogin1crucrutsversion_3_0update_top anomauto minn calculated as 7 ho hum recalculated it to 6 whilst checking that 19611990 still gave 23 reran to my horror if not surprise that let even more in well of course it did you silly sausage this still doesnt explain how bodo vi gets in with 5 values uealogin1crucrutsversion_3_0update_top wc l interim_dataanomsanoms0902201545cldcld200011txt 1404 interim_dataanomsanoms0902201545cldcld200011txt aha i wonder if im initialising the onestn array in the wrong place because data is only added if not 9999 so it has to be prefilled with 9999 every time dammit if i fix that i get uealogin1crucrutsversion_3_0update_top wc l interim_dataanomsanoms0902201545cldcld200011txt 746 interim_dataanomsanoms0902201545cldcld200011txt 14 stations less than the previous exercise thatll do surely old reliable crua6crucrutsversion_3_0update_top head 10 secondariescldcldupdatetxtcldupdate200011txt 6827 2230 3270 850000 208000 6583 2415 60 1660000 219600 6318 1450 3700 320000 222600 5937 1347 550 1530000 241800 5778 1188 530 890000 251200 5767 1835 470 650000 259000 6975 2703 1010 890000 280500 6737 2665 1790 940000 283600 6493 2537 150 1120000 287500 6240 2568 1450 590000 293500 new latest uealogin1crucrutsversion_3_0update_top head interim_dataanomsanoms0902201545cldcld200011txt 6827 2230 3270 856250 208000 9014 6583 2415 60 1659999 219600 8340 6318 1450 3700 326250 222600 8544 5937 1347 550 1533749 241800 8466 5778 1188 530 895714 251200 8604 5767 1835 470 658749 259000 8591 6975 2703 1010 895714 280500 9104 6737 2665 1790 947143 283600 9053 6493 2537 150 1127142 287500 8873 6240 2568 1450 590000 293500 9410 its not going to be easy to find 14 missing stations is it since the anomalies arent exactly the same should i be worried about 14 lost series less than 2 actually i noticed something interesting look at the anomalies the anomdtb ones arent rounded to 1dp theyre truncated so er wrong so lets say anomalies are done hurrah onwards plenty more to do got the gridding working i think idl of course i modified quick_interp_tdm2pro to accept start and end months otherwise it just produces whole years with files of zeros for months with anomaly file and errors and since this is likely to be sixmonth update replanned the program layout not major exercise just putting different loops in to speed up and simplify operations it now runs as follows note this is simplified 1 user chooses update databases or update datasets dates parameters etc 2 update databases 21 convert any mcdw bulletins to cru format merge into existing databases 22 convert any climat bulletins to cru format merge into databases from 21 23 convert any bom bulletins to cru format merge into databases from 22 3 update datasets 31 convert databases to anomalies 32 grid primary parameters 33 generate synthetic secondary parameters 34 grid secondary parameters 35 convert gridded anomalies to actuals 36 produce final datasets 1876 lines including subrotuines and notes ten fortran and four idl programs plus indirect ones all fortran programs are mine now toplevel listing drwx 10 f098 cru 4096 feb 19 2055 db drwx 3 f098 cru 4096 feb 28 1701 reference drwx 3 f098 cru 4096 mar 1 1541 runs drwx 4 f098 cru 4096 feb 23 1215 gridded_finals drwx 4 f098 cru 4096 feb 27 1756 results drwx 5 f098 cru 4096 mar 1 1540 logs drwx 6 f098 cru 4096 dec 18 1100 updates drwx 8 f098 cru 4096 feb 28 1615 interim_data rw 1 f098 cru 11 feb 27 1748 newdatalatestdate rwxrxrx 1 f098 cru 132425 mar 1 1441 update rwxrxrx 1 f098 cru 16465 mar 1 1441 dtr2cldauto rwxrxrx 1 f098 cru 17990 mar 1 1455 tmnx2dtrauto rwxrxrx 1 f098 cru 19427 mar 1 1543 glo2absauto rwxrxrx 1 f098 cru 20929 mar 1 1442 movenormsuato rwxrxrx 1 f098 cru 23350 mar 1 1542 anomauto rwxrxrx 1 f098 cru 29076 mar 1 1450 climat2cruauto rwxrxrx 1 f098 cru 29481 mar 1 1450 bom2cruauto rwxrxrx 1 f098 cru 29867 mar 1 1449 mcdw2cruauto rwxrxrx 1 f098 cru 323870 mar 1 1552 makegridsauto rwxrxrx 1 f098 cru 89515 mar 1 1610 newmergedbauto so to station counts these will have to mirror section 3 above coverage of secondary parameters is particularly difficult what is the best approach to include synthetic coverage when its only at 25degree im going to back my previous decision all station count files reflect actualy obs for that parameter only so for secondaries you get actual obs of that parameter ie naff all for frs you get the info about synthetics that enables you to use the relevant primary counts if you want to of course im going to have to provide combined tmp and dtr station count to satisfy vap frs users the problem is that the synthetics are incorporated at 25degrees idea why so saying they affect particular 05degree cells is harder than it should be so well just gloss over that entirely 0 argh just went back to check on synthetic production apparently i have memory of this at all were not doing observed rain days its all synthetic from 1990 onwards so im going to need conditionals in the update program to handle that and separate gridding before 1989 and what tf happens to station counts oh fuck this its sunday evening ive worked all weekend and just when i thought it was done im hitting yet another problem thats based on the hopeless state of our databases there is uniform data integrity its just catalogue of issues that continues to grow as theyre found rd0_gts_anom_05 will produce halfdegree glo files from gridded pre anoms so if we call that we can use it and stncounts for pre will be authentic as its the sole input final decision coded updatefor to produce wet from obssyn until 121989 syn only thereafter wet station counts only produced until 1989 pre must be used with caveats after that point wrote tmpdtrstnsautofor to produce tmpanddtr station counts ie you only get count when both parameters have count and even then its the min the resulting counts are the effective frs counts and the synthetic vap counts onto pet tracked down the pet program from dimitrios way back in 2007 it uses tmp tmn tmx vap cld and wnd the latter as 6190 normals from ipcc converted to f77 automatic makepetautofor onto whole runs of the update program with lot of debugging discovered that wmo codes are still pain in the arse and that id forgotten to match australian updates by bom code last field in header instead of wmo code so i had to modify newmergedbauto also found that running fixwmosfor was less than successful on vap because its already screwed uealogin1crucrutsversion_3_0update_topdbvap grep i jan mayen vap0804231150dtb 0100100 7093 867 9 jan mayennornavy norway 2003 2007 999 0 1001000 7093 866 9 jan mayennor navy norway 1971 2003 999 999 uealogin1crucrutsversion_3_0update_topdbvap started work on fixdupesfor to cleanse given database of obvious duplicate stations but self diverted back onto getting the whole update process compiled and running end to end almost immediately found that match rated in the merging were mixed added section to newmergedbauto that did quick matchmaking exercise on any update stations that failed the code matching just latlon and character fields really didnt seem to make lot of difference here are the merge results for all updates and parameters in the order they would have happened uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergmcdwtmp0903091631log outputs written new master database updatesmcdwdbdb0903091631int1tmp0903091631dtb update database stations 2802 matched with master stations 1759 automatically 1759 by operator 0 added as new master stations 1043 rejected 0 uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergmcdwpre0903091631log outputs written new master database updatesmcdwdbdb0903091631int1pre0903091631dtb update database stations 2807 matched with master stations 2783 automatically 2783 by operator 0 added as new master stations 24 rejected 0 uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergmcdwvap0903091631log new master database updatesmcdwdbdb0903091631int1vap0903091631dtb update database stations 2804 matched with master stations 2677 automatically 2677 by operator 0 added as new master stations 124 rejected 3 rejects file updatesmcdwdbdb0903091631mcdwvap0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergmcdwwet0903091631log new master database updatesmcdwdbdb0903091631int1wet0903091631dtb update database stations 2801 matched with master stations 2634 automatically 2634 by operator 0 added as new master stations 163 rejected 4 rejects file updatesmcdwdbdb0903091631mcdwwet0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergmcdwcld0903091631log new master database updatesmcdwdbdb0903091631int1cld0903091631dtb update database stations 2204 matched with master stations 2199 automatically 2199 by operator 0 added as new master stations 0 rejected 5 rejects file updatesmcdwdbdb0903091631mcdwcld0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimattmp0903091631log new master database updatesclimatdbdb0903091631int2tmp0903091631dtb update database stations 3065 matched with master stations 2629 automatically 2629 by operator 0 added as new master stations 345 rejected 91 rejects file updatesclimatdbdb0903091631climattmp0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimatvap0903091631log new master database updatesclimatdbdb0903091631int2vap0903091631dtb update database stations 3039 matched with master stations 2912 automatically 2912 by operator 0 added as new master stations 38 rejected 89 rejects file updatesclimatdbdb0903091631climatvap0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimatwet0903091631log new master database updatesclimatdbdb0903091631int2wet0903091631dtb update database stations 3047 matched with master stations 2718 automatically 2718 by operator 0 added as new master stations 232 rejected 97 rejects file updatesclimatdbdb0903091631climatwet0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimatpre0903091631log new master database updatesclimatdbdb0903091631int2pre0903091631dtb update database stations 3054 matched with master stations 2801 automatically 2801 by operator 0 added as new master stations 229 rejected 24 rejects file updatesclimatdbdb0903091631climatpre0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimatcld0903091631log new master database updatesclimatdbdb0903091631int2cld0903091631dtb update database stations 2038 matched with master stations 1964 automatically 1964 by operator 0 added as new master stations 71 rejected 3 rejects file updatesclimatdbdb0903091631climatcld0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimattmn0903091631log new master database updatesclimatdbdb0903091631int2tmn0903091631dtb update database stations 2921 matched with master stations 2406 automatically 2406 by operator 0 added as new master stations 387 rejected 128 rejects file updatesclimatdbdb0903091631climattmn0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergclimattmx0903091631log new master database updatesclimatdbdb0903091631int2tmx0903091631dtb update database stations 2921 matched with master stations 2406 automatically 2406 by operator 0 added as new master stations 387 rejected 128 rejects file updatesclimatdbdb0903091631climattmx0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergbomtmn0903091631log new master database updatesbomdbdb0903091631int3tmn0903091631dtb update database stations 906 matched with master stations 783 automatically 783 by operator 0 added as new master stations 120 rejected 3 rejects file updatesbomdbdb0903091631bomtmn0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 tail mergbomtmx0903091631log new master database updatesbomdbdb0903091631int3tmx0903091631dtb update database stations 906 matched with master stations 783 automatically 783 by operator 0 added as new master stations 120 rejected 3 rejects file updatesbomdbdb0903091631bomtmx0903091631dtbrejected uealogin1crucrutsversion_3_0update_toplogslogs0903091631 probably the worst story is temperature particularly for mcdw over 1000 new stations highly unlikely i am tempted to blame the different latlon scale but for now it will have to rest still hitting the problem with tmp lats and lons being mix of deg10 and deg100 its screwing up the station counts work of course unfortunately i did some tests and the original tmp database has the trouble its not my update suite then i worked it out sample headers from the original tmp db tmp0705101334dtb 10010 709 87 10 jan mayen norway 1921 2006 341921 99900 10050 780 142 9 isfjord radio norway 1912 1979 101912 99900 10080 783 155 28 svalbard lufthavn norway 1911 2006 341911 99900 10100 693 162 999 andenes 1868 1955 101868 99900 10250 697 189 10 tromsolangnes norway 1949 2006 101949 99900 10260 697 189 100 tromsoe norway 1890 2006 341890 99900 10280 745 190 16 bjoernoeya norway 1920 2006 341920 99900 and from the fixwmoswmofixed version tmp0903081416dtb 0100100 7090 870 10 jan mayen norway 1921 2006 341921 99900 0100500 7800 1420 9 isfjord radio norway 1912 1979 101912 99900 0100800 7830 1550 28 svalbard lufthavn norway 1911 2006 341911 99900 0101000 6930 1620 999 andenes 1868 1955 101868 99900 0102500 6970 1890 10 tromsolangnes norway 1949 2006 101949 99900 0102600 6970 1890 100 tromsoe norway 1890 2006 341890 99900 0102800 7450 1900 16 bjoernoeya norway 1920 2006 341920 99900 fm fixwmos fixed coordinates as well heres the snippet locfac 10 init location factor assuming lat lon are in degs10 do i110000 read10a86end12buffy readbuffyfmtwmolatlonaltsnamectrysyeyflagextref if latgtmaxlat maxlat lat if latgt900 goto 12 do jsyeynorml read10 enddo enddo 12 if maxlatgt900 locfac 1 lat lon are in degs 100 so it was written with tmp in mind oh for memory so we dont need to fret about tmp latlon being 10 any more and its taken until now to realise that the idl synthetic generators vap_gts_anom frs_gts_tdm rd0_gts_anom all need to calculate 19611990 normals so they will need tmp dtr andor pre binary normals for 1961 to 1990 which means anomalies will have to be automatically generated for that period regardless of the requested period cries introduced suitable conditionals to ensure that 6190 anomalies and gridded binaries are automatically produced if the relevant secondary parameters are requested more runtime issues vap is still giving an apparently nonfatal error program caused arithmetic error floating underflow program caused arithmetic error floating overflow program caused arithmetic error floating illegal operand this only appears once the vap_gts_anompro program has finished so cant be identified stuck on wet production getting an error from rd0_gts_anom_05pro from the same bit of code that works fine in rd0_gts_anompro the error attempt to subscript rd0syn with nsea is out of range execution halted at rd0_gts_anom_05 34 cruautocrutsversion_3_0badc_areaprogramsidlrd0_gts_anom_05pro main line 34 rd0synfloatprenorm00 rd0synnsea9999 do you know i actually worked this one out by myself preen it turned out that nsea was 1 which meant that it was finding hits here nsea whererd0norm eq 9999 or prenorm eq 9999 when i looked the min and max of rd0norm and prenorm were 32768 32514 and i thought what coincidence thats 216 aha must be an endian problem looked it up on the web abd the idl ref manual and found that adding swap_if_big_endian to the end of the openr statements in rdbinpro it all worked and then of course another problem i should have anticipated halfdegree gridding of synthetics needs halfdegree primary binaries so the precip binaries must be halfdegree for wet after 1989 and the usual 25degrees earlier more modifications to updatefor and it took further 24 hours to cotton on that id need halfdegree tmp and dtr binaries for frs vap wont mind as its using the synthetics as an adjunct to the observations the exceptions are those secondaries where observations can be used wet after 1989 frs and cld after 2002 but cld considerately works from dtr anomalies ungridded so im going to have to produce halfdegree gridded binary tmp and dtr anomalies adding half an hour to the run time bollocks though i could be clever and save it then id have to monitor when 19611990 databases were altered and compare and wibble got that done then got it all working though outputs not tested whooo now for badc actually badc wasnt too bad took day or so to get everything to compile mainly having to shift to gfortran rather than f77 and also to use w to suppress warnings discovered that the idl there didnt look at idl_startup bah but then found way to specify startup file on the command line ie call systemidl runsrunsdtstr idlsyn1wettxtdtstrdat quiet idl startup so thats all right then got it all running without errors at badc well i say that im still getting this for vap gridding pre anomalies at 05 for synthetics producing secondary vap program caused arithmetic error floating overflow program caused arithmetic error floating illegal operand gridding vap anomalies and synthetics producing secondary wet i havent been able to identify whats causing that um anyway the next items are the tricky saving of 25 and 05 binaries for 19611990 only regenerating then if the dbs have been altered requires multiprocess cooperation since we cant tell from the database timestamps which years were potentially changed admittedly with this system that only accepts mcdwclimatbom updates pre1991 change is all but impossible but build for the case you cant anticipate also up next is the deconstruction of the early cloud data ie to 2002 so we can generate netcdf files for the whole shebang degroupcldfor will do the honours did cld first having reverseengineered gabs gridded absolute files for 19012002 i then modified update extensively to skip anything to do with cld including station counts before 2003 then at the anomstoabsolutes stage unzipped and copied over any pre2003 cld gabs files from the reference repository i suppose ill have to do cld station counts just n obviously at some stage too ran update just for cld just for 1901062006 realised halfway through that id really have to do station counts as well because update does em for dtr anyway that ought to cut out but doesnt at the moment its getting faster implementing the saved binaries was easier than i thought as well lots to change but straightforward now the idl synthetics generators will always look in the reference area for 19611990 gridded binaries whether 25degree or 05degree and those datasets should be regenerated if flags are set that 19611990 data has been changed in the databases then big problem lots of stars in the pet gridded absolutes wrote sidebysidem to display the five input parameters vap looks like being the culprit with unfeasibly large values up to 10034 in fact and thats after the standard 10 so erm drainsup on vap is now required oh joy and cld also looks unacceptable despite all that work big patches of 100 and 0 dominate doubt result of clipping by glo2absauto the clipping is necessary but shouldnt be needed so often reassuringly the 3_00 vap and cld that are published look fine so its soemthing ive done in the automation process misscaling is most likely started chaining back through initially vap the gabs files were identical to the finals now if that had failed it would have been problem the gridded anomaly files were lot more interesting because although they looked just as bad their max values were exactly 9999 that aint coincidence trailing fiurther back vap anoms are ok so suspicion falls on the synthetics and and behold rerunning the tmp and dtr 25grid binary productions with quick_interp_tdm2 gives idl quick_interp_tdm220062006interim_datagbinsgbins0903201540tmptmp1200gs25pts_prefixinterim_dataanomsanoms0903201540tmptmpdumpbindumpbinstartm07endm12 defaults set 2006 grid 2006 nonzero83414424 83414424 37126726 cells 74509 idl quick_interp_tdm220062006interim_datagbinsgbins0903201540dtrdtr 750gs25pts_prefixinterim_dataanomsanoms0903201540dtrdtrdumpbindumpbinstartm07endm12 defaults set 2006 grid 2006 nonzero91169639 91169639 28250928 cells 68171 idl those strings of numbers theyre supposed to be mean average magnitude and std dev should look something like this idl quick_interp_tdm220062006testdtrglodtr750gs05pts_prefixdtrtxtdtrdumpglodumpglodumpbindumpbin defaults set 2006 grid 2006 nonzero 01125 21122 29219 cells 202010 if i run with infoinfo i get mean av mag std dev 2006 data 2006 month 7 00981 11909 17665 data 2006 month 8 03129 13504 19677 data 2006 month 9 02413 12774 20954 data 2006 month 10 00024 13375 20739 data 2006 month 11 02594 11632 20542 data 2006 month 12 00874 13236 22353 confirming that the dtr in this case incoming anomalies are all within expected tolerances ooh just found this few thousand lines back which may be relevant quote on parallel track this would really have been better as blog tim has found that the binary grids of primary vars used in synthetic production of secondary parameters should be produced with binfac set to 10 for tmp and dtr this may explain the poor performance and coverage of vap in particular end_quote did that help not much at all unfortunately this is frustrating i cant see whats different i even enabled commentedout line that prints the ranges of pts22 and r and they look ok idl quick_interp_tdm220062006interim_datagbinsgbins0903201540dtrdtr 750gs25pts_prefixinterim_dataanomsanoms0903201540dtrdtrdumpbindumpbinstartm07endm12infoinfo mean av mag std dev 2006 data 2006 month 7 00981 11909 17665 104367 175867 715403 145088 data 2006 month 8 03129 13504 19677 700800 256929 489867 157781 data 2006 month 9 02413 12774 20954 184621 262400 151905 227162 data 2006 month 10 00024 13375 20739 861333 185400 605684 157678 data 2006 month 11 02594 11632 20542 691852 333200 510848 285915 data 2006 month 12 00874 13236 22353 876667 244500 603609 219419 grid 2006 nonzero91249951 91249951 28131790 cells 68111 idl ok i think ive got it its the fact that were writing yearly binary file but only have data for the second half of that year minmax janjun 999900 999900 minmax juldec 151905 285915 now i dont see how we get grid 2006 nonzero91251289 91251289 28130332 cells 68110 but i do see how vap_gts_anom might just read the first six months which would all be 9999 so we need to be able to write sixmonth binaries oh my giddy aunt what crap crap system well have to switch to monthly binaries its the only unambiguous way meaning major modifications to numerous idl proglets fuck everything from the main progs vap_gts_anom quick_interp_tdm2 etc to the supporting ones rdbin for one after hours i think ive sussed it at least for vap the incoming integer binaries had to be constructed with binfac10 because otherwise the integer bit renders most anomalies 0 then in the vap_gts_anom script the values have to be divided by 100 to give degrees any other combination of scaling factors throws the sat vap pressure calculations into the weeds of course monthly binaries are still required ho hum modified quick_interp_tdm2 to take another additional commandline option dumpmobin which if set will see that binaries are saved monthly not yearly of course the 25degree tmp and dtr binary grids are only used by vap frs uses 05degree so rather than carry on with mods i thought id mod update enough to fix vap then run it all again well it ran until pet production where it crashed with the same understandable read error as before not being an integer however when i invoked the matlab sidebyside proglet to examine the vap it was much improved on the previous vap the max was still 10000 just shade too high but the actual spatial pollution was much reduced theres hope i think this all stems from the sensitivity of the saturated vapour pressure calculations where factor of 10 error in an input can make factor of 1000 difference to the output had to briefly divert to trick makegridsauto into thinking it was in the middle of full 19012006 update to get cld netcdf files produced for the whole period to june 06 kept some important users in bristol happy so back to vap tried dividing the incoming tmp 7 dtr binaries by 1000 still joy then had the bright idea of imposing threshold on the 300 vap in the matlab program the result was that quite lot of data was lost from 300 but what remained was very good match for the 210 data on which the thresholds were based i think ive got it hey i might be home by 11 i got quick_interp_tdm2 to dump minmax for the synthetic grids guess what our old friend 32767 is here again otherwise known as bigendian trauma and sure enough the 05 and 25 binary normals which i inherited ive never produced them both need to be opened for reading with openrlunfnameswap_if_big_endian so i added that as an argument to rdbin and used it wherever rdbin is called to open these normals so i went through all the idl routines i added an integertofloat conversion on all binary reads and generally spruced things up also went through the parameters one by one and fixed hopefully their scaling factors at each stage what minefield the pet problem or unwriteable numbers was solved by this tightening of secondaries particularly vap and also putting in clause to abs any negative values from the wind climatology i really dont think there should be any but there are finally im able to get run of all ten parameters the results compared to 210 with sidebyside3colm are pretty good on the whole not really happy with frs range ok but mysterious banding in southern hemisphere or pet pet range210 0 573 range300 0 175000 so ive ended up with range that doesnt scale simply to the 210 range i also have idea what the actual range ought to be and they said pet would be easy next step has to be comparison of maxmin values of pet precursors vs pet actuals for the two sources did that significant differences except that of course the 210 pet was produced with uncorrected wind when i took out the correction for 300 it shot up to even higher levels so well just have to ignore 210 comparisons with pet still top whack of 175 isnt too good for pet printed out the ranges of the precursors pet precursor parameters ranges tm 4940 3920 tn 5280 3950 tx 4510 5980 vp 000 3660 wn 000 2900 cl 000 100 so the temps are in degs c vapour pressures in hpa winds in ms and clouds fractional then i thought about it 175mmday is pretty good especially as it looks to be eastern sahara as for frs with those odd longitudinal stripes i just tidied the idl prog up and it er went away how very comforting did complete run for 706 to 1206 ran the matlab visuals all params looked ok if not special ftpd the program suite and reference tree to badc replacing the existing ones and tried the same full run there well the first thing i noticed was how slow it was ooops maybe 3x slower than uealogin1 then lots of error messages see below i had wondered whether the big endian scene was going to show maybe this is it anyway it finished heres the screen dump quote date25 0903270742 date05 0903270742 last6190 0901010001 producing anomalies producing station counts gridding primary parameters producing gridded binaries for synthetics gridding tmp binary anomalies for secondary support program caused arithmetic error floating illegal operand gridding dtr binary anomalies for secondary support program caused arithmetic error floating illegal operand gridding tmp anomalies at 05 for synthetics gridding dtr anomalies at 05 for synthetics gridding pre anomalies at 05 for synthetics program caused arithmetic error floating illegal operand producing secondary vap program caused arithmetic error floating divide by 0 program caused arithmetic error floating underflow program caused arithmetic error floating overflow program caused arithmetic error floating illegal operand gridding vap anomalies and synthetics producing secondary wet producing secondary cld making synthetic cld from dtr anomalies gridding cld anomalies and synthetics producing secondary frs converting anomalies to absolutes deriving pet creating output data and station files creating final nstation tmpdtr files creating final 0station tmpdtr files all work completed satisfactorarily see logscompletioninfolog0904010108dat and logslogs0904010108update0904010108log bash300 end_quote pulled back the output files and ran the sidebyside3col matlab script to compare with ours interesting here are the ranges tmp badc 300 mm 494 392 cru 300 mm 494 392 tmn badc 300 mm 528 395 cru 300 mm 528 395 tmx badc 300 mm 451 598 cru 300 mm 451 598 dtr badc 300 mm 1 392 cru 300 mm 1 392 pre badc 300 mm 0 4573 cru 300 mm 0 4573 vap badc 300 mm 0 479 cru 300 mm 0 363 wet badc 300 mm 0 310 cru 300 mm 0 3095 cld badc 300 mm 0 999 cru 300 mm 0 100 frs badc 300 mm 0 310 cru 300 mm 0 310 pet badc 300 mm 0 171 cru 300 mm 0 175 i dont know which is more worrying the vap discrepancy or the fact that the minimum dtr is 1 degree for both the maximum badc cld is 999 and the maximum cru wet is 3095 days well i guess the vap issue is the showstopper and must be related to those errors producing secondary vap program caused arithmetic error floating divide by 0 program caused arithmetic error floating underflow program caused arithmetic error floating overflow program caused arithmetic error floating illegal operand now these are idl errors and probably from our old pal vap_gts_anom_mpro so the established procedure is to rerun just that program with all the info turned on oh my idl path programsidl path idl vap_gts_anom_m20062006dtr_prefixinterim_datagbinsgbins0904010108dtrdtrtmp_prefixinterim_datagbinsgbins0904010108tmptmpoutprefixinterim_datasynssyns0904010108vapvapsyndumpbin1startm07endm12 compiled module vap_gts_anom_m landsea 56016 68400 calculating tmn normal calculating synthetic vap normal calculating synthetic anomalies 200607 vap xs2 inf nan inf 121306 200608 vap xs2 inf nan inf 154191 200609 vap xs2 inf nan inf 232317 200610 vap xs2 inf nan inf 224792 200611 vap xs2 inf nan inf 157444 200612 vap xs2 inf nan inf 112271 program caused arithmetic error floating divide by 0 program caused arithmetic error floating underflow program caused arithmetic error floating overflow program caused arithmetic error floating illegal operand idl yes its back right back where we started with vap at cru all those er days ago well last time it was big endian stuff wasnt it and presumably the little linux box at badc is big endian so i might try changing those rdbin calls just to see that didnt seem to help heres dump of key array ranges just before the main loop kicks in norgrd minmax 689000 366000 tadj minmax 715433 445602 tmpgrd minmax 316530 315360 dtrgrd minmax 186890 161280 vapsyn minmax 001000000 inf v minmax 000000 inf so tmpgrd and dtrgrd look waaay too high though could just be 100 v and vapsyn are shot this does look like scaling boo hoo i fixed that these are the ranges on uealogin1 norgrd minmax 689000 366000 tadj minmax 467671 258468 tmpgrd minmax 689000 376000 dtrgrd minmax 740000 630000 vapsyn minmax 00100000 334119 v minmax 000521439 419604 i wonder if i need to reverse the rdbin logic reverse_if_little_endian on the nonclim calls since normals are reading ok without it cru version has bigend1 badc version doesnt lets try with just the tmpgrd dtrgrd reads ooh norgrd minmax 689000 366000 tadj minmax 715433 445602 tmpgrd minmax 689000 376000 dtrgrd minmax 740000 630000 vapsyn minmax 001000000 593142 v minmax 000521439 610593 200607 vap xs2 0614392 157785 533517 102892 200608 vap xs2 0593988 169958 355033 123374 200609 vap xs2 0448958 0793516 520586 104787 200610 vap xs2 0525755 115223 283614 892979 200611 vap xs2 0243011 0939122 466185 212776 200612 vap xs2 0302154 0628504 505943 584549 program caused arithmetic error floating underflow program caused arithmetic error floating overflow idl so just tadj to fix then though surely i should read the 2006 tmp dtr the same way or is it that i copied the 6190 over from here but generated the 2006 there ah should probably regenerate the 6190 binaries at badc yes anyway found the other tmpdtr reads and adjusted those and behold norgrd minmax 689000 366000 tadj minmax 467671 258468 tmpgrd minmax 689000 376000 dtrgrd minmax 740000 630000 vapsyn minmax 001000000 334119 v minmax 000521439 419604 200607 vap xs2 0493936 115553 614130 582037 200608 vap xs2 0460588 0994776 442765 569217 200609 vap xs2 0381708 0674991 456722 827954 200610 vap xs2 0506931 0895855 437382 513692 200611 vap xs2 0263565 0656560 384704 115171 200612 vap xs2 0374605 0791715 315873 641023 the cru version has the same ranges but some month stats differ norgrd minmax 689000 366000 tadj minmax 467671 258468 tmpgrd minmax 689000 376000 dtrgrd minmax 740000 630000 vapsyn minmax 00100000 334119 v minmax 000521439 419604 200607 vap xs2 0462426 111003 614130 469486 200608 vap xs2 0428764 0999707 442765 648673 200609 vap xs2 0342277 0642287 456722 827954 200610 vap xs2 0485457 0858445 437382 513692 200611 vap xs2 0276767 0685921 372504 115171 200612 vap xs2 0373327 0862642 315873 153975 december in particular has quite drift idea why since the data going in should be the same so another full run with regeneration of binary reference grids enforced tmp badc 300 mm 494 392 cru 300 mm 494 392 tmn badc 300 mm 528 395 cru 300 mm 528 395 tmx badc 300 mm 451 598 cru 300 mm 451 598 dtr badc 300 mm 1 392 cru 300 mm 1 392 pre badc 300 mm 0 4573 cru 300 mm 0 4573 vap badc 300 mm 0 365 cru 300 mm 0 363 wet badc 300 mm 0 3093 cru 300 mm 0 3095 cld badc 300 mm 0 999 cru 300 mm 0 100 frs badc 300 mm 0 310 cru 300 mm 0 310 pet badc 300 mm 0 175 cru 300 mm 0 175 i honestly dont think itll get closer so i guess ill clear out and reset the badc process and let kevin loose on it well badc have had it for good while without actually doing anything what surprise its lucky actually as ive ironed out few bugs including pet being garbage one bug is eluding however i cant get full 19012008 run to complete it gets stuck after producing the final tmp files data plus stations it just seems to sit there indefinitely so i tried different periods 19012008 failed 1901 only worked 2008 only worked 19011910 worked 19011950 worked 19512008 worked 19012008 failed sigh what the hells going on well time to ask the compiler so i recompiled as follows g77 update wall wsurprising fboundscheck programsfortranupdatefor then i reran this time i got an error almost immediately producing anomalies subscript out of range on file line 1011 procedure programsfortranupdateformain attempt to access the 6th element of variable dobin25subscript1of2 abort core dumped hurrah in way thyat bug was easy enough id just forgotten to put an extra test iparle5 in the test for binary production so as it was in 18 loop there was bound ho ho to be trouble there was second identical instance after all that final success date25 0903270742 date05 0903270742 last6190 0901010001 producing anomalies producing station counts gridding primary parameters producing gridded binaries for synthetics gridding tmp binary anomalies for secondary support gridding dtr binary anomalies for secondary support gridding pre binary anomalies for secondary support gridding tmp anomalies at 05 for synthetics gridding dtr anomalies at 05 for synthetics gridding pre anomalies at 05 for synthetics producing secondary vap gridding vap anomalies and synthetics producing secondary wet gridding wet anomalies and synthetics producing secondary cld making synthetic cld from dtr anomalies gridding cld anomalies and synthetics producing secondary frs converting anomalies to absolutes deriving pet creating output data and station files creating final nstation tmpdtr files creating final 0station tmpdtr files all work completed satisfactorarily see logscompletioninfolog0905070939dat and logslogs0905070939update0905070939log uealogin1esdatacruf098update_top and in terms of disk usage um remember its not that reliable uealogin1esdatacruf098update_top du ks 64 anomauto 32 batchdel 64 bom2cruauto 64 climat2cruauto 32 compile_all 629856 db 32 dtr2cldauto 64 glo2absauto 16108896 gridded_finals 13822176 interim_data 18368 logs 416 makegridsauto 64 makepetauto 64 mcdw2cruauto 32 movenormsauto 32 newdatalatestdate 288 newmergedbauto 2368 programs 1101088 reference 2848 results 3008 runs 32 saved_timings_090420_1716 64 stncountsauto 64 stncountsauto_safe 704 timings 32 tmnx2dtrauto 32 tmpdtrstnsauto 352 update 638432 updates uealogin1esdatacruf098update_top meaning that complete 19012008 run will need about 14gb of working data and the resulting files will need approximately 16gb all gzipped then of course or at last depending on your perspective tim had look at the data with that analytical brain thingy hes got oooops lots of wild values even for tmp and pre and thats compared to the previous output yes this is comparing the automated 19012008 files with the 1901june2006 files not with cru ts 21 so you guessed it bonnet up again first investigation was wet where variance was far too low usually indicative of scaling issue and thus it was despite having had drainsup on scaling wet seems to have escaped completely the initial gridding to binary outputs at x10 which is absolutely fine but the pretowet converters are not so simple the 25degree converter rd0_gts_anom_mpro has reasonable output values five monthly examples minmax rd0 25 binaries 100000 357327 minmax rd0 25 binaries 942232 250621 minmax rd0 25 binaries 930808 512557 minmax rd0 25 binaries 100000 623526 minmax rd0 25 binaries 951105 521668 the trouble is when written to binary these will be rounded to integer and degree of accuracy will be lost they should be x10 then theres the 05degree converter rd0_gts_anom_05_mpro which has indescribably awful output values minmax rd0 05 binaries 100000 833519 minmax rd0 05 binaries 0970328 813772 minmax rd0 05 binaries 0951749 433032 minmax rd0 05 binaries 100000 926219 minmax rd0 05 binaries 0960226 380590 these are basically 1000 times too small how did this happen when i specifically had complete review of scaling factors ffs aha not so silly the 05 grids are saved as glo files because after 1989 its all synthetic so theyre not rounded on the other hand they are still 100x too low for percentage anomalies and the 25 grids are sent to the gridder as synthfac100 when currently its 1 so some changes to make p the 25degree prewet path is now at x10 all the way to the final gridding the 05degree prewet path is at x10 until the production of the synthetic wet at which point it has to be x1 to line up with the pre1990 output from the gridder the gridder outputs glo files as x1 only we havent used the actfac parameter yet and were not going to start got all that fixed then onto the excessions tim found quite lot that really should have triggered the 34 sd cutoff in anomautofor wrote retracefor proglet ive been looking for an excuse to write it takes country or individual cell along with dates and run id and preforms reverse trace from final output files to database its not complete yet but it already gives extremely helpful information i was able to look at the first problem guatemala in autumn 1995 has massive spike and find that station in mexico has temperature of 78 degrees in november 1995 this gave local anomaly of 5323 which would have been lost amongst the rest of mexico as tim just did country averages and an anomaly in guatemala of 2408 which gave us the spike 7674100 1808 9425 22 coatzacoalcos ver mexico 1951 2009 101951 99900 1994 1889999 24499999999 286 281 275 274 274 2629999 1995 237999999999999 3009999 281 283 2729999 780 239 1996 219 232 235 256 285 276 280 226 285 260 247 235 now this is clear indication that the standard deviation limits are not being applied which is extremely bad news so i had drainsup on anomautofor and yup my awful programming strikes again because i copied the anomdtbf90 process i failed to notice an extra section where the limit was applied to the whole station i was only applying it to the normals period 196190 so i fixed that and reran here are the before and after outputs from tracefor trace on mexico 111995 run 0905070939 crua6crucrutsversion_3_0fixing_tmp_and_pre cat retracemexicotmp199511stat 1995 11 2141 980 239 145 7280 216 173 1995 11 2141 980 239 145 7280 216 173 1995 11 1833 870 239 145 2380 216 173 1995 11 308 113 239 145 4904 216 173 1995 11 323 057 238 148 2232 5323 217 172 2244 1995 11 2239 1280 243 148 7227000 7800 217 172 7674100 trace on mexico 111995 run 0907031504 crua6crucrutsversion_3_0fixing_tmp_and_pre cat retracemexicotmp199511stat 1995 11 1951 980 239 145 2890 216 156 1995 11 1951 980 239 145 2890 216 156 1995 11 1833 870 239 145 2850 216 156 1995 11 118 113 239 145 036 216 156 1995 11 073 057 238 148 2227 182 227 148 2231 1995 11 2239 1280 243 148 7227000 7800 217 172 7674100 the column to be looking at is this one because its traceability program it works backwards in time row 1 final gridded output row 2 gridded absolutes should row 1 row 3 climatology row 4 gridded anomalies row 5 anomalies row 6 actual station values columns are as follows cols 12 year month col 3 mean cols 46 min with cell indices cols 79 max with cell indices row 5 cols 47 min with cell indices and line in anoms file cols 811 max with cell indices and line in anoms file row 6 cols 47 min with cell indices and wmo code in database cols 811 max with cell indices and wmo code in database in this case the erroneous value of 78 degrees has been counted in the earlier run giving an anomaly of 5323 in the later run it hasnt the anomaly of 182 is from different cell 227148 instead of 217172 so rerunning improved matters the extremes have vanished but the means are still out sometimes significantly stand by were about to go down the rabbithole again i took the twelve 1990 anomaly files from the original 19012006 run that was done with some flavour of anomdtbf90 they were here crucrutsversion_3_0primariestmptmptxt1990 then i modified the update latest databases file to say that tmp0705101334dtb was the current database and made limited run of the update program for tmp only killing it once it had produced the anomaly files the run was 0908181048 so under crucrutsversion_3_0fixing_tmp_and_precustom_anom_comparisons we have manual directory and an automatic directory each with twelve 1990 anomaly files and how do they compare not at all example from january crua6crucrutsversion_3_0fixing_tmp_and_precustom_anom_comparisons head manualtmp199001txt 7090 870 100 420000 10010 7830 1550 280 910000 10080 6970 1890 100 090000 10250 6970 1890 1000 130000 10260 7450 1900 160 540000 10280 6950 2550 1290 030000 10650 7040 3110 140 040000 10980 6600 200 00 170000 11000 6730 1440 130 080000 11520 6680 1400 390 250000 11530 crua6crucrutsversion_3_0fixing_tmp_and_precustom_anom_comparisons head automatictmp199001txt 709 087 100 297558 10010 783 155 280 787895 10080 697 189 100 050690 10250 697 189 1000 049478 10260 745 190 160 388554 10280 695 255 1290 148960 10650 704 311 140 046391 10980 660 020 00 163333 11000 673 144 130 012662 11520 668 140 390 203333 11530 the numbers of values in each pair are not always identical but are within 2 or 3 so thats not too worrying worrying yes just not fatal there are number of things going on the lats and lons are the same just scaled because originally the tmp coordinates were x10 not x100 we can ignore that problem the real problem is the completely different results from the automated system i dont understand this because i painstakingly chcked the anomautofor file to ensure it was doing the right job the overall pattern of anomalies is roughly the same its just that the actual values differ not always lower sometime higher could be rounding error got anomauto to dump the first month of the first station 10010 the clue to the problem is in the first lines were only getting the fulllength mean used for sd calculations and not the 6190 mean nv should be 30 wmo 10010 im 01 nvgt5 sums 38490 nv 86 ave 448 onestn049001 150 d 1049001 298 aaaaand found it what happened was this in the original anomdtbf90 program theres test for existing normals in the header of each station if they are present then sd is calculated to allow excessions to be screened out if not sd is calculated and then used to screen excessions then 6190 normal is built provided there are enough values after the screening however in my version i followed the same process but crucially i wasnt using the same variable to store the existing normals and the calculated ones so we were ending up with the full length normal n86 in the above example instead all i had to add was single line ave xstnrmsimfac new actually use existing normals we then get onestn049001 150 d 1049001 420 which is what we want so complete rerun just tmp for 1990 still using the old db tadaa uealogin1crucrutsversion_3_0fixing_tmp_and_precustom_anom_comparisonsnew_automatic head tmp199001txt 709 087 100 420000 10010 783 155 280 910000 10080 697 189 100 090000 10250 697 189 1000 130000 10260 745 190 160 540000 10280 695 255 1290 030000 10650 704 311 140 040000 10980 660 020 00 170000 11000 673 144 130 080000 11520 668 140 390 250000 11530 spot on 100 match with the previouslygenerated anomalies phew of course now we have to do proper run with the latest db that very nearly worked mostly the same but one noticeable exception is the hot 2003 jja in europe its much less extreme in the automated version so i ran with the original database again thought id see if there were different station counts for the original anomdtb and original june 2006 db tmp0705101334dtb 1259 tmp200306txt 1216 tmp200307txt 1223 tmp200308txt for 0909041051 fixed anomauto and original june 2006 db tmp0705101334dtb 1210 tmp200306txt 49 1201 tmp200307txt 15 1178 tmp200308txt 45 for 0909021348 the fixed anomauto and the latest db tmp0904151410dtb 1246 tmp200306txt 13 1250 tmp200307txt 34 1228 tmp200308txt 5 ran retrace because i might as well use it for 0909041051 original db 2003 6 1613 690 273 375 2060 266 380 2003 6 1613 690 273 375 2060 266 380 2003 6 1613 690 273 375 2060 266 380 2003 6 000 000 273 375 000 266 380 2003 6 99900 99900 999 999 999 99900 999 999 999 2003 6 99900 99900 999 999 999 99900 999 999 999 crua6crucrutsversion_3_0fixing_tmp_and_pre cat retracefrance0909041051tmp200307stat 2003 7 1858 940 273 375 2380 265 380 2003 7 1858 940 273 375 2380 265 380 2003 7 1858 940 273 375 2380 265 380 2003 7 000 000 273 375 000 265 380 2003 7 99900 99900 999 999 999 99900 999 999 999 2003 7 99900 99900 999 999 999 99900 999 999 999 crua6crucrutsversion_3_0fixing_tmp_and_pre cat retracefrance0909041051tmp200308stat 2003 8 1825 890 273 375 2380 265 380 2003 8 1825 890 273 375 2380 265 380 2003 8 1825 890 273 375 2380 265 380 2003 8 000 000 273 375 000 265 380 2003 8 99900 99900 999 999 999 99900 999 999 999 2003 8 99900 99900 999 999 999 99900 999 999 999 for 0909021348 latest db 2003 6 1912 850 273 375 2360 267 367 2003 6 1912 850 273 375 2360 267 367 2003 6 1613 690 273 375 2010 267 367 2003 6 299 163 273 375 345 267 367 2003 6 340 190 277 352 66 510 270 360 68 2003 6 2094 1060 272 375 6717000 2610 267 371 7650000 2003 7 2061 1220 273 375 2670 266 380 2003 7 2061 1220 273 375 2670 266 380 2003 7 1858 940 273 375 2380 266 380 2003 7 203 280 273 375 287 266 380 2003 7 218 110 275 358 69 320 273 373 65 2003 7 2070 920 272 375 6717000 2640 266 379 7790000 2003 8 2104 1190 273 375 2660 266 380 2003 8 2104 1190 273 375 2660 266 380 2003 8 1825 890 273 375 2380 266 380 2003 8 279 297 273 375 283 266 380 2003 8 290 280 277 352 62 300 281 369 61 2003 8 2315 1180 272 375 6717000 2820 266 379 7790000 well the differences certainly show up and it looks like database change so i guess i need to look at changes in french stations argh and that argh was prescient since when i ran getcountry to extract the french stations from each database i found crua6crucrutsversion_3_0fixing_tmp_and_pre getcountry enter the database to search update_topdbtmptmp0705101334dtb enter the country name to extract france 33 stations written to update_topdbtmptmp0705101334dtbfrance crua6crucrutsversion_3_0fixing_tmp_and_pre getcountry enter the database to search update_topdbtmptmp0904151410dtb enter the country name to extract france 104 stations written to update_topdbtmptmp0904151410dtbfrance somehow ive added 71 new french stations surely id remember that especially as theyd have had to have arrived with the mcdwclimat bulletins sizes crua6crucrutsversion_3_0fixing_tmp_and_pre wc l france 2725 tmp0705101334dtbfrance 3700 tmp0904151410dtbfrance thats not so bad well the ratios improved could be lot of unmatched incoming stations oh its the bloody wmo codes again these bloody nonstandard ambiguous illogical systems amateur hour again first example the beautiful city of lille here are the appropriate headers tmp0705101334dtbfrance 70150 506 31 47 lille france 1851 2006 101851 99900 tmp0904151410dtbfrance 701500 5034 306 52 lille france 2000 2009 999 0 7015000 5034 306 52 lille france 1851 2008 101851 99900 so just what i was secretly hoping for not drainsup on the climat and mcdw programs otherwise known as climat2cruautofor and mcdw2cruautofor as well as the merging program mergedbautofor some random manual traceability that may be useful or not considering the mcdw update run numbered 0904151410 cat crucrutsversion_3_0update_toprunsruns0904151410mergmcdw0904151410dat dbcldcld0904021239dtb updatesmcdwdbdb0904151410mcdwcld0904151410dtb updatesmcdwdbdb0904151410int1cld0904151410dtb blind u is for cld but indicates that the input database was tmp0904021239dtb the mcdw database was mcdwtmp0904151410dtb the output database was of course tmp0904151410dtb i wonder what they all have for lille tmp0904021239dtb 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 7015000 5034 306 52 lille france 1851 2008 101851 99900 mcdwtmp0904151410dtb 0701500 5034 306 52 lille france 2009 2009 999 0 tmpdtb 701500 5034 306 52 lille france 2000 2009 999 0 7015000 5034 306 52 lille france 1851 2008 101851 99900 ill bet this just updated the false lille with another month or something in fact convmcdw0904151410dat 1 2009 1 2009 before tmp0904021239dtb 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 6190999999999999999999999999999999999999999999999999 2000 42 63 76 99 147 166 159 182 164 116 78 57 2001 37999999999999 144 158 187 193 135 145 69 30 2002 45 77 80 103 133 167 175 186 148 109 87 51 2003 30 29 87 106 137 186 195 208 158 85 81 45 2004 39 53 65 106 127 166 176 192 165 120 71 34 2005 54 30 71 105 129 179 182 170 165 144 65 37 2006 20 28 49 93 137 170 226 166 185 142 90 57 2007 74 67 79 136 142 168 173 173 145 107 69 40 2008 65 59 67 93 166 159 182 176 140 102 72 30 2009 7 379999999999999999999999999999999999999999 after tmp0904151410dtb 701500 5034 306 52 lille france 2000 2009 999 0 6190999999999999999999999999999999999999999999999999 2000 42 63 76 99 147 166 159 182 164 116 78 57 2001 37999999999999 144 158 187 193 135 145 69 30 2002 45 77 80 103 133 167 175 186 148 109 87 51 2003 30 29 87 106 137 186 195 208 158 85 81 45 2004 39 53 65 106 127 166 176 192 165 120 71 34 2005 54 30 71 105 129 179 182 170 165 144 65 37 2006 20 28 49 93 137 170 226 166 185 142 90 57 2007 74 67 79 136 142 168 173 173 145 107 69 40 2008 65 59 67 93 166 159 182 176 140 102 72 30 2009 7 379999999999999999999999999999999999999999 the data is identical but ooh lookit the wmo codes oh lordy the update has changed the code from 7digit to 6digit lets look at all available headers for this lille station ie the short modern one tmp0904021106dtb0701500 5057 310 52 lillelesquin france 2000 2009 999 0 tmp0904021239dtb0701500 5057 310 52 lillelesquin france 2000 2009 999 0 tmp0904151410dtb 701500 5034 306 52 lille france 2000 2009 999 0 aha its not the same station 0 an input has updated the details istr that can happen lets look at the mcdw update for jan 2009 ssm0901fin 07015 lille 5034n 00306e 52 10078 10137 7 58 7 63 75 145 and previous update ssm0812fin 07015 lille 5034n 00306e 52 10127 10186 30 69 7 32 1 65 140 well thats help why did it change climat but climat doesnt have station names lets try and work out how the updates happened mcdw is first drwx 2 f098 cru 4096 mar 5 2009 db0903051342 drwx 2 f098 cru 4096 mar 5 2009 db0903051442 drwx 2 f098 cru 4096 mar 5 2009 db0903051448 drwx 2 f098 cru 4096 mar 9 2009 db0903091631 drwx 2 f098 cru 4096 apr 2 1125 db0904021106 drwx 2 f098 cru 4096 apr 2 1257 db0904021239 drwx 2 f098 cru 4096 apr 15 1416 db0904151410 then climat drwx 2 f098 cru 4096 mar 5 2009 db0903051342 drwx 2 f098 cru 4096 mar 5 2009 db0903051448 drwx 2 f098 cru 4096 mar 9 2009 db0903091631 drwx 2 f098 cru 4096 apr 2 1126 db0904021106 drwx 2 f098 cru 4096 apr 2 1259 db0904021239 we wont bother with bom i dont think they stretch to lille im hoping i didnt do any on the escluster checks nope just copied so this looks like the sequence 0903051342 mcdw climat 0903051442 mcdw only 0903051448 mcdw climat 0903091631 mcdw climat 0904021106 mcdw climat 0904021239 mcdw climat 0904151410 mcdw only interestingly we only seem to have the last three tmp databases at least in terms of having the short lille station this is so hard because i cannot remember the process have to dig some more ok i think the key update is 0903091631 heres the climat runfile convclimat0903091631dat 1 2000 12 2008 mcdw was even furtherranging convmcdw0903091631dat 9 1994 11 2008 still not there one issue is that for some reason i didnt give the merg runfiles individual names for each parameter so i might mod the update program to do that then rerun all updates the problem with rerunning all updates of course is that i also fixed wmo codes and though my memory is extremely flaky probably corrected some extreme values detected by tim oh bugger well wmo code fixing is identifiable because you get log file ie heres the tmp dir r 1 f098 cru 25936385 aug 18 1048 tmp0705101334dtb rrr 1 f098 cru 7278548 feb 17 2009 tmp0705101334dtbgz rwrr 1 f098 cru 25936385 mar 8 2009 tmp0903081416dtb rwrr 1 f098 cru 408 mar 8 2009 tmp0903081416log rwrr 1 f098 cru 27131064 apr 2 1115 tmp0904021106dtb rwrr 1 f098 cru 27131064 apr 2 1248 tmp0904021239dtb rwrr 1 f098 cru 27151999 apr 15 1411 tmp0904151410dtb tmp0705101334dtb had its wmo codes fixed and became tmp0903081416dtb which has the accompanying log file tmp0903081416log to prove it program fixwmos was run 0903081416 reference wmo list crucrutsversion_3_0wmofrom_dave_lister_wmo_list country codes unused crucrutsversion_3_0wmowmo_country_codesdat input database tmp0705101334dtb total stations 5065 wmos matched 2263 false wmos 0 0 bad wmos 0 1000 0 output database tmp0903081416dtb unfortunately only tmp and pre have such log files heres the one for pre program fixwmos was run 0903051740 reference wmo list crucrutsversion_3_0wmofrom_dave_lister_wmo_list country codes unused crucrutsversion_3_0wmowmo_country_codesdat input database pre0803271802dtb total stations 15937 wmos matched 4196 false wmos 0 88 bad wmos 0 1000 1540 bad wmo heads written to pre0803271802bad output database pre0903051740dtb so i guess i will use tmp0903081416dtb pre0903051740dtb and the earliest available from the other parameters in other words cld0902101409dtb dtr0708081052dtb pre0903051740dtb tmn0708071548dtb tmx0708071548dtb tmp0903081416dtb vap0804231150dtb wet0710161148dtb well its worth try actually lets compare those eight databases assuming we can find at least some common stations oh boy cld0902101409dtb 7015000 5056 310 52 lillelesquin france 1971 1996 999 999 cld0902101409dtb 0701500 5057 310 52 lillelesquin france 2000 2008 999 0 dtr0708081052dtb 701500 5057 310 52 lille france 1973 2006 999 0 pre0903051740dtb 0701500 5060 310 47 lille france 1784 2006 999 99900 tmn0708071548dtb 701500 5057 310 52 lille france 1973 2006 999 0 tmp0903081416dtb 0701500 5060 310 47 lille france 1851 2006 101851 99900 tmx0708071548dtb 701500 5057 310 52 lille france 1973 2006 999 0 vap0804231150dtb 0701500 5057 310 52 lillelesquin france 2003 2007 999 0 vap0804231150dtb 1378000 6108 1048 271 lillehammer saether norway 1972 1994 999 999 vap0804231150dtb 7015000 5056 310 52 lillelesquin france 1971 2003 999 999 wet0710161148dtb 0701500 5057 310 52 lillelesquin france 1996 2007 999 999 this whole project is such mess wonder i needed therapy so cld already has the problem and its the earliest version in the archive also vap well looking back er up we know what happened to cld it was updated with newmergedb before it went auto so we now have cld0902101409dtb database consisting of cld0312181428dtb updated first with derivedcloud data from mcdw 19942008 then with derivedcloud data from climat 20002008 and finding cld0312181428dtb does it have the lille problem 70150 5056 310 52 lillelesquin france 1971 1996 999 999 so cld0312181428dtb is our new starting point i think vap oh dear again from above discovered that wmo codes are still pain in the arse and that id forgotten to match australian updates by bom code last field in header instead of wmo code so i had to modify newmergedbauto also found that running fixwmosfor was less than successful on vap because its already screwed uealogin1crucrutsversion_3_0update_topdbvap grep i jan mayen vap0804231150dtb 0100100 7093 867 9 jan mayennornavy norway 2003 2007 999 0 1001000 7093 866 9 jan mayennor navy norway 1971 2003 999 999 ulp i am seriously close to giving up again the history of this is so complex that i cant get far enough into it before by head hurts and i have to stop each parameter has tortuous history of manual and semiautomated interventions that i simply cannot just go back to early versions and run the update prog i could be throwing away all kinds of corrections to latlons to wmos yes and more so what the hell can i do about all these duplicate stations well how about fixdupesfor that would be perfect except that i never finished it i was diverted off to fight some other fire aarrgghhh i need database cleaner what about the ones i used for the crutem3 work with phil brohan cant find the bugger looked everywhere matlab scripts aplenty but not the one that produced the plots i used in my cru presentation in 2005 oh fuck it sorry i will have to write program to find potential duplicates it can show pairs of headers and correlations between the data and i can say yay or nay there is the finddupesfor program though i think the comment for this program sums it up nicely program postprocdupes2 c further postprocessing of the duplicates file just to show how crap the c program that produced it was well not so much that but that once it was c running it took 2 days to finish so i couldnt really reset it to improve c things anyway this version does the following useful stuff c 1 removes and squirrels away all segments where dates dont match c 2 marks segments 5 where dates dont match c 3 groups segments from the same pair of stations c 4 sorts based on total segment length for each station pair you see how messy it gets when you actually examine the problem this time around dedupedbfor i took as simple an approach as possible and almost immediately hit problem thats generic but which doesnt seem to get much attention whats the minimum n for reliable standard deviation i wrote quick matlab proglet stdevtest2m which takes 12column matrix of values and for each month calculates standard deviations using sliding windows of increasing size finishing with the whole vector and whats taken to be the standard deviation the results are depressing for paris with 237 years 20 of the real value was possible with even 40 values windter months were more variable than summer ones of course what we really need and i dont think itll happen of course is set of metrics by latitude band perhaps so that we have broad measure of the acceptable minimum value count for given month and location even better confidence figure that allowed the actual standard deviation comparison to be made with looseness proportional to the sample size all thats beyond statistically and in terms of time im going to have to say 30 its pretty good apart from djf for the one station ive looked at back to the actual database issues i need day or two to think about the duplicate finder lets just look at the year 2003 for all the french stations in each database duh original db extraction tmp0705101334dtbfrance 2003 30 29 87 106 137 186 195 208 158 85 81 45 2003 59 64 96 108 123 159 174 188 155 110 103 75 2003999999999999999999999999999999999999999999999999 x 2003999999999999999999999999999999999999999999999999 x 2003 10 2 83 110 162 226 210 239 159 81 67 26 2003 42 54 108 122 144 199 200 232 173 109 101 65 2003 24 34 102 120 149 221 213 252 168 99 82 45 2003 12 15 86 109 154 232 220 251 161 88 67 31 2003 20 33 102 114 137 212 200 240 162 101 90 49 2003999999999999999999999999999999999999999999999999 x 2003 51 58 123 142 160 227 219 252 190 129 109 77 2003 45 56 114 133 165 242 243 267 197 133 109 72 2003999999999999999999999999999999999999999999999999 x 2003 54 63 111 141 194 261 263 279 201 153 121 85 2003 85 79 115 137 191 248 253 274 209 156 129 96 2003 73 73 118 140 181 247 262 275 205 155 125 94 2003 86 73 105 131 184 241 251 265 207 166 136 93 new db extraction tmp0904151410dtbfrance 2003 30 29 87 106 137 186 195 208 158 85 81 45 2003 59 64 96 108 123 159 174 188 155 110 103 75 2003 10 2 83 110 162 226 210 239 159 81 67 26 2003 42 54 108 122 144 199 200 232 173 109 101 65 2003 24 34 102 120 149 221 213 252 168 99 82 45 2003 12 15 86 109 154 232 220 251 161 88 67 31 2003 20 33 102 114 137 212 200 240 162 101 90 49 2003 51 58 123 142 160 227 219 252 190 129 109 77 2003 45 56 114 133 165 242 243 267 197 133 109 72 2003 85 79 115 137 191 248 253 274 209 156 129 96 2003 73 73 118 140 181 247 262 275 205 155 125 94 2003 86 73 105 131 184 241 251 265 207 166 136 93 2003 30 29 87 106 137 186 195 208 158 85 81 45 do 2003 27 32 88 101 129 181 186 209 153 87 79 45 da 2003 59 64 96 108 123 159 174 188 155 110 103 75 do 2003 10 2 83 110 162 226 210 239 159 81 67 26 do 2003 42 54 108 122 144 199 200 232 173 109 101 65 do 2003 24 34 102 120 149 221 213 252 168 99 82 45 do 2003 12 15 86 109 154 232 220 251 161 88 67 31 do 2003 20 33 102 114 137 212 200 240 162 101 90 49 do 2003 18 32 93 116 157 232 217 242 160 104 83 43 db 2003 51 58 123 142 160 227 219 252 190 129 109 77 do 2003 45 56 114 133 165 242 243 267 197 133 109 72 do 2003 57 60 110 133 184 245 256 267 196 147 113 81 dc 2003 54 63 111 141 194 261 263 279 201 153 121 85 2003 85 79 115 137 191 248 253 274 209 156 129 96 do 2003 73 73 118 140 181 247 262 275 205 155 125 94 do 2003 86 73 105 131 184 241 251 265 207 166 136 93 do 2003999999999999999999999999999999999999999999999999 2003 27 32 88 101 129 181 186 209 153 87 79 45 da 2003 18 32 93 116 157 232 217 242 160 104 83 43 db 2003 57 60 110 133 184 245 256 267 196 147 113 81 dc 2003 35 35 85 101 128 170 183 200 152 86 83 46 2003 73 69 88 102 122 156 174 185 169 129 116 84 2003 43 49 90 105 130 178 186 204 154 99 91 55 2003 17 18 83 100 143 195 199 218 148 83 77 41 2003 69 70 95 107 124 160 177 184 164 123 109 82 2003 45 53 106 120 142 195 198 225 174 112 101 64 2003 30 39 93 107 134 191 191 221 155 91 83 47 2003 67 75 105 116 136 179 189 210 173 125 120 90 2003 28 39 102 115 144 209 205 243 167 97 85 51 2003 10 3 78 102 156 230 210 235 150 74 62 22 2003 61 67 113 128 151 197 207 229 188 136 120 89 2003 30 43 101 122 144 214 206 243 168 104 89 54 2003 7 7 52 77 125 202 188 206 127 73 54 13 2003 20 28 100 128 171 254 233 261 179 107 86 42 2003 33 40 112 129 154 233 220 255 176 111 98 60 2003 29 40 25 32 79 158 151 189 96 39 42 4 2003 39 48 107 131 183 254 251 268 182 126 100 61 2003 4 6 79 99 148 215 223 229 158 90 68 31 2003 48 52 113 135 159 229 224 255 184 128 99 65 2003 43 42 105 120 146 214 209 241 178 116 92 60 2003 41 44 101 117 145 216 212 237 173 116 93 55 2003 81 71 111 133 183 244 246 272 200 149 128 101 2003 93 69 111 137 191 254 264 282 212 168 137 103 2003 17 24 88 105 146 208 207 234 158 91 81 42 2003 1 3 84 99 143 208 202 233 153 77 70 29 in the original db ive xd those lines missing in the new one just missing vals in the new db ive asterisked all the lines matching the old one with duplicate matches labeled do any other duplicates are marked da db dc we can see that all the original 2003 lines are included and replicated three new lines are also replicated further 25 lines are apparently new though could well have parents in the original db this implies that very little matching is being performed had look at the act action files interesting crua6crucrutsversion_3_0update_top gunzip c updatesmcdwmergefilesmergmcdwtmp0904021106actgz grep lille master 701500 5034 306 52 lille france 1851 2008 101851 99900 update 0701500 5034 306 52 lille france 2001 2008 999 0 newh 701500 5034 306 52 lille france 1851 2008 101851 99900 crua6crucrutsversion_3_0update_top gunzip c updatesmcdwmergefilesmergmcdwtmp0904021239actgz grep lille master 701500 5034 306 52 lille france 1851 2008 101851 99900 update 0701500 5034 306 52 lille france 2001 2008 999 0 newh 701500 5034 306 52 lille france 1851 2008 101851 99900 crua6crucrutsversion_3_0update_top gunzip c updatesmcdwmergefilesmergmcdwtmp0904151410actgz grep lille master 701500 5034 306 52 lille france 2000 2009 999 0 update 0701500 5034 306 52 lille france 2009 2009 999 0 newh 701500 5034 306 52 lille france 2000 2009 999 0 so it worked fine until the 0904151410 run when it went crazee so what happened why did it behave differently idea it was the same for pre though crua6crucrutsversion_3_0update_top gunzip c updatesmcdwmergefilesmergmcdwpre0904021239actgz grep lille master 701500 5034 306 52 lille france 1784 2008 999 99900 update 0701500 5034 306 52 lille france 2001 2008 999 0 newh 701500 5034 306 52 lille france 1784 2008 999 99900 crua6crucrutsversion_3_0update_top gunzip c updatesmcdwmergefilesmergmcdwpre0904151410actgz grep lille master 701500 5034 306 52 lille france 2000 2009 999 0 update 0701500 5034 306 52 lille france 2009 2009 999 0 newh 701500 5034 306 52 lille france 2000 2009 999 0 there was something very fishy about that run of course it was single month i wonder if that made difference crua6crucrutsversion_3_0update_top cat runsruns0904021239convmcdw0904021239dat 9 1994 12 2008 crua6crucrutsversion_3_0update_top cat runsruns0904151410convmcdw0904151410dat 1 2009 1 2009 also of interest how did the program find 20002009 station when the previous update was to 2008 aha crua6crucrutsversion_3_0update_top cat runsruns0904021239convclimat0904021239dat 1 2000 2 2009 the climat update did it its that bloody nometadata problem so i should be looking at the climat process for 0904021239 not the mcdw one duhh so the merge run crua6crucrutsversion_3_0update_top cat runsruns0904021239mergclimat0904021239dat dbtmxtmx0708071548dtb updatesclimatdbdb0904021239climattmx0904021239dtb updatesclimatdbdb0904021239int2tmx0904021239dtb blind m crua6crucrutsversion_3_0update_top looking at the climat dtb conversion the converted climat bulletins crua6crucrutsversion_3_0update_top gunzip c updatesclimatdbdb0904021239climattmp0904021239dtbgz grep i lille 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 the merged bulletins in tmp0904021239dtb er presumably crua6crucrutsversion_3_0update_top gunzip c updatesclimatdbdb0904021239int2tmp0904021239dtbgz grep i lille 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 7015000 5034 306 52 lille france 1851 2008 101851 99900 crua6crucrutsversion_3_0update_top grep i lille dbtmptmp0dtb dbtmptmp0705101334dtb 70150 506 31 47 lille france 1851 2006 101851 99900 dbtmptmp0903081416dtb0701500 5060 310 47 lille france 1851 2006 101851 99900 dbtmptmp0904021106dtb0701500 5057 310 52 lillelesquin france 2000 2009 999 0 dbtmptmp0904021106dtb7015000 5034 306 52 lille france 1851 2008 101851 99900 dbtmptmp0904021239dtb0701500 5057 310 52 lillelesquin france 2000 2009 999 0 dbtmptmp0904021239dtb7015000 5034 306 52 lille france 1851 2008 101851 99900 dbtmptmp0904151410dtb 701500 5034 306 52 lille france 2000 2009 999 0 dbtmptmp0904151410dtb7015000 5034 306 52 lille france 1851 2008 101851 99900 ok lets be absolutely clear about the process step 1 convert mcdw bulletins 0994 1208 to produce mcdwtmp0904021106dtb 0701500 5034 306 52 lille france 2001 2008 999 0 step 2 merge mcdwtmp0904021106dtb into tmp0903081416dtb to produce int1tmp0904021106dtb 701500 5034 306 52 lille france 1851 2008 101851 99900 step 3 convert climat bulletins 0100 0209 to climattmp0904021106dtb 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 step 4 merge climattmp0904021239dtb into int1tmp0904021106dtb to produce int2tmp0904021106dtb 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 7015000 5034 306 52 lille france 1851 2008 101851 99900 theres then the bom section but its all over by now so the merging of climattmp0904021106dtb into int1tmp0904021106dtb failed why well the wmo codes are the same as for mcdw 0701500 so it cant be that the lat and lon are slightly different though remember the database entry was originally tmp0903081416dtb 0701500 5060 310 47 lille france 1851 2006 101851 99900 after the mcdw 0994 1208 merge it became int1tmp0904021106dtb 701500 5034 306 52 lille france 1851 2008 101851 99900 after the climat 0100 0209 merge int2tmp0904021106dtb 0701500 5057 310 52 lillelesquin france 2000 2009 999 0 7015000 5034 306 52 lille france 1851 2008 101851 99900 now the lillelesquin station header comes from the climat bulletins ie from the wmo reference file wmo0710151633dat but it should have matched with the existing lille the problem looks like the latitude shift from 5060 to 5034 introduced by mcdw did the damage obviously if we are going to trust mcdw metadata as being valid corrections then the wmo reference file needs to be updated at the same time so well need 1 file called wmoreflatestdat that contains the name of the latest wmo reference file done 2 hook in newmergedbauto that flags when header is being changed by an mcdwbom bulletin extremely complicated 3 routine to write new wmo reference and to archive the old one extremely complicated 4 record of every iteration of the dblatestversionsdat file in dbpreviouslatest done as part of the investigations i found that i wasnt closeing off channel 10 when i used it in updatefor now im pretty sure that f77 follows the convention that an open on an open channel initiates an initial close automatically but who wants to take that chance with the variety of compilers were subject to so i went through and inserted an indecent number of close10s point 2 flagging changes to the metadata well the merged database is written principally from dbm with dbu chipping in new stations i guess that new stations should be added to the wmo reference file they are panparameter well the mcdw ones are but i have an eerie feeling that i wont experience joy when headers are compared between parameters wrote metacmpfor it accepts list of parameter databases by default latestversionsdat and compares headers when wmo codes match if all wmo matches amongst the databases share common metadata lat lon alt name country then the successful header is written to file if however any one of the wmo matches fails on any metadata even slightly the gaggle of disjointed headers is written to second file i know that leeway should be given particularly with lats lons but as first stab i just need to know how bad things are well i got that crua6crucrutsversion_3_0update_top metacmp metacmp compare parameter database metadata results matchedunopposed 2435 clashed horribly 4077 ouch though actually far far better than expected as for the disport of those 2435 crua6crucrutsversion_3_0update_top grep 1 report0909181759metacmpwmo wc l 1250 crua6crucrutsversion_3_0update_top grep 2 report0909181759metacmpwmo wc l 279 crua6crucrutsversion_3_0update_top grep 3 report0909181759metacmpwmo wc l 41 crua6crucrutsversion_3_0update_top grep 4 report0909181759metacmpwmo wc l 92 crua6crucrutsversion_3_0update_top grep 5 report0909181759metacmpwmo wc l 83 crua6crucrutsversion_3_0update_top grep 6 report0909181759metacmpwmo wc l 9 crua6crucrutsversion_3_0update_top grep 7 report0909181759metacmpwmo wc l 129 crua6crucrutsversion_3_0update_top grep 8 report0909181759metacmpwmo wc l 552 interesting but not astounding roughly half are unpaired stations with an impressive 23 showing perfect match across all eight databases analysis of the 4000 bad matches will be more complicated unfortunately an initial rerun looking for latlon within half degree andor station partial will be useful hang on easier to analyse the output from metacmp and so postmetacmpfor stats report for report0909181759metacmpbad overall distribution of group sizes 2 in group 642 3 in group 71 4 in group 188 5 in group 625 6 in group 183 7 in group 411 8 in group 1957 lat number of diffs within group 1 0 2 3059 3 276 4 15 5 0 6 0 7 0 8 0 maximum differences 01 1233 02 726 05 1225 10 15 10 151 lon number of diffs within group 1 0 2 2996 3 339 4 30 5 1 6 0 7 0 8 0 maximum differences 01 1195 02 722 05 1242 10 30 10 177 alt number of diffs within group 1 0 2 2035 3 237 4 17 5 0 6 0 7 0 8 0 maximum differences 50m 1767 100m 75 500m 121 1km 36 1km 290 station name number of diffs within group 1 0 2 2167 3 365 4 43 5 0 6 0 7 0 8 0 worst percentage matches 25 281 50 385 75 770 100 276 100 863 country name total groups with country mismatches 1698 number of diffs within group 1 0 2 1475 3 182 4 41 5 0 6 0 7 0 8 0 hmmm lots of groups that could be eliminated if we incorporated the wmo reference list because then we could allow an element of drift from reference point decided to make it bit quicker and easier as well by removing tmntmx and letting dtr take the strain they should all be identical anyway