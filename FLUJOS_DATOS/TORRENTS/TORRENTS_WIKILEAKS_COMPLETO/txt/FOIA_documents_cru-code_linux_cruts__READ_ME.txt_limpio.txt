procedure for updating the databases underlying the cru highresolution grids tim mitchell 250603 revised 30304 1 transform additional station data into cru timeseries cts format the cts subroutines are in crutsfilesf90 the cts files should be stored under datastnmon the f90 programs described are under codelinuxcruts or codealphacruts the programs should be easily portable from the alphas to linux or vice versa if the additional data is in the style of ghcnv2 or climat the phil jones format ie one file per time interval use or modify makecrutsf90 b mcdw or climat original or climat aopcoffenbach format ie one file per year and month use or modify reformatf90 the mcdw data must have already gone through two stage process see the readme file in datastnmonmcdw_raw c jians chinese data from excel ie single ascii table per variable with one line per stationyear use or modify fromexcelf90 d the cru timeseries file format but not quite right it may be easily convertible using option 1 in opcrutsf90 2 the size of the arrays required in the entire procedure can be substantially reduced by subdividing the additional station data by continent at this stage simply subdivide the initial raw data into set of raw files by continent reduced arry sizes mean programs that run more quickly and reliably 3 clean up the metadata in the cts headers this is done using the information in the master metadata file which is the most recently dated file in crutyn1f709762crutsmaster run cleanmetaf90 on the transformed cru ts file the sole purpose of this program is to make the header line as accurate as possible without adding new information thus the following steps are included the original station code is stored as 7digit code in both the main and old code columns b the station and country labels are made allcaps and any hyphens etc are removed c impossible latlonelv values are setting to missing d the country label is checked and made consistent using the master country list the latlon are checked to ensure that they are reasonable using the country information each country is given centroid and and 3sigma distance stns lying outide this radius are flagged f if corresponding source code file src is available it too is checked else one is created using information about the source supplied by the user 4 check the homogeneity of the additional cts file this is done using reference timeseries this is far too complex to describe here run homogiterf90 on the cleaned cts file the program runs iteratively to maximise the proportion of the original data that can be checked and placed in homog cts and src file with best estimates is stored in crutshomog and stns that could not be checked are stored in crutsretry this program may fire up 2 subsidiary xterms on startup if given the option decline these can be killed forcibly if necessary once the program has finished executing but not before one xterm is simply view of the log file which provides rough progress meter the other is the idl window running an idl program that awaits for prompts through pipe stored in cruscratch2f709762 to tell it when and where there is data file for it to read and plot in f 5 merge the additional cts file with the existing database dtb and dts the most recent version of each database is in datacrutsdatabase the latest version of the master station code file is in datacrutsmaster and the latest accessions file is in datacrutsaccession use updatedtbf90 to merge the new file in crutshomog with the existing database do this immediately before going through the whole process for new region to ensure that as much info as possible is avilable for creating reference series for the new region 6 optional at this stage add normals to the database file the best time to do this is when all the new information has been absorbed into the database steps 15 and the database is about to be used for gridding the program addnormf90 is used to add the 196190 normal in header line in the dtb files this is then used by the program that calculates anomalies where possible normal is calculated from the station series itself where this is not possible through insufficient data an attempt is made to estimate what the normal would have been if it had been measured this estimate is made using the reference series construction software used in step 4 neighbouring stations are used to construct reference timeseries that includes 196190 wherever possible and this reference timeseries is used to calculate 196190 normal for that stn and stores it in the normal line in the database file 7 additional capability required for gridding transform the database file with normals added under step 6 if possible from absolute values to anomaly values prior to gridding using anomdtbf90 the key output option from this program is 3 which dumps the anomalies to set of txt files that can be read by the idl gridding software the other output options provide info 1 produces the same data in the cts format 2 only summarises the outputs through data counts 4 summarises the original data discarded as duplicates the usual options to select are normal period 1961 1990 missing percent permitted 25 stdevs to reject 3 duplicate stns 8km 8 additional capability use as required the program opcrutsf90 is the home for all the little useful routines for manipulating the cts and dtb and src and dts files option 1 can be used to convert from one of these formats to another the other options can be exploresd to find out what they do