from peter thorne peterthornemetofficegovuk to tom wigley wigleyucaredu subject re our d3 test date thu 29 may 2008 092720 0100 cc ben santer santer1llnlgov leopold haimberger leopoldhaimbergerunivieacat karl taylor taylor13llnlgov tom wigley wigleycgducaredu john lanzante johnlanzantenoaagov susan solomon ssolomonalnoaagov melissa free melissafreenoaagov peter gleckler gleckler1llnlgov phil jones pjonesueaacuk thomas r karl thomasrkarlnoaagov steve klein klein21mailllnlgov carl mears mearsremsscom doug nychka nychkaucaredu gavin schmidt gschmidtgissnasagov steve sherwood stevensherwoodyaleedu frank wentz frankwentzremsscom one more addendum we still need to be aware that this ignores two sources of uncertainty that will exist in the real world that are not included in section 6 which is effectively 1 perfect obs and finite number of runs of perfect model 1 imperfect models 2 observational uncertainty related to dataset construction choices parametric and structural of course with the test construct given 1 becomes moot as this is the thing we are testing for with h2 this is definitely not the case for 2 which will be important and is poorly constrained for amplification factors we are either blessed or cursed by the wealth of independent estimates of the observational record one approach that i would advocate here because im lazy because its more intuitive delete as appropriate is that we can take the obs error term outside the explicit uncertainty calculation by making comparisons to each dataset in turn however the alternative approach would be to take the range of dataset estimates make the necessary poormans assumption that this is the 1 sigma or 2 sigma range depending upon how far you think they span the range of possible answers and then incorporate this as an extra term in the denominator to d3 as with the other two it would be orthogonal error so still sqrt of sum of squares such an approach would have advantages in terms of universal applicability to other problems where we may have less independent observational estimates but drawback in terms of what we should then be using as our observational yardstick in testing h2 the mean of all estimates the median something else anyway just methodological quirk that logically follows if we are worried about ensuring universal applicability of approach which with the increasingly frequent use of cmip3 archive for these types of applications is something we maybe should be considering i dont expect us to spend very much time if any on this issue as i agree that key is submitting asap peter on wed 20080528 at 2158 0600 tom wigley wrote dear all just to add bit to bens notes the conceptual problem is how to account for two different types of uncertainty in comparing single observed trend with temporal uncertainty with the average of bunch of model trends where the uncertainty is from intermodel differences the old d3 tried to do this but failed the synthetic data test the new d3 does this different way in the way that the intermodel uncertainty term is quantified this passes the synthetic data test very well the new d3 test differs from dcsp07 only in that it includes in the denominator of the test statistic an observed noise term this is by far the bigger of the two denominator terms ignoring it is very wrong and this is why the dcsp07 method fails the synthetic data test tom ben santer wrote dear folks just wanted to let you know that i did not submit our paper to ijoc after some discussions that ive had with tom wigley and peter thorne i applied our d1 d2 and d3 tests to synthetic data in much the same way that we applied the dcps07 d test and our original paired trends test d to synthetic data the results are shown in the appended figure relative to the dcps07 d test our d1 d2 and d3 tests of hypothesis h2 yield rejection rates that are substantially closer to theoretical expectations compare the appended figure with figure 5 in our manuscript as expected all three tests show dependence on n the number of synthetic time series with rejection rates decreasing to nearasymptotic values as n increases this is because the estimate of the modelaverage signal which appears in the numerator of d1 d2 and d3 has dependence on n as does the estimate of sb_m the intermodel standard deviation of trends which appears in the denominator of d2 and d3 the worrying thing about the appended figure is the behavior of d3 this is the test which we thought reviewers 1 and 2 were advocating as you can see d3 produces rejection rates that are consistently lower by factor of two or more than theoretical expectations we do not wish to be accused by douglass et of devising test that makes it very difficult to reject hypothesis h2 even when there is significant difference between the trends in the model average signal and the observational signal so the question is did we misinterpret the intentions of the reviewers were they indeed advocating d3 test of the form which we used i will try to clarify this point tomorrow with francis zwiers our reviewer 2 recall that our current version of d3 is defined as follows d3 bo bm sqrt sbm 2 sbo 2 where bo observed trend bm model average trend sbm intermodel standard deviation of ensemblemean trends sbo standard error of the observed trend adjusted for autocorrelation effects in franciss comments on our paper the first term under the square root sign is referred to as an estimate of the variance of that average ie of bm its possible that francis was referring to sigmase which is an estimate of the variance of bm if one replaces sbm with sigmase in the equation for d3 the performance of the d3 test with synthetic data is at least for large values of n very close to theoretical expectations its actually even closer to theoretical expectations than the d2 test shown in the appended figure which is already pretty close ill produce the revised d3 plot tomorrow the bottom line here is that we need to clarify with francis the exact form of the test he was requesting the new d3 with sigmase as the first term under the square root sign would lead to simpler interpretation of the problems with the dcps07 test it would show that the primary error in dcps07 was in the neglect of the observational uncertainty term it would also simplify interpretation of the results from section 6 im sorry about the delay in submission of our manuscript but this is an important point and id like to understand it fully im still hopeful that well be able to submit the paper in the next few days many thanks to tom and peter for persuading to pay attention to this issue it often took lot of persuasion with best regards ben benjamin d santer program for climate model diagnosis and intercomparison lawrence livermore national laboratory po box 808 mail stop l103 livermore ca 94550 usa tel 925 4222486 fax 925 4227675 email santer1llnlgov peter thorne climate research scientist met office hadley centre fitzroy road exeter ex1 3pb tel 44 1392 886552 fax 44 1392 885681 wwwmetofficegovukhadobs