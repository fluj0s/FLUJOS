oios office of internal oversight services monitoring evaluation nd consulting division mecd inspection of the use of client satisfaction ratings and web metrics as programme performance measures report mecd2006006 date 13 april 2007 mecd team arild hauge k r i s t i n n d r s n emily hamptonmanley elizabeth tullettcourt janet closa 1 report of the office of internal oversight services on the inspection of the use of client satisfaction ratings and web metrics as programme performance measures executive summary planning and budget instructions identify clien t benefits as key dimension of the accomplishments that the united nations secretariat programmes pursue in reference to their general assemblyapproved result s frameworks diverse range of client satisfaction measurement prac tices have entered into prog ramme performance planning monitoring and reporting the techniques used to determine client sa tisfaction appear in many cases to be of relatively poor methodolog ical quality with insu fficient attention to client identification sampling use of unbal anced rating scales and questionable inferences about findings frequently narrow range of services and biased respondent selection is employed to substantiate much broader perfor mance claims informal techniques such as compilation of letters of appr eciation are in oios opinion not appropriate but are declining in use within dga cm and dpi there are some subprogrammes that have sought adherence to sound methodological standards internet traffic statistics reflecting use of secretariat website material not client satisfaction as such is increasingly used but technical entry points to website use analysis is continually changing the mo st common item of observation at the is webpage hits measure that is vulnerable to manipulation in testimony to their convenience both client satisfaction measurement and web traffic statisti cs are utilized to s upport higher number of retroactive result claims than results for which they were or iginally envisaged as the pertinent performance indicator whilst measurement of client satisfaction is not gauge of the degree to which the fulfils its ultimate objectives it can c apture change one step beyond the delivery of outputs also it holds the poten tial of offering some degree of comparability ver time and across different programmes and types of service however the condition of client satisfaction measurements valid ity is the existence and adherence to minimum standards of methodological rigour for which surveys represen t the main instrument in that regard current support facilities are inadequate though client satisfaction measurement may with methodological strengthening yield rele vant performance information monitoring efforts ultimately need to be complemented by programme evaluation in order for the to understand the cause andeffect relationships that affe ct observed positive or negative trends be it in client satisfaction or in other programmatic performance indicators current practices are ultimately constrained by the absence of corporate accountability framework for w hat occurs to bureaucratic out puts and the results beyond whether results are achieved or not matters little to resource allocation and individual performance assessment programmes have had th option of specifying or adjusting their 2data collection methodologi and thereby in effect th eir performance targets after budgets have been approved these factors whic h are features of th overall secretariat planning budgeting and performance assessment syst em in general have had direct effect on status of practices pertaining to client satisfaction as well as website traffic usage measurement oios recommends number of initiatives to improve the level of methodological rigour that is being vested in client satisfa ction measurement practice including formulation of basic standards the possible establishmen t of corporate technical support and guidance facility an ex vetting process and the establishment of common organizationwide platforms for online rveys and for website traffic monitoring contents paragraph page abbreviations i introduction and objectives 12 ii methodology 3 iii findings 473 31 clients satisfaction in normative planning framework 45 32 client satisfaction and website usage measures are becoming more prevalent 68 33 client satisfaction and we bsite traffic measures are often used as an afterthought 910 34 there are commonly agreed measures for website traffic 1114 35 informal methods and ad hoc feedback are inadequate measures of client satisfaction but becoming less prevalent 1517 36 client satisfaction does not necessarily reflect ultimate programme success 1819 37 validity of client satisfaction measurement rests upon sound methodology 2026 38 technical support is wanted some already available but not much used 2728 339 some shortcomings are shared with other programme performance data 2930 iv recommendations 3138 abbreviations cpc committee on programme and coordination dda department of disarmament affairs ea expected accomplishment eca economic commission for africa ece economic commission for europe eclac economic commission for latin america and the caribbean escap economic and social commission for asia and the pacific escwa economic and social commission for western asia ga general assembly ioa indicator or achievement ict information and communication technology imdis integrated monitoring and do cumentation information system ohchr office of the united nations high commissioner for human rights oios office of internal oversight services pas performance appraisal system pm performance measure ppbme rules and regulation governing programme planning the programme aspects of the budget the monitoring of implementation and the methods for evaluation ppr programme performance report rbb resultsbased budgeting unctad united nations conference on trade and development unep united nations environment programme unhabitat united nations human settlements programme unhcr united nations high commissioner for refugees unodc united nations office on drugs and crime unrwa united nations relief and works agency for palestine refugees in the near east 4 organizations will not have long term future if they do not meet the requirements of their customers1 for many organizations in the public sector the measuremen t of customer satisfaction will itself be the measure of success2 i introduction and objectives 1 the current inspection was triggered by the office of internal oversight services oios ongoing concern with quality of the unit ed nations secretariats systems and practices of programme performance planning monitoring and evaluation in the course of preparing the secretarygenerals 2004 2005 programme performance report ppr3 the observation was made of trend towards increasi ng reliance on performance measures that refer to client satisfaction as well as statistics on website usage the inspection was conceived to address measurement of client satisfaction and we bsite usage as features of organizationwide performance planning and manageme nt practice the inspection was thus crosscutting in scope and does not comprise an indepth review of pr actices at individual secretariat entities oios needs to emphasize that the subject of the curre nt report is not whethe r clients are actually satisfied with services provided by the secretaria t but whether the secret ariat has the means to know the specific objectives of the exercise were to review trends and current status in use of different approaches to the determination of client satisfaction and website usag as performance measures assess the validity and credibility of current techniques recommend possible improvements to current practice 2 client satisfaction can most generically be defined as the perception of client regarding the degree to which service provider meets or exceeds his or her expectations 4 customer focus is the first principle of the intern ational standards organizations iso quality management standards iso 900020005 website traffic measurement is somewhat different issue than measurement of client satisfaction6 it involves observing activit pertaining to use of website resources and is derived mechanically ie without client s volunteering their opinions the association stems from website usage bei ng used as evidence of client satisfaction appropriately or not 1 rochie g et customer satisfaction measurement for iso 9000 2000 elsevier 2002 2 hill n and alexander j handbook of customer satisfaction and loyalty measurement gower publishing ltd 2000 3 a6164 4 treasury board secretariat of canada quality services guide ii measuring client satisfaction at httpwwwtbssctgccapubs_polopepubstb_o2qg12easp 1996 5 see httpwwwisoorgisoeniso900014000understandqmphtml see also bill self greg roche customer satisfaction measurement for iso 90002000 elsevier isbn 0750655135 6 the exercise was originally announced further to morandum from under secretarygeneral oios dated 3 may 2006 to all department heads as two separate insp ections respectively on client satisfaction ratings and on web metrics both in respect of their use as performance measures 5ii methodology 3 the inspection process involved combination of desk resear ch two attitudinal surveys and stakeholder interviews i desk research comprised an initial tabulation of all secretariat programmes references to client satisfaction and web metrics as performance measures in the results frameworks approved by the general assembly ga for the three biennia 20022003 20042005 and 20062007 as recorded in the integrated moni toring documentation information system imdis 7 desk research also comprised review of nonun literature re garding utilization of client satisfaction and web metrics measures in countrylevel public sector management ii two concurrent attitudinal surveys were administered during the mayaugust 2006 period respectively on client sati sfaction ratings in this report referred to as scs survey on client satisfaction and on the use of web metrics in this report referred to as swm survey on web metrics the scs was addre ssed to all 186 subprogramme managers and the swm was addressed to 33 departmental website or it managers the two surveys yielded respectively 100 and 52 responses 8 respectively iii lastly inperson and phone interviews were conducted with personnel identified by 22 secretariat departments 9 as having responsibilities releva nt to the current inspection iii findings 31 client satisfaction in rmative planning framework 4 at the secretariat the immediate associati on between client satisfaction and performance measurement follows from the resultsbased budgeting rbb system which has been gradually implemented since 2001 10 the underlying purpose of rbb is for planning and decisionmaking to be driven by future effects rather than the mere historical efforts of the secretariat rbb brings the articulation of re sults frameworks frequently referred to as logframes built on assumed causeandeffect relationships as an entry point to strategic planning resource allocation and reporting these logframes are part of the budget fascicles that are presented to and finally approved by the ga they comprise for all departments sub programmes set of objectives expected acco mplishments ea indicators of achievement ioa and performance measures pm pertai ning to the twoyear budgeting periods whilst objectives represent an articulat ion of the basic longerterm rationale for subprogramme usually derived from formal mandate pert aining to programme eas reflect the 7 see httpimdisunorg 8 thus yielding nominal response rate respectively of 53 and 157 however we understand that many of our survey questionnaire were forwarded by recipients to colleagues thus expanding the respondent universe to an unknown quantity and rendering the calculation of response rates less relevant 9 further request for nomination of focal points as per memorandum from under secretarygeneral oios dated 3 may 2006 10 further to ga resolution 55231 6outcomes to which subprogramme will contribute within given biennium ioas are the means of verification for those eas and pms ar intended to capture the anticipated degree of change from baseline to targ et within given biennium 5 programme performance planning and assessm ent requirements are encapsulated by the rules and regulation governing programme pla nning the programme aspects of the budget the monitoring of implementation and the methods for evaluation ppbme11 and the instructions that are pe riodically issued in suppor t of planning and budgeting12 and performance reporting13 the ppbme actually defines expect ed accomplishments as centred on client benefits expected accomplishmentsshall identify those benefits or changes expected to accrue to users or beneficiaries14 32 client satisfaction and website usag measures are becoming more prevalent 6 it is evident that reliance on client sati sfaction andor website usage measurement has significantly increased in both nomin and relative terms as secr etariat practice with clear majority of departments now utilizing such measures within one or more of their subprogrammes for the 20022003 biennium oios f ound that out of 649 ioas that were listed in departmental budget fascicles 73 11 made reference to client satisfaction15 or to website usage see table 1 below these were spread across 1016 out of 32 31 programmes reviewed for the 20042005 biennium the number of refere nces had increased to 115 out of 974 ioas relative to total number of ioas slight in crease 12 but invol ving higher share of programmes 22 out of 32 6917 7 for the 20062007 biennium midterm records18 indicate that across the secretariat as whole the number of such references increa sed to 201 of the then 992 ioas 20 deriving from 2819 out of the 33 secretariat programmes 8520 the observed trend towards increased reliance on client satisfaction as performance meas ure appears likely to continue as evidenced by 89 of respondents to the scs expressing the opinion that client satisfaction measurement will in the future be either important 37 or very important 52 11 stsgb20008 rule1054 iii 12 see httpppbdunorgrbb 13 see httpimdisunorg 14 ppbme rule1054 iii we note that rbb guidelines for 20082009 biennium httpppbdunorgbi08rbbguidepdf introduces as further refinement ref p 26 the formulation of the result should answer the question what benef it will accrue to the end user at the end of the biennium 15 based on wordsearch followed by elimination of instances of doublecounting 16 dda desa nepad eclac escwa hchr dpi dmppba dmohrm oios 17 additions were dgacm unctad unep habitat odc ocha dmocss dmunog dmunov and dmunon 18 programmes have had the option of specifying or adding to their list of performance measures after the ga approved their budget although the total number of such measures can thus increase over time until the end of the biennium we have considered ioas and pms as being most essentially part of the ex planning process 19 further additions being dpko ola unhcr itc escap ece 20 including subprogrammes for which parate budget fascicles are issued 7table 1 secretariat use f client satis faction or web use measures in per formance plans reporting 20022003 20042005 20062007 number of indicators of achievement ioa 649 974 992 total of references to client satisfaction or web use 73 115 201 share of ioas 11 12 20 total of departments citing client satisfaction or web use 10 22 28 share of departments citing client satisfaction or web use 1032 31 2232 69 2833 85 total of results achieved citing client satisfaction or web use 74 184 na of results achieved citing client satisfaction or web use 16 29 na 8 among techniques the use of client surveys is predominant accounting for 82 of the references made to client satisfaction or webs ite usage in the ioas for 20062007 as per table 2 below amongst the surveys conducted by sc s respondents 42 were paperbased and administered in person 38 were distributed as attachment to emails and only 30 were administered as webbased surveys oios noted that there is current organizationwide software system for administering online survey s several programmes have independently and in parallel gone through vendor selection process in respect of procuring software for web based surveys21 in other cases online survey instrument s have been designed from scratch based on internal expertise and capacities table 2 types of measurement techniques in us at the secretariat by imdis word reference 20042005 20062007 change surveybased client satisfaction ra tings 83 72 165 82 82 10 indicators of website traffic 21 18 24 12 3 6 informal reviews letters of appreciation citations in publications etc11 10 12 6 1 4 total 115 100 201 100 86 75 33 client satisfaction and website traffic asures are often used as an afterthought 9 changing the unit of observation from exante ioas to expost results statements reveals another dimension to the pictur of increasing reliance on client satisfaction and website usage measurement whilst the share of ex ioas citing client satisfaction or website use was relatively stable in the 1112 region be tween 20022003 and 20042005 the proportion of end ofbiennium ex post results statements that referred to such methodologies increased from 16 per cent to 29 per cent this suggests that programme s when retroactively making result claims end up being more dependent on client satisfacti on measurement than they envisaged at the beginning of the planning cycle this was pecially pronounced at end of 20042005 for which 21 websurveyor survey monkey gmi snapsurveys and questback being among the software providers cited by departments 8the share of ex post results statements referring to client satisfaction or website usage was more than twoandahalf times the share of ex ioas that made such reference in comparison for the 20022003 biennium the share of ex post statem ents referring to client satisfaction was only somewhat higher than ex ioas22 10 likewise when it comes to web traffic alone at the end of the 20042005 biennium total of 74 ex post results statements referred to web usag being more than threeandahalf times the number of ex ioas for the same period this means again that web traffic measures are employed in support of many more results than those for which web traffic was originally identified as the pert inent performance indicator in turn this suggests that website traffic indicators are found in hindsight to be more relevant or simply more convenient than envisaged at the beginn ing of the biennium 34 there are commonly agreed measures for website traffic 11 web traffic can be measured in many ways including analysis of number of downloads hits unique visitors page views and other user tracking data ach approach also comes with limitations in the inferences that can be made fr om the quantitative findings they yield log file analysis can extract accurate page view or page request details breaking down visits to individual website subcomponents ie the differe nt pages within given website the duration of visits and the geographical distri bution of those who have entered but may provide an incomplete picture of use eg due to caching23 the measurement of downloads can also be technically challenging for instance one need s to know the number of successful not just requested downloads 12 amongst secretariat programmes the most common approaches to gauging website traffic is to count hits followed by downloads duration of time spent on web page or study of log files of user patterns24 the use of popup surveys to obt ain more facts about website users and their perceptions about materials perused ie determination of satisfaction is limited25 several subprogrammes still make retroactive performance claims for 20042005 and ex performance plans for 20052006 based on increased volume of hits however hits have largely been discredited as measure of web site traffic26 because single web page can contain dozens or more different elements that are separa tely counted the use of hits make comparisons meaningless also performance against target s can in effect be manipulated by changing 22 because these observations emanate fr om statements provided at endbie nnium comparable numbers do not yet exist for 20062007 23 entailing that when web page is being viewed the user may not actually be visiting the website maintained by the content owner but cached version stored elsewhere such as databases of search engine and the content owner never acquiring any record of it having been viewed conversely visits made by search engines and robots looking for content that is not necessarily leading to material be ing viewed can also inflate the number of entries in log files thus not showing visitors who actually made use of content factoring out the activity of search engines is thus necessary in order to obtain realistic and accurate picture of web traffic like wise programmeinternal access ie staff who access programmes own website eg fo r commonly used documents and materials need to be factored out in order to arrive at any measure of client use 24 respectively in use by 36 34 9 and 10 of respondent departments 25 15 of respondent departments indicate such use 26 for more detailed and supplierindependent review of different techniques see httpwwwcomputerworldcommanagementtopicsebusinessstory0108017198900html 9content eg adding photos without actually receiving any additional visitors there are numerous different commercial software products to support website usage or traffic monitoring currently in use by secretariat programmes27 use of commercial products is frequently supplemented by programming efforts of the individual subprogrammes 13 in any case all automated web traffic m onitoring systems yield nominal and largely quantitative data on volume wit hout giving information allowing inferences about satisfaction of users ultimately the satisfaction of we bsite users can only be determined through supplementary qualitative techniques eg throug h interviews focus groups or more indepth surveys of website users 14 the use of internet has become mainstay of the secretariats operations at the moment the determination of the web traffic use is fr agmented among observation of multiple different technical web parameters oios is unable to pr escribe the exact parameters that are most efficacious to future monitoring the industry benchmarks for what is useful and possible to track are continuously evolving in this respec t it is apparent to oios that degree of flexibility will be needed to avoid programmes becoming locked into performance targets and measurement techniques determined at the pla nning stage but that are either irrelevant or cost ineffective by the time of actual programme implementation 35 informal methods and ad hoc feedback are in adequate measures of client satisfaction but becoming less prevalent 15 the use of letters of appreciation as methodology for measurement of client satisfaction by the secretariat progra mmes has declined between 2002 and 2007 28 by 2006 2007 letters of appreciation were not include d among the planned performance measures as stated at beginning of biennium oios assessment is that letters of appreciation are especially vulnerable to subjective analysis review of samples submitted to oios indicates that letters of appreciation and complaints are very variable in specificity and that there is little standardization even within individual departments of the pr ocessing recording and response to such letters several programmes wrote that they did not have specific or formal procedures while they may be used to express sincere gratitude for par ticipation in an event that in the senders view was wellexecuted the letters reviewed by oios are not clearly relevant to the eas that secretariat departments have committed themselv to as highlighted by one scs respondent such letters measure political appreciation and are not nece ssarily meritbased reflecting reality also they do not measure dissatisfac tion at the end of the day the writing and recording of letters of appreciation needs to be seen as part of the customs of diplomatic protocol and courtesy being nice to receive but nomin in substantive focus and unreliable as performance indicator 16 most programmes 56 keep record of the number of times they are cited in media academic journals and in official records of proceedings and several relate such 27 we note eg ddas use of sawmill eclacs use of web trans escaps use of urchin habitats use of deep matrix other applications mentioned in clude webalizer analo gue netiq sade 28 during the 20022003 biennium letters of appreciation were used in support of performance reporting by dda desa and eclac 10information to client satisfaction of course the frequency or volume of such citation does not necessarily indicate client sati sfaction the context of mention may on the contrary be entirely critical similarly there are cases29 in which number of participants in meetings is interpreted as an expression of satisfaction in this case too nominal volume of participation cannot necessarily be interpreted as satisfa ction with services provided by the 17 oios assessment is that letters of apprecia tion and other informal sources of feedback are not in general adequate as measures of client satisfaction when expressed by specific clients in respect of specific services provided by specific secretariat staff they may be relevant to assessing the performance of those specific cretariat staff however their usefulness as measure of performance at the overall pr ogramme level is in general limited 36 client satisfaction does not necessarily reflect ultimate programme success 18 oios recognizes from the outset that to the extent that client sa tisfaction relates to attitudes perceptions and other proxies for realworld phenomena that the secretariat seeks to effect it is lessthan perfect measure of performance indication of client satisfaction ultimately represents measure of performance that should be complemented by triangulation with other types of observa tions an example of perfor mance measures that are more relevant than client satisfaction as single measure of overall programme success are those used by the relief and works agency for palestine ref ugees in the near east unrwa which is provider of key social services directly to over 4 million refugees although the clients are clearly identifiable and their levels of satis faction can be gauged there are actually more objective and substantive measur of performance available unrwa is able to report30 on the actual health and educational status of those served by the agency eg school pass rates infant and maternal mortality sewerage connection and access to safe water when data is simultaneously available for cont rol group ie palestine refugees not served by unrwa the differential will be seen as associated with unr wa and founded on an evidential basis that is more substantively relevant as performan ce measure than perceptions of satisfaction 19 nevertheless oios assessment is that the notion of client satisfaction does have validity secretariat entities vary greatly in the na ture of their operations as well as what may be considered appropriate as measure of their programmatic performance many of the uns functions are processoriented involving globa l forumconvening and normsetting rather than direct delivery of services to the public objec tive and uniform indicators of impact efficiency or effectiveness can be elusive the realworld effects of what the does may only materialize over very long timeframe and then be difficu lt to separate from the contribution of other actors and factors as such client satisfaction does represent tion of performance that goes at least one step beyond the measurem ent of internal bureaucratic ac tivity all departments provide service of some kind for which set of clients can be identified be it an internal or an external constituency client satisfaction ratin gs also hold the potential of allowing some degree of 29 eg ola law of the seas subprogramme 30 eg in context of 20042005 programme performance of the united nations for the biennium 20042005 a6164 pp 211216 11comparability across location types of operation and time31 surveys in particular have the advantage of being adaptable to number of varying environments and can be administered by placement on websites through email or paper media or through phone interviews 37 validity of client satisfaction asurement rests upon sound methodology 20 whilst potentially relevant there are conditi ons attached to the utility of client satisfaction measurement above all there is need for higher gree of consistency and rigour to the methodological foundation of client satisfaction measurement practices in that regard an initial set of conditions relates to defi nitional clarity in terms of alignment between queried services and expected programme accomplis hments b existence of an identifiable and legitimate client constituency and c appropriate techniques for determining satisfaction these concerns in turn bring focus to the imperative of minimizing survey error firstly there may be nonresponse bias ie those who provide feedb ack being representative only of those who have received service not those who are meant to receive service 32 secondly those who do respond may not be typical of those who have received service only those who have strong positive or negative feelings thirdly those who do respond may not be truthful and instead provide answers that they think are wanted or that they think they themselves will benefit from fourthly there may be measurement errors whereby ina ccuracies follow from the way questions are framed or responses tabulated33 oios notes albeit without having conducted an indepth review of individual instruments that dgacm and dp i are among the few departments that have sought to maintain efficacious survey methodology 21 oios found number of instances where ther is mismatch between the eas that are being pursued and the actual services about whic h expressions of satisfaction from clients have been sought or expressed an example would be an ea framed as effective implementation of outcomes of global conference34 being validated at endbiennium by reference to participants satisfaction with support provided to meetings of part icular commission or committee backstopped by the subprogramme in ques tion similar example would be that an ea on enhanced policy dialogue on trade practices and regulatory framework35 is evidenced by satisfaction expressed in respect of particular forum meeting that has been held in these cases the mismatch is most importan tly one of magnitude ie that the service about which satisfaction is expressed is little more than narro w slice of the ea and thus not sufficient as evidence of progress toward s the much bigger ea 22 satisfaction is itself complex issue and ma comprise perceptions about the degree to which service is pertinent to respondents needs their feelings about whether service delivery 31 as an example of client satisfaction measurement thodology that has been applied to multiple contexts covering both private an d public services see the american customer satisfaction index at httpwwwtheacsiorgoverviewhtm 32 see eg everett s 2000 respondent satisfaction m easurement council for marke ting and opinion research cmor port jefferson ny 2000 wwwcmororg or fletcher j and schmidt d measuring response bias in survey research paper presented at aapor nnual conference may 1619 2001 33 there are numerous standards and definitions of survey error see g us census bureau httpwwwcensusgov or oecd httpstatsoecdorgglossaryindexhtm 34 example from desa sustainable development subprogramme 20042005 35 example from ece trade and development subprogramme 20062007 12has been well executed and may or may not be expressed relative to particular set of expectations at the secretariat when clients satisfaction perceptions are sought it is general satisfaction that is most frequently 81 queried although timeliness quality technical expertise are also raised by majority of sc s respondents as being focused upon clarity in these regards is indeed instrumental to validity and utility of client satisfaction measurement as tool to instigate improvements in service delivery 23 it is not clear to oios that those managers who conduct client satisfaction surveys in general make appropriate efforts to minimize sampling bias for some services eg public documents there is finite universe of clie nts and response rates to surveys are often unknown whilst the direct recipients of servic from the may be possible to identify their satisfaction is not necessarily the same as that of the true population or universe of clients most appropriately associated with the ea fo r instance the people who attend conferences or meetings perhaps with funding provided by the itself may be entirely satisfied with their participation without their attendance ever tr anslating into any benefits to the intended ultimate beneficiaries of the uns work whose satisfaction would more closely mirror the stated eas 24 from oios interviews there is some indi cation that client satisfaction surveys are administered by selecting service or event th at is generally considered success and thus not be typical of the full range of services needed to make progress towards an expected accomplishment along the same lines there are several cases of satisfaction ratings being expressed in reference to unbalanced scales 36 whereby number and labelling of response options are tilted towards yielding favourable ratings37 oios notes that in administering surveys practices for maintaining respondent anonymity also vary lastly we have found subprogrammes that have made any detailed description of their client satisfaction methodology publicly available all survey and public opin ion researchers have an obligation to provide certain minimal information about how research was conducted in order to allow consumers of survey results an adequate basis for judging the re liability and validity of results reported at the secretariat such practice would be in li ne with the secretarygenerals reform proposal38 and suggestions for improving public access to secretariat information39 25 an important risk to the utility of qu estionnaires as method for obtaining client satisfaction data raised by many inspection interloc utors is the possibility of survey fatigue ie that clients whether internal or extern will avoid responding to questionnaires not because the questionnaires are poorly designed or because they have opinions to offer but because they get so many of them40 whilst agreeing that this is risk oios notes that it is also in part question of survey design and manage ment ie that too many departments ask too many and too general questions from client gr oup that has not been too well defined we 36 eg where more calibration is pres ented for positive than negative perceptions for instance by offering range of response options comprising excellent good satisfactory and poor 37 see eg sangster r and willits f evaluating numeric rating scales replicated results united states department of labor bureau of labor statistics 2001 at httpwwwblsgovorepdfst010120pdf 38 see proposal 19 of a60692 and corr1 investing in the united nations for stronger organization worldwide 39 a60846add4 40 for transparency we need to make public complaint made by some inspection interlocutors namely of being recipients of three different simultaneous surveys from oios mecd division alone 13believe this to represent factor that strongl lends support to the need for organizationwide standards and coordination 26 oioss general consideration is that there is not sufficient rigour nd discipline to the measurement of client satisfaction and website usage oios notes that there has in general been little progress towards the earlier call by the cpc 41 for consistent standards for survey conduct finally oios notes that although c lient satisfaction measurement may with methodological strengthening yi eld relevant performance information monitoring efforts ultimately need to be complemented by program evaluation practice that addresses the full range of causeandeffect relationships that affect observed positive or negative trends42 be it in client satisfaction or in other pr ogrammatic performance indicators 38 technical support is wanted some already available but not much used 27 whilst some departments notably dgacm and dpi have developed an inhouse expertise for the review of client satisfaction nd website usage large majority of informants both interviewees and respondents to the scs the swm agree that lack of financial and human resources were the greatest obs tacles to adequate practices43 amongst respondents to the swm an overwhelming majority also underlined the im portance of policies and guidelines only one programme44 reported receiving any training from itsd on analysis of web metrics data we understand webtrends the software in use by itsd to be facto industry standard but note that its use is limited one crit ical factor to that effect is th at use of itsd services involves charge or cost for which other secretar iat programmes have budget allocation 28 oios has reviewed the body of technical guidance available at dms rbb website 45 and found the materials to be relevant but not to have been used much46 not single inspection interlocutor referred to the guidance materials ava ilable oios also notes that little if any revision has been made since 2003 whilst materi als highlight pertinen t principles little reference is made to cases of potential individual good practices47 that already exist subprogramme staff wish to have more direct pr actical showmehowto type of advice there are currently staff in dm or elsewhere inhou available to provide the handson assistance that subprogramme managers express need for overall 62 of responde nts to the scs agreed that there is need for common guidelines and minimum standards for conducting surveys 41 as per a5916 supp 27 42 see eg oios report a6183 strengthening the role of evaluation and the application of evaluation findings on programme design delivery and policy directives and oios annual report a60346 and corr1 43 respectively by 54 and 55 indicating that factor as big or moderate obstacle 44 department of disarmament affairs geneva branch 45 see guide to rbb dated 23 october 1998 httpppbdunorgbi08rbbguidepdf guide to preparation for data collection and measurement httpppbdunorgrbbprepdoc guide to collecting data httpppbdunorgrbbcolldatadoc and guide to post data collection httpppbdunorgrbbpostdatadoc 46 as of 22 january 2007 total of 7921 visitors was cited on the website itself 47 oios found that eg dpi conducts surveys with attention being paid to the client identification sampling phrasing of questions and utilization of likert scales effort s to maintain historical data has also been started with an access database the efforts of dpi have been selfdirected but their experiences could be shared with other departments or subprogrammes 1439 some shortcomings are shared w ith other programme performance data 29 the measurement of client satisfaction respec tively website usage is subject to the same systemic constraints that apply to the broader enterprise of programme performance management at the secretariat in general perhaps most crucially programme performance measures in general do not have direct decisionmaking purpose or accountability implications this is however characteristic of the rbb budgeting process that is centred upon results that are aimed at not results that have actually been achieved when actual performance against budget objectives is reported through the ppr budget d ecisions for the next bu dget period have already been made the primary recipient of the ppr th cpc does not in any case have authority over budget resources at the same time the ppbme explicitly state that information shall be transmitted between the programme evaluation and the personal performance appraisal systems 48 likewise there are client satisfaction measures that have been included in the indicators to be reviewed by th management performance board49 oios findings reaffirm the general picture noted by the secretarygeneral50 that the existing systems for reporting and evaluating the performance of programmes have practical impact on future plans and resource allocation decisions 30 similarly on the methodology front specification of ioas and pms has not necessarily been disciplined by realism in availability of underlying data the biennial budget process has not required that data collect ion methodologies for ioas and pm s be specified by the time of budget approval 51 in many cases performance indicator methodologies specified in imdis are aspirational being things that could or should be done to determine performance without it being clear whether they will be used or not programme manage rs can in effect modify their own performance targets during the biennium ma nagers will always wish to put their own performance in the best possible light and ther efore choose measures accordingly on the other hand we note that there are number of instances where client satisfaction has been recorded as 100 as both baseline and target thus leav ing the measure of little utility to improving performance iv recommendations 31 the status of the secretariats use of clie nt satisfaction as measure of performance cannot ultimately be seen in isolation from th underlying systems and practices of programme performance planning budgeting and reporting in that regard oios analysis and recommendations should be seen in the context of the joint inspection its jiu observations on resultsbased management at the secretariat52 as well as oioss own assessment of the need 48 ppbme rule 1073 49 as per a61319 manag ement performance board 50 as per a57387 strengthening of the united nations an agenda for further change 164 51 as of 1 february 2004 ie after beginning of 20042005 biennium data collection plans had been specified for only 25 per cent of the secretariats total range of performance indicators by 31 january 2005 that share had risen to only 46 per cent in respect of the 20062007 biennium as of 17 july 2006 indicator methodologies had been specified for 55 of the secr etariats 1021 ioas by 18 january 2007 such methodologies had been specified for 67 of ioas 52 see jiurep20045 overview of the series of reports on managing for results in the united nations system and jiurep20066 resultsbased management in the in the context of the reform process 15for strengthening programme perfor mance monitoring and evaluation53 the ongoing reviews of rbm and of the experiences gained with pl anning and budgeting system requested by the general assembly54 presents an opportunity for pl acing the current findings and recommendations within comprehensive set of considerations pertaining to the broader decisionmaking process at the all the following recommendations are addre ssed to the department of management recommendation 1 32 oios recommends that set of minimum methodological standards for survey conduct be established this may comprise of definition and subsequent circulation of guidelines pertaining to eg survey constituency sampling techniques presentation of findings and public availability of methodological description and should be integrated within the format for imdis as description of such methodologies one item of methodology that can potentially be addressed separately from broader issue of stan dards and guidance is promulgation of uniform scale of satisfaction ratings for perception surveys oios believ that practices for use of likert scales 55 can and should be standardized into si mple and balanced format eg with fivepoint scale for use in all surveys that address strength of attitudes sp06006001 recommendation 2 33 oios recommends that letters of appreci ation informal doc ument review and feedback be discontinued as performance measures advice to this effect would need to be integrated with instructions for articulati on of strategic frameworks budget proposals and performance monitoring as well as being integr ated into the body of guidance available on an ongoing basis ie websites manua ls etc sp06006002 recommendation 3 34 in order to enable implementation of minimum methodological standards as above oios recommends that consideration be given to the establishment of an advis ory facility for client satisfaction measurement and survey conduct this recommendation may most appropriately be addressed in the context of re viewing broader technical guidan ce in support of the uns overall rbbrbm system for the planning budgeting and reporting of programme performance sp 06006003 53 eg as per pp 1118 of a6073 and pp 95 of a6164 programme performance report of the 54 as per resolutions 58269 and 61245 55 likert scales are frequently knowingly or not used for asking person to select category label from list that expresses intensity of attitudes or indicating the extent of disagreement or agreement with statement an internal code used by oios for recording recommendations 16recommendation 4 35 in order to strengthen the demand for appl ication of good practices as recommended above oios recommends that consideration be given to the establishment of mechanism for vetting prior to review of individual depar tmental budget submissions of the client satisfaction measurement methodo logies that are being propos ed as basis for programme performance assessment this would in turn involve form ulation of criteria for review b assigning responsibility for review of methodology and c communicating the requirements and approach to the budget applican t departments sp06006004 recommendation 5 36 oios recommends that consideration be given to procurement and installation of common software platform for conduct of online surveys56 this would eventually support convergence in practices allow for accumulation of organizationwide statistics on client satisfaction and could lead to substantial scal economies in vendor selection and maintenance common online survey platform would however not merely be software consideration it would also need to be seen in context of broader advisory cap acity and support facilities sp06 006005 recommendation 6 37 oios recommends the establishment of an interdepartmental advisory group or task force on website traffic monitoring be initiated this body should be tasked above all with articulating and periodically updating body of good practice pe rtaining to the technical parameters of website traffic monitoring it s hould also review the functional conditions and costs of establishing common organizationwide software plat form for such website traffic monitoring sp06006006 38 finally oios notes that further to its communication 57 of early findings from the current inspection exercise dm has included number of pertinent revisions to its budget instructions for the 20082009 biennium58 however the current final in spection report brings further specificity to findings and recommendations and to the actions that need to be taken by the secretariat report of the committee on relati ons with the host country resolution 6141 56 we recognize that whilst itsd may need to have technical responsibility for such installations its functional parameters would need to be determined by user programmes 57 as per email exchange 7 september 2006 58 ref 22 page 1112 of instructions proposed programme budget for the biennium 20082009 intranet httpppbdunorgbi08 17