from anders moberg andersmobergnatgeosuse to martin juckes mnjuckesrlacuk subject mcintyre mckitrick mitrie date fri 04 aug 2006 091824 0100 cc anders andersmisususe eduardozoritagkssde hegerldukeedu esperwslch kbriffaueaacuk mallen1physicsoxacuk weberknminl tosbornueaacuk xflowed dear martin and all others having read the new manuscript i would like to draw the attention of all of you to the section about mcintyremckitrick vs mann et i am not entirely happy with this section it may be that i am not fully updated about all details on their dispute but it appears to be some mistakes in this section of our manuscript therefore i ask all of you to check how this section can be improved and clarified this is very important if we refer incorrectly to the mmmann dispute i am convinced that all of us will be involved in lengthy frustrating email discussions later on i anticipiate this from personal experience lets do our best to avoid this the problematic bit of text starts on p 16 4 the failure of mm2003 is partly due to misunderstanding of the stepwise reconstruction method and slightly below mm2003 only calculate principal components for the period when all chronologies are present i read through the mm2003 paper yesterday from what is written there on p 763765 it appears that they were well aware of the stepwise method on p 763 about at the middle of the page they write following the description of mbh98 our construction is done piecewise for each of the periods listed in table 8 using the roster of proxies available through the period and the selection of tpcs for each period listed in table 8 this is clearly at odds to what is written in our manuscript has it been documented somewhere else that mm2003 despite what they wrote really misunderstood the stepwise technique if it is so we need to insert reference if this is not the case we need to omit the lines about the misunderstanding we also need to explain better why the mm2003 calculations differ from mbh moreover our sentence mm2003 only calculate principal components for the period when all chronologies are present imply that mm2003 only calculated pcs for the period 18201971 as this would be the period when all chronologies are present according to the mm2003 table 8 obviously they calculated pcs beyond 1820 as their calculations actually extend back to 1400 the problem continues in the legend to our fig 2 each of the 212 data series is shown the red rectangle indicates the single block used by mm2003 neglecting all data prior to 1619 the last sentence is inconsistent with the information in mm2003 in three ways mm2003 clearly show in their table 8 that they analysed the same blocks of data as mbh b the year 1619 as starting point of data block is inconsistent with mm table 8 where does the year 1619 come from it is not mentioned anywhere in mm2003 c the red block implies that mm2003 made calculations back only to 1619 but they did back to 1400 moreover the numbers given in the graph of our fig 2 indicate that the total number of series is 211 whereas the text in the legend and also in the main text on p 16 says 212 which number is correct i suppose that some of you others will know this subject much better than i i have just read the mm2003 paper and find our reference to it to be inconsistent with it i hope you all can make efforts to make this bit crystal clear if not i fear we will get problems finally i would like to draw your attention to the related sentence in our conclusions on p 26 papers which claim to refute have been reviewed and found to contain serious flaws are all of you happy with this statement would it sound better with somewhat less offending sentence something like papers which claim to refute have been reviewed and found to essentially contribute with insignificant information that does not affect the consensus and even to include some flaws i attach the mm2003 paper i will send some comments to the other parts of the text in separate mail cheers anders martin juckes wrote hello all here is another draft ive added new reconstruction using 19 independent proxies series from jones et mann et esper et and moberg et this gives good fit to the calibration data such that 2 recent years exceed the maximum preindustrial estimate by 4 sigma levels ive included this because without it i found it hard to draw precise and useful conclusions from the 4 partially overlapping reconstructions i had done before cheers martin documentclasscpd11ptegu input macs voffset 5cm hoffset 15cm begindocument title bf millennial temperature reconstruction intercomparison and evaluation runningtitlemillennial temperature runningauthormnjuckes et authormartin juckes1 myles allen2 keith briffa3 jan esper4 gabi hegerl5 anders moberg6 tim osborn3 nanne weber7 eduardo zorita8 correspondencemartin juckes mnjuckesrlacuk affil british atmospheric data centre sstd rutherford appleton laboratory chilton didcot oxfordshire ox11 0qx united kingdom affil1 rutherford appleton laboratory 2 university of oxford 3 university of east anglia 4 swiss federal research institute 5 duke university 6 stockholm university 7 royal netherlands meteorological institute knmi 8 gkss research centre datemanuscript version from 31 oct 2005 msnumberxxxxxx pubyear pubvol pubnum received pubacpd only applicable to acp revised accepted firstpage1 maketitle beginabstract there has been considerable recent interest in paleoclimate reconstructions of the temperature history of the last millennium wide variety of techniques have been used the interrelation among the techniques is sometimes unclear as different studies often use distinct data sources as well as distinct methodologies recent work is reviewed with an aim to clarifying the import of the different approaches range of proxy data collections used by different authors are passed through two reconstruction algorithms firstly inverse regression and secondly compositing followed by variance matching it is found that the first method tends to give large weighting to small number of proxies and that the second approach is more robust to varying proxy input reconstruction using 19 proxy records extending back to 1000ad shows maximum preindustrial temperature of 0227k relative to the 1866 to 1970 mean the standard error on this estimate based on the residual in the calibration period is 0149k two recent years 1998 and 2005 have exceeded the preindustrial estimated maximum by more than 4 standard errors endabstract openup 1jot introductionlabelsecintro the climate of the last millennium has been the subject of much debate in recent years both in the scientific literature and in the popular media this paper reviews reconstructions of past temperature on the global hemispheric or nearhemispheric scale by citetjones_etal1998 jbb1998 citetmann_etal1998a mbh1998 citetmann_etal1999 mbh1999 citethuang_etal2000 hps2000 citetcrowley_lowery2000 cl2000 citetbriffa_etal2001 bos2001 citetesper_etal2002b ecs2002 citetmann_jones2003 mj2003 citetmoberg_etal2005 msh2005 citetoerlemans2005 oer2005 citethegerl_etal2006 hca2006 the criticism directed at them mainly mbh1999 by citetmcintyre_mckitrick2003 mm2003 and others climate variability can be partitioned into contributions from internal variability of the climate system and response to forcings which the forcings being further partitioned in natural and anthropogenic the dominant change in forcing in the late 20th century arises from human impact in the form of greenhouse gases citepprimarily carbon dioxide methane and chlorofluoro carbonsipcc2001 the changes in concentration of these gases in the atmosphere are well documented and their radiative properties which reduce for given temperature difference radiative loss of heat to space from the mid and lower troposphere citepfor carbon dioxide this was first documented byarrhenius1896 are beyond dispute however there remains some uncertainty on two issues firstly how much of the observed change is due to greenhouse forcing as opposed to natural forcing and internal variability secondly how significant compared to past natural changes are the changes which we now observe and expect in the future the first question is not answered by the ipcc conclusion cited above because that conclusion only compares the anthropogenic forcing of the late 20th century with the natural forcings of the same period further back in the past it is harder to make definitive statements about the amplitude of variability in natural forcings the second question reflects the uncertainty in the response of the climate system to given change in forcing in the last century both the variations in forcing and the variations in response have been measured with some detail yet there remains uncertainty about the contribution of natural variability to the observed temperature fluctuations in both cases investigation is hampered by the fact that estimates of global mean temperature based on reliable direct measurements are only available from 1856 onwards citepjones_etal1986 climate models are instrumental in addressing both questions but they are still burdened with some level of uncertainty and there is need for more detailed knowledge of the behaviour of the actual climate on multicentennial timescales both in order to evaluate the climate models and in order to address the above questions directly the scientific basis for proxy based climate reconstructions may be stated simply there are number of physical indicators which contain information about the past environmental variability as these are not direct measurements the term proxy is used citetjones_mann2004 review evidence for climate change in the past millennium and conclude that there had been global mean cooling since the 11th century until the warming period initiated in the 19th century but the issue remains controversial this paper reviews recent contributions and evaluates the impact of different methods and different data collections used section 2 discusses recent contributions which have developed range of new methods to address aspects of the problem section 3 discusses the technique used by mbh19989 in more detail in the context of criticism by citetmcintyre_mckitrick2003 hereafter mm2003 section 4 presents some new results using the data collections from 5 recent studies sectiona survey of recent reconstructions this section gives brief reviews of recent contributions displayed in fig1 of these 5 are estimates of the northern hemisphere mean temperature mbh1999 hps2000 cl2000 msh2005 hca2006 2 of the northern hemisphere extra tropical mean temperature bos2001 ecs2002 and 3 of the global mean temperature jbb1998 mj2003 oer2005 all except the inherently low resolution reconstructions of hps2000 and oer2005 have been smoothed with 40 year running mean with the exception of hps2000 and oer2005 the reconstructions use partly overlapping methods and data so they cannot be viewed as independent from statistical viewpoint in addition to exploiting range of different data sources the above works also use range of techniques the subsections below cover different scientific themes ordered according to the date of key publications some reconstructions which do not extend all the way back to 1000ad are included because of their importance in addressing specific issues the extent to which the global northern hemisphere and northern hemisphere extratropical reconstructions might be expected to agree is discussed in sect210 below subsectionhighresolution paleoclimate records citetjones_etal1998 jbb1998 present the first annually resolved reconstructions of temperatures back to 1000ad using composite of standardised 10 proxies for the northern hemisphere and 7 for the southern with variance damped in the early part of the series to account for the lower numbers of proxies present 6 series extend back to 1000ad following citetosborn_etal1997 the composites are scaled by variance matching appendix against the annual mean summer temperatures for 19311960 climate models are also employed to investigate the temperature coherency between proxy sites and it is shown that there are strong large scale coherencies in the proxy data which are not reproduced by the climate model an evaluation of each individual proxy series against instrumental data from 1881 to 1980 shows that treerings and historical reconstructions are more closely related to temperature than those from corals and icecores with regard to the temperatures of the last millennium the primary conclusion of jbb1998 is that the twentieth century was the warmest of the millennium there is clear evidence of cool period from 1500 to 1900 but strong medieval warm period mwp though the second warmest century in the northern hemisphere reconstruction is the 11th the mwp is discussed further in sect24 below jbb1998 draw attention to the limitations of some of the proxies on longer timescales see sect35 below homogeneity of the data record and its relation with temperature may not be guaranteed on longer timescale this is an important issue since many climate reconstructions assume constant relationship between temperature anomalies and the proxy indicators there are also problems associated with timescaledependency in the relationship which are discussed further in sect26 below mj2003 include some additional proxy series and extend to study period back further millennium and conclude that the late 20th century warmth is unprecedented in the last two millennia subsectionclimate field reconstruction citetmann_etal1999 published the first reconstruction of the last thousand years northern hemispheric mean temperature which included objective error bars based on the analysis of the residuals in the calibration period the authors concluded not only that their estimate of the temperature over the whole period 1000ad to 1860ad was colder than the late twentieth century but also that 95 certainty limits were below the last decade of the twentieth century the methods they used were presented in mbh1998 which described reconstruction back to 1400ad mbh1998 use collection of 415 proxy time indicators many more than used in citetjones_etal1998 but many of these are too close geographically to be considered as independent so they are combined into smaller number of representative series the number of proxies also decreases significantly with age only 22 independent proxies extend back to 1400ad and in mbh1999 12 extend back to 1000ad 7 in the northern hemisphere mbh1998 and mbh1999 have been the subject of much debate since the latter was cited in the ipcc 2001 report though the ipcc conclusionsfootnotecitetipcc2001 concluded that the 1990s are likely to have been the warmest decade of the millennium in the northern hemisphere and 1998 is likely to have been the warmest year where likely implies greater than 66 probability since 2001 it has been recognised that there is need to explicitly distinguish between an expression of confidence as made by the ipcc in this quote which should include expert assessment of the robustness of statistical methods employed and simple citation of the results of statistical test in the language of citetmanning_etal2004 we can say that mbh1999 carried out statistical tests which concluded that the 1990s have been the warmest decade of the millenium with 95 likelihood while ipcc 2001 after assessing all available evidence had 66 confidence in the same statement were weaker than those of mbh1999 this work also differ from jones et 1998 in using spatial patterns of temperature variability rather than hemispheric mean temperatures in this way the study aims to exploit proxies which are related to temperature indirectly for instance changes in temperature may be associated with changes in wind and rainfall which might affect proxies more strongly than temperature since wind and rainfall are correlated with changes in temperature patterns it is argued there may be important nonlocal correlations between proxies and temperature different modes of atmospheric variability are evaluated through an empirical orthogonal function eof analysis of the time period 1902 to 1980 expressing the global field as sum of spatial patterns the eofs multiplied by principal components pcs representing the temporal evolution earlier instrumental data are too sparse to be used for this purpose instead they are used in validation calculation to determine how many eofs should be included in the reconstruction time series for each mode of variability are then reconstructed from the proxy data using optimal least squares inverse regression finally the skill of the regression of each pc is tested using the 1856 to 1901 validation data prior to 1450ad it is determined that only one pc can be reconstructed with any accuracy this means that the main advantage of the climate field reconstruction method does not apply at earlier dates the methodology will be discussed further in sect3 below the reconstructed temperature evolution fig1 is rather less variable than that of jones et 1998 but the differences are not statistically significant the overall picture is of gradual cooling until the mid 19th century followed by rapid warming matching that evaluated by the earlier work subsectionborehole temperatures citethuang_etal2000 hps2000 estimate northern hemisphere temperatures back to 1500ad using measurements made in 453 boreholes their paper also presents global and southern hemisphere results using an additional 163 southern hemisphere boreholes the reconstruction is included here even though it does not extend back to 1000ad because it has the advantage of being completely independent of the other reconstructions shown temperature fluctuations at the surface propagate slowly downwards so that measurements made in the boreholes at depth contain record of past surface temperature fluctuations hps2000 used measurements down to around 300m the diffuse nature of the temperature anomaly means that short time scale fluctuations cannot be resolved prior to the 20th century the typical resolution is about 100 years citetmann_etal2003 analyse the impact of changes in land use and snow cover on borehole temperature reconstructions and conclude that it results in significant errors this conclusions has been refuted by citetpollack_smerdon2004 on statistical grounds citetgonzalezrouco_etal2003 using climate simulations and citethuang2004 using an expanded network of 696 boreholes in the northern hemisphere subsectionmedieval warm period despite much discussion citepeghughes_diaz1994 bradley_etal2003 there is clear quantitative understanding of what is meant by the medieval warm period mwp citetcrowley_lowery2000 cl2000 discuss the evidence for global mwp which they interpret as period of unusual warmth in the 11th century all the reconstructions of the 11th century temperature shown in fig1 estimate that century to have been warmer than most of the past millennium however the question of practical importance is not whether it was warmer than the 12th to 19th centuries which is generally accepted but whether it was period of comparable warmth to the late 20th century mbh1999 concluded with 95 confidence that this was not so cl2000 revisit the question using 15 proxy records of which 9 were not used in the studies described above several of the series used have extremely low temporal resolution cl2000 sought to select tree ring chronologies with consistent quality throughout their length as measured by the sample replication citepcook_etal2004 check usage of sample replication cook etal qsr is available from jans website they draw attention to the spatial localization of the mwp in their proxy series it is strong in north america north atlantic and western europe but not clearly present elsewhere periods of unusual warmth do occur in other regions but these are short and asynchronous their estimate of northern hemispheric temperature over the past millennium is consistent with the works discussed above they conclude that the occurrence of decades of temperatures similar to those of the late 20th century cannot be unequivocally ruled out but that there is on the other hand evidence to support the claims that such an extended period of largescale warmth occurred citetsoon_baliunas2003 carry out an analysis of local climate reconstructions they evaluate the number of such reconstructions which show sustained climate anomaly during 8001300ad b sustained climate anomaly during 13001900ad and c their most anomalous 50 year period in the 20th century their definition of sustained climate anomaly is 50 years of warmth wetness or dryness for and c and 50 years of coolness wetness or dryness in b it should be noted that they do not carry out evaluations which allow direct comparison between the 20th century and earlier times they compare the number of extremes occurring in the 20th century with the number of anomalies occurring in periods of 3 and 4 centuries in the past both the use of sampling periods of differing length and different selection criteria make interpretation of their results problematic they have also been criticised for interpreting regional extremes which occur at distinct times as being indicative of global climate extremes citepjones_mann2004 this issue is discussed further in sect29 below citetosborn_briffa2006 perform systematic analysis along the lines of citetsoon_baliunas2003 and conclude that the proxy records alone bypassing the problem of proxy calibration against instrumental temperatures show an unprecedented anomaly in the 20th century subsectionsegment length curse citetbriffa_etal2001 and citetbriffa_etal2002 discuss the impact of the segment length curse citepcook_etal1995a briffa_etal1996 briffa2000 on temperature reconstructions from tree rings tree rings have been shown to have much greater sensitivity than other proxies on short timescales jbb1998 but there is concern that this may not be true on longer timescales tree ring chronologies are often made up of composites of many trees of different ages at one site the width of the annual growth ring depends not only on environmental factors but also on the age of the tree the age dependency on growth is often removed by subtracting growth curve from the tree ring data for each tree this process done empirically will not only remove age related trends but also any environmental trends which span the entire life of the tree citetbriffa_etal2001 use more sophisticated method age band decomposition abd which forms separate chronologies from tree rings in different age bands and then averages all the ageband chronologies to construct northern hemisphere temperatures back to 1400ad and show that greater degree of long term variability is preserved the reconstruction lies between those of mbh1999 and jbb1998 showing the cold 17th century of the former but the relatively mild 19th century of the latter the potential impact of the segment length limitations is analysed further by citetesper_etal2002b esper_etal2003 using regional curve standardisation rcs citepbriffa_etal1992 in rcs composite growth curves different curves reflecting different categories of growth behaviour are obtained from all the trees in region and this rather than fitted curve is subtracted from each individual series whereas abd circumvents the need to subtract growth curve rcs seeks to evaluate growth curve which is not contaminated by climate signals the ecs2002 analysis agrees well with that of mbh1999 on short time scales but has greater centennial variability citepesper_etal2004 ecs2002 suggest that this may be partly due to the lack of tropical proxies in their work which they suggest should be regarded as an extratropical northern hemisphere estimate the extratropics are known to have greater variability than the tropics checkfrom eduardo table 1 in mbh grl 99 add ref however it has to be also noted that among the proxies used by mbh1999 12 in total just 2 of them are located in the tropics both at one location see table 1 below citetcook_etal2004 study the data used by ecs2002 and pay particular attention to potential loss of quality in the earlier parts of treering chronologies when relatively small number of tree samples are available their analysis suggests that tree ring chronologies prior to 1200ad should be treated with caution subsectionseparating timescales citetmoberg_etal2005 follow bos2001 and ecs2002 in trying to address the segment length curse but rather than trying to improve the treering chronologies by improving the standardizations they discard low frequency component of the treering data and replace this with lowfrequency information from proxies with lower temporal resolution wavelet analysis is used to filter different temporal scales each individual proxy series is first scaled to unit variance and then wavelet transformed averaging of the wavelet transforms is made separately for tree ring data and the lowresolution data the average wavelet transform of treering data for timescales less than 80 years is combined with the averaged wavelet transform of the lowresolution data for timescales longer than 80 years to form one single wavelet transform covering all timescales this composite wavelet transform is inverted to create dimensionless temperature reconstruction which is calibrated against the instrumental record of northern hemisphere mean temperatures ad 18561979 using variance matching method unfortunately the calibration period is too short to independently calibrate the low frequency component the variance matching represents form of crosscalibration in all calibrations against instrumental data the long period multicentennial response is determined by calibration which is dominated by subcentennial variance the msh2005 approach makes this explicit and shows level of centennial variability which is much larger than in mbh1999 reconstruction and similar to that in simulations of the past millennium with two different climate models echog citepstorch_etal2004 and ncar csm climate system model citepmann_etal2005 subsectionglacial advance and retreat citetoerlemans2005 provides another independent estimate of the global mean temperature over the last 460 years from an analysis of glacial advance and retreat as with the bore hole based estimate of hps2000 this work uses physically based model rather than an empirical calibration the resulting curve lies within the range spanned by the highresolution proxies roughly midway between the mbh1999 climate field reconstruction and the hps2000 bore hole estimate unlike the borehole estimate but consistent with most other works presented here this analysis shows cooling trend prior to 1850 related to glacial advances over that period it should be noted that the technique used to generate the bore hole estimate citeppollack_etal1998 assumes constant temperature prior to 1500ad the absence of cooling trend after this date may be influenced by this boundary condition subsectionregression techniques many of the reconstructions listed above depend on empirical relationships between proxy records and temperature citetstorch_etal2004 suggest that the regression technique used by mbh1999 underrepresentsfootnotethis is sometimes referred to as underestimating which will mean the same thing to many people but something slightly different to statisticians any statistical model that is set of assumptions about the noise characteristics of the data being examined will deliver estimates of an expected value and variability the variability of the expected value is not generally the same as the expected value of the variability the variability of past climate this conclusion is drawn after applying method similar to that of mbh1999 to output from climate model using set of pseudoproxies time series generated from the model output and degraded with noise which is intended to match the noise characteristics of actual proxies citetmann_etal2005 use the same approach and arrive at different conclusion namely that their regression technique is sound citetmann_etal2005 show several implementations of their climate field reconstruction method in the csm simulation using different levels of white noise in their synthetic pseudo proxies for case of pseudoproxies with realistic signaltonoise ratio of 05 they use calibration period 18561980 which is longer than that used in mbh1998 and mbh1999 19011980 it turns out that the difference in the length of the calibration period is critical for the skill of the method zorita personal communication et submitted i think you can refer to buerger et 2006 here check with eduardo if this is ok by the way update the reference list tellus 58a 227235 am there is some uncertainty about the true nature of noise on the proxies and on the instrumental record as will be discussed further below the optimal least squares estimation technique of mbh1998 effectively neglects the uncertainties in the proxy data relative to uncertainties in the temperature instead citethegerl_etal2006 use total least squares regression citepallen_stott2003 adcock1878 this approach allows the partitioning of noise between instrumental temperatures and proxy records to be estimated on the assumption that the instrumental noise is known citethegerl_etal2006 show that this approach leads to greater variability in the reconstruction citetrutherford_etal2005 take different view they compare reconstructions from 1400ad to present using regularised expectation maximisation technique citepschneider2001 and the mbh1998 climate field reconstruction method and find only minor differences standard regression techniques assume that we have calibration period in which both sets of variables are measured and reconstruction or prediction period in which one variable is estimated by regression from the other the climate reconstruction problem is more complex there are hundreds of instrumental records which are all of different lengths and similar numbers of proxy records also of varying length the expectation maximisation technique citeplittle_rubin1987 is well suited to deal with this instead of imposing an artificial separation between calibration period and reconstruction period it fills in the gaps in way which exploits all data present regularised expectation maximisation is generalisation developed by citetschneider2001 to deal with ill posed problems nevertheless there is still simple regression equation at the heart of the technique that used by citetrutherford_etal2005 is similar to that used by new corrected mbh1998 so the issue raised by citethegerl_etal2006 is unanswered subsectionnatural variability and forcings global temperature can fluctuate through internally generated variability of the climate system as in the nino phenomenon through variability in natural forcings solar insolation volcanic aerosols natural changes to greenhouse gas concentrations and human changes reconstructions of variations in the external forcings for the last millenium have been put forward citepcrowley2000 although recent studies have suggested lower amplitude of lowfrequency solar forcing citeplean_etal2002 foukal_etal2004 analysis of reconstructed temperatures of mbh1999 and cl2000 and simulated temperatures using reconstructed solar and volcanic forcings shows that changes in the forcings can explain the reconstructed long term cooling through most of the millenium and the warming in the late 19th century citepcrowley2000 the relatively cool climate in the second half of the 19th century may be attributable to cooling from deforestation citepbauer_etal2003 citethegerl_etal2003 analyse the correlations between four reconstructions mbh1999 bos2001 ecs2002 and modified version of cl2000 and estimated forcings citepcrowley2000 they find that that natural forcing particularly by volcanism explains substantial fraction of decadal variance greenhouse gas forcing is detectable with high significance levels in all analyzed reconstructions except msh2005 which ends in 1925 citetweber2005b carries out similar analysis with wider range of reconstructions it is shown that the regression of reconstructed global temperatures on the forcings has similar dependence on timescale as regressions derived from the climate model the role of solar forcing is found to be larger for longer timescales whereas volcanic forcing dominates for decadal timescales the trend component over the period 1000 to 1850 is however in all reconstructions larger than the trend implied by the forcings the methods employed by citethegerl_etal2006 attribute about third of the early 20th century warming sometimes more in highvariance reconstructions to greenhouse gas forcing these results indicate that enhanced variability in the past does not make it more difficult to detect greenhouse warming since large fraction of the variability can be attributed to external forcing quantifying the influence of external forcing on the proxy records is therefore more relevant to understanding climate variability and its causes than determining if past periods were possibly as warm as the 20th century citetgoosse_etal2005 investigate the role of internal variability using an ensemble of 25 climate model simulations of the last millennium and forcing estimates from citetcrowley2000 they conclude that internal variability dominates local and regional scale temperature anomalies implying that most of the variations experienced by region such as europe over the last millennium could be caused by internal variability on the hemispheric and global scale however the forcing dominates this agrees with results from long solarforced model simulation by citetweber_etal2004 similar this reinforces similar statements made by jos1998 where does this come from citetgoosse_etal2005 make the new point that noise can lead to regional temperature anomalies peaking at different times to the forcing so that disagreements in timing between proxy series should not necessarily be interpreted as meaning there is common forcing subsectionthe long view the past sections have drawn attention to the problems of calibrating temperature reconstructions using relatively short period over which instrumental records are available for longer reconstructions with lower temporal resolution other methods are available pollen reconstructions of climate match the ecosystem types with those currently occurring at different latitudes the changes in ecosystem can then be mapped to the temperatures at which they now occur citepegbernabo1981 gajewski1988 these reconstructions cannot resolve decadal variability but they provide an independent estimate of local lowfrequency temperature variations the results of citetweber_etal2004 and citetgoosse_etal2005 suggest that such estimates centennial mean temperatures can provide some information about global mean anomalies as they strongly reflect the external forcings on centennial and longer timescales however there has as yet been detailed intercomparison between the pollen based reconstructions and the higher resolution reconstructions sectioncritics of the ipcc consensus on millennial temperatures the temperature reconstructions described in the previous section represent including their respective differences and similarities the scientific consensus based on objective analysis of proxy data sources which are sensitive to temperature nevertheless there are many who are strongly attached to the view that past temperature variations were significantly larger and that consequently the warming trend seen in recent decades should not be considered as unusual the criticism has been directed mainly at the citetmann_etal1998a mann_etal1999 work therefore this section focuses mainly on this criticism new though some of the critics identify the consensus with the mbh1998 work this is not the case the consensus rests on broader body of work and as formulated by ipcc2001 is less strong than the conclusions of mbh1998 sect32 citetmcintyre_mckitrick2003 mm2003 criticize mbh1998 on many counts some related to deficiencies in the description of the data used and possible irregularities in the data themselves these issues have been largely resolved in citetmann_etal2004 footnoteftpholoceneevscvirginiaedupubmannetal1998 as noted above the mbh1998 analysis is considerably more complex than others and uses greater volume of data there are 3 main stages of the algorithm 1 subsampling of regions with disproportionate numbers of proxies 2 regression 3 validation and uncertainty estimates stage 1 is necessary because some parts of the globe particularly north america and northern europe have disproportionate number of proxy records other authors have dealt with this by using only small selection of the available data or using regional averages citepbos2001hegerl_etal2006 mbh1998 use principal component analysis to extract the common signal from the records in densely sampled regions the failure of mm2003 to replicate the mbh1998 results is partly due to misunderstanding of the stepwise reconstruction method mbh1998 use different subsets of their proxy database for different time periods this allows more data to be used for more recent periods for example fig2 illustrates how the stepwise approach applies to the north american tree ring network of the total of 212 chronologies only 66 extend back beyond 1400ad mm2003 only calculate principal components for the period when all chronologies are present similarly mbh1998 use one principal component calculated from 6 drought sensitive treerings chronologies from south west mexico and this data is omitted in mm2003 is this clear now am new table 7 of mm2003 indicates only 20 series for the region as the supplementary information provided with mbh2003 omitted 2 citepmann_etal2004 endnew citetmcintyre_mckitrick2005a mm2005 continue the criticism of the techniques used by mbh1998 and introduce hockey stick index defined in terms of the ratio of the variance at the end of time series to the variance over the remainder of the series mm2005 argue that the way in which principal component analysis is carried out in mbh generates an artificial bias towards high hockeystick index and that the statistical significance of the mbh results may be lower that originally estimated the issue arises because the tree ring chronologies are standardized this involves subtracting mean and dividing by variance mbh1998 use the mean and variance of the detrended series evaluated over the calibration period mm2005 are of the view that this is incorrect they suggest that each series should be standardised with respect to the mean and variance its full length the code used by mm2005 is not at the time of writing available but the code fragments included in the text imply that their calculation used data which had been centred mean removed but had not been normalized to unit variance standardised figure 3 shows the effect of the changes applied to the north american tree ring subnetwork of the data used by mbh1998 using those chronologies which extend back to 1400ad the calculation used here does not precisely reproduce the archived mbh1998 result but the differences may be due to small differences in mathematical library routines used to do the decomposition the effect of replacing the mbh1998 approach with centering and standardising on the whole time series is small the effect of omitting the standardisation as in mm2005 is much larger this omission causes the 20th century trend to be removed from the first principal component citetstorch_zorita2005 look at some of the claims made in mm2005 and analyses them in the context of climate simulation they find the impact of the modifications suggested by mcintyre and mckitrick to be minor citetmcintyre_mckitrick2005b clarify their original claim stating that the standardisation technique used by mbh98 does not create the hockeystick structure but does steer the selection of this structure in principal component analysis citetmcintyre_mckitrick2005c mm2005c revisit the mm2003 work and correct their earlier error by taking the stepwise reconstruction technique into account they assert that the results of mm2003 which show 15th century reconstruction 05k warmer than found by mbh1998 are reproduced with only minor changes to the mbh1998 proxy data base examination of the relevant figures however shows that this is not entirely true the mm2005c predictions for the 15th century are 03k warmer than the mbh1998 result this is still significant but unlike the discredited mm2003 result it would not make the 15th century the warmest on record mm20005c and citetwahl_ammann2005 both find that excluding the north american bristlecone pine data from the proxy data base removes the skill from the 15th century reconstructions mm2005c justify this removal on the grounds that the first principal component of the north american proxies which is dominated by the bristlecone pines is statistical outlier with respect to the joint distribution of r2 and the difference in mean between 1400 to 1450 and 1902 to 1980 first ref to table 1 table 1 which lists range of proxies extending back to 1000 shows that the north american first principal component itrdb pc01 in that table is not an outlier in terms of its coherence with northern hemispheric mean temperature from 1856 to 1980 begintablet small output from mitriepylibmulti_r2py editted begintabularp70cmrrlrl hline name lat lon id r2 type cr hline grip borehole temperature degc greenland1 73 38 mo 067 ic cr china composite degc2 30 105 mo 063 mc cr taymir russia 72 102 he 060 tr c cr eastern asia 35 110 he 058 tr c cr polar urals3 65 67 ma 051 tr cr tornetraesk sweden4 58 21 mo 050 tr cr itrdb pc01 40 110 ma 049 tr pc cr mongolia 50 100 he 046 tr c cr arabian sea globigerina bull5 18 58 mo 045 cl cr western siberia 60 60 he 044 tr c cr northern norway 65 15 he 044 tr c cr upper wright usa6 38 119 043 tr cr shihua cave layer thickness degc china7 40 116 mo 042 sp cr western greenland 75 45 he 040 cr quelcaya 2 do18 peru8 14 71 ma 037 ic cr boreal usa6 35 118 032 tr cr tornetraesk sweden9 58 21 031 tr cr taymir russia10 72 102 mo 030 tr cr fennoscandia11 68 23 joma 028 tr cr yamal russia12 70 70 mo 028 tr cr northern urals russia13 66 65 jo 027 tr cr hline endtabular captioncontinued overleaf endtable renewcommandthetablearabictable addtocountertable1 begintablet small begintabularp70cmrrlrl hline name lat lon id r2 type cr hline itrdb pc02 42 108 ma 021 tr pc cr lenca chile14 41 72 jo 018 tr cr crete greenland15 71 36 jo 016 ic cr methuselah walk usa 37 118 mo 014 tr cr greenland stack15 77 60 ma 013 ic cr morocco 33 5 ma 013 tr cr north patagonia16 38 68 ma 008 tr cr indian garden usa 39 115 mo 004 tr cr tasmania17 43 148 ma 004 tr cr itrdb pc03 44 105 ma 003 tr pc cr chesapeake bay mgca degc usa18 38 76 mo 007 cr quelcaya 2 accum peru8 14 71 ma 014 ic cr france 44 7 ma 017 tr cr hline endtabular captioncontinued the primary reference for each data set is indicated by the superscript in the first column as follows 1 citepdahljensen_etal1998 2 citetyang_etal2002 3 citetshiyatov1993 4 citetgrudd_etal2002 5 citetgupta_etal2003 6 citetlloyd_graumlich1997 7 citettan_etal2003 8 citetthompson1992 9 citetbartholin_karlen1983 10 citetnaurzbaev_vaganov1999 11 citetbriffa_etal1992 12 citethantemirov_shiyatov2002 13 citetbriffa_etal1995 14 citetlara_villalba1993 15 citetfisher_etal1996 16 citetboninsegna1992 17 citetcook_etal1991 18 citetcronin_etal2003 the id in column 4 refers to the reconstructions in which the data were used the type of proxy is indicated in column 6 treering tr treering composite tr c treering principle component tr pc coral cl sediment ice core ic multiproxy composite mc the 19 proxy series marked with in column 4 are used in the union reconstruction endtable citep mm2005cbriffa_osborn1999 suggest that rising co_2 levels may have contributed significantly to the 19th and 20th century increase in growth rate in some trees particularly the bristlecone pines but such an effect has not been reproduced in controlled experiments with mature trees citepkorner_etal2005 once time series purporting to represent past temperature has been obtained the final and perhaps most important step is to verify its and estimate uncertainty limits this is discussed further in the next section sectionvarying methods vs varying data one factor which complicates the evaluation of the various reconstructions is that different authors have varied both method and data collections here we will run representative set of proxy data collections through two algorithms inverse regression and scaled composites these two methods and the different statistical models from which they may be derived are explained in the appendix esper et 2005 investigated the differing calibration approaches used in the recent literature including regression and scaling techniques and concluded that the methodological differences in calibration result in differences in the reconstructed temperature amplitudevariance of about 05k this magnitude is equivalent to the mean annual temperature change for the northern hemisphere reported in the last ipcc report for the 10001998 period citetburger_etal2006 take another approach and investigate family of 32 different regression algorithms derived by adjusting 5 binary switches using pseudoproxy data they show that these choices which have all been defended in the literature can lead to wide variety of different reconstructions given the same data they also point out that the uncertainty is greater when we attempt to estimate the climate of periods which lie outside the range experienced during the calibration period the relevance of this point to the last millennium is under debate the glacier based temperature estimates of oer2005 suggest that the coldest northern hemisphere mean temperatures occurred close to the start of the instrumental record in the 19th century the borehole reconstructions however imply that there were colder temperatures experienced in the 16th to 18th centuries for the question as to whether the warmth of the latter part of the calibration period has been experienced in the past however this particular issue is not directly relevant as noted above much of the mbh1999 algorithm is irrelevant to reconstructions prior to ad 1450 because before that date the data only suffice according to estimates in that paper to determine one degree of freedom hence we will only look at direct evaluation of the hemispheric mean temperature several authors have evaluated composites and calibrated those composites against instrumental temperature many of the composites contain more samples in later periods so that the calibration may be dominated by samples which do not extend into the distant past here we will restrict attention to records which span the entire reconstruction period the data series used are listed in table 1 subsectionproxy data quality issues as noted previously their has been especially strong criticism of mbh1998 1999 partly concerning some aspects of their data collection figures 4 and 5 show reconstructions made using the mbh1999 and mbh1998 data respectively regression against northern hemispheric mean temperature from 1856 to 1980 is used instead of regression against principal components of temperature from 1902 to 1980 there are differences but key features remain mm2003 draw attention to the fact that one time series cana036 in the itrdb classification contributed by gaspe appears twice in the mbh1998 database this error is corrected in the red dashed curve of fig5 which is almost identical to the green curve which retains the duplication subsectionreconstruction using union of proxy collections the following subsection will discuss range of reconstructions using different data collections the first 5 of these collections are defined as those proxies used by jbb1998 mbh1999 ecs2002 msh2005 and hca2006 respectively which extend back to 1000ad these will be referred to below as the jbb mbh ecs msh hca composites below to distinguish them from the composites used in the published articles which include additional shorter proxy data series finally there is union composite made using 19 independent northern hemisphere proxy series marked with in table 1 apart from the china composite record all the data used are individual series the pcs used by mbh1999 have been omitted in favour of individual series used in other studies two southern hemisphere tropical series both from the quelcaya glacier peru are included ensure adequate representation of tropical temperatures this union collection contains 11 treering series 4 icecores and one each of coral speleothem lake sediment and composite record including historical data subsectionintercomparison of proxy collections figure 6 shows reconstructions back to 1000ad using composites of proxies and variance matching cvm for the proxy principal components in the mbh1998 mbh1999 data collections the sign is arbitrary these series have where necessary had the sign reversed so that they have positive correlation with the northern hemisphere temperature record surprisingly the union does not lie in the range spanned by the other reconstructions and reaches colder temperatures than any of them it does however fit the calibration period data better than any of the subcollections the reconstructions shown in fig7 use the same data is used this time using inverse regression invr appendix as used by mbh1998 the method used here differs from that of mbh1998 in using northern hemisphere temperature to calibrate against having longer calibration period and reconstructing only single variable instead of multiple eofs the spread of values is substantially increased relative to the cvm reconstruction with invr only one reconstruction that using the ecs2001 data shows temperatures warmer than the mid 20th century the inverse regression technique applies weights to the individual proxies which are proportional to the correlation between the proxies and the calibration temperature signature for this time series the 5 proxies are weighted as 17 boreal 29 polar urals 17 taymir 18 tornetraesk and 23 upper wright firstly it should be noted that this collection samples north america and the eurasian arctic only the bias towards the arctic is strengthened by the weights generated by the inverse regression algorithm such that the reconstruction has poor geographical coverage the mbh1999 and hps2000 published reconstructions are shown in fig6 for comparison the mbh1999 reconstruction lies near the centre of the spread of estimates while the hps2000 reconstruction is generally at the lower bound much of the current debate revolves around the level of centennial scale variability in the past the cvm results generally suggest low variance scenario comparable to mbh1999 the inverse regression results however suggest greater variability it should be noted that the mbh1999 inverse regression result use greater volumes of data for recent centuries so that the difference in fig7 between the dashed red curve and the full green curve in the 17th century is mainly due to reduced proxy data input in the latter there is also difference because mbh1999 used inverse regression against temperature principle components rather than northern hemisphere mean temperature as here table 2 shows the cross correlations of the reconstructions in fig6 for high pass upper right and low pass lower left components of the series with low pass being defined by 40 year running mean the low pass components are highly correlated begintablet output from mitriepylibpppy begintabularlcccccc hline ma mo jo he unioncr hline ma 14 25 60 20 61 cr mo 69 37 11 13 60 cr 64 77 14 36 57 cr jo 62 51 46 11 35 cr he 72 75 85 53 26 cr union 67 71 62 45 84 cr hline endtabular captioncross correlations between reconstructions from different proxy data bases mann et ma moberg et mo esper et jones et jo hegerl et he lower left block correspond to low pass filtered series upper right to high pass filtered endtable the significance of the correlations between these five proxy data samples and the instrumental temperature data during the calibration period 18561980 has been evaluated using montecarlo simulation with 1 first order markov model and 2 random time series which reproduces the lag correlation structure of the data samples see appendix figure 8 shows the lag correlations the instrumental record had pronounced anticorrelation on the 40 year timescale this may be an artifact of the short data record but it is retained in the significance calculation as the best available estimate which is independent of the proxies the union composite shows multicentennial correlations which are not present in the other data the mbh and jbb composites clearly underestimate the decadal scale correlations while the hca and union composites overestimate it first ref to table 3 results are shown in table 3 if the full lag correlation structure of the data were known it would be true as argued by mm2005 that the first order approach generally leads to an overestimate of significance here however we only have estimated correlation structure based on small sample using this finite sample correlation is likely to overestimate longterm correlations and hence lead to an underestimate of significance nevertheless results are presented here to provide cautious estimate of significance for the mbh and jbb composites which have short lagcorrelations the difference between the two methods is minimal for other composites there is substantial difference in all cases the r2 values exceed the 99 significance level when detrended data are used the r2 values are lower but still above the 95 level with the exception of the hegerl et data this data has only decadal resolution so the lower significance in high frequency variability is to be expected begintablet output from mitriepylibsum_acpy begintabularlccccccp11cm hline source r2_95h r2_95ar r2 r2_detr sigma signif signif detrended cr hline mann et 0205 0170 0463 0286 0186 9999 9875cr hline moberg et hilo2 0225 0183 0418 0338 0153 9987 9925cr hline esper et 0335 0220 0613 0412 0158 9996 9811cr hline jones et 0187 0180 0371 0274 0203 9993 9917cr hline hegerl et 0440 0266 0618 0357 0133 9956 9013cr hline union 0337 0236 0655 0414 0149 9998 9791cr hline endtabular caption r2 values evaluated using the northern hemisphere mean temperature 1856 to 1980 and various proxy records columns 2 and 3 show r2 values for the 95 significance levels evaluated using monte carlo simulation with 10000 realisations in columns 2 7 and 8 the full lagcorrelation structure of the data is used in column 3 first order autoregressive model is used based on the lag one autocorrelation column 4 shows the r2 value obtained from the data and column 5 shows the same using detrended data column 6 shows the standard error rootmeansquare residual from the calibration period columns 7 and 8 show significance levels estimated using monte carlo simulations as in column 2 for the full and detrended r2 values endtable figure 9 plots this reconstruction with the instrumental data in the calibration period the composite tracks the changes in northern hemisphere temperature well capturing the steep rise between 1910 and 1950 and much of the decadal scale variability this is reflected in the significance scores tab3 which are high both for the full series and for the detrended series the highest temperature in the reconstructed data relative to the 18661970 mean is 0227k in 1091ad this temperature was first exceeded in the instrumental record in 1878 again in 1937 and frequently thereafter the instrumental record has not gone below this level since 1986 taking sigma0149 as the rootmeansquare residual in the calibration period 1990 is the first year when the 1091 maximum was exceed by 2sigma this happened again in 1995 and every year since 1997 1998 and every year since 2001 have exceeded the preindustrial maximum by 3sigma conclusionslabelsecend there is general agreement that global temperatures cooled over the majority of the last millennium and have risen sharply since 1850 in this respect the recent literature has not produced any change to the conclusions of jbb1998 though there remains substantial uncertainty about the magnitude of centennial scale variability superimposed over longer term trends the ipcc 2001 conclusion that temperatures of the past millennium are unlikely to have been as warm at any time prior to the 20th century as the last decades of the 20th century is supported by subsequent research and by the results obtained here the greatest range of disagreement among independent assessments occurs during the coolest centuries from 1500 to 1900 when the departure from recent climate conditions was strongest and may have been outside the range of temperatures experienced during the later instrumental period there are many areas of uncertainty and disagreement within the broad consensus outlined above and also some who dissent from that consensus papers which claim to refute the ipcc2001 conclusion on the climate of the past millennium have been reviewed and found to contain serious flaws major area of uncertainty concerns the accuracy of the long timescale variability in the reconstructions this is particularly so for timescale of century and longer there does not appear to be any doubt that the proxy records would capture rapid change on 10 to 50 year time scale such as we have experienced in recent decades using two different reconstruction methods on range of proxy data collections we have found that inverse regression tends to give large weighting to small number of proxies and that the relatively simple approach of compositing all the series and using variance matching to calibrate the result gives more robust estimates new reconstruction made with composite of 19 proxies extending back to 1000ad fits the instrumental record to within standard error of 0149k this reconstruction gives maximum preindustrial temperature of 0227k relative to the 1866 to 1970ad mean the maximum temperature from the instrumental record is 0841k over 4 standard errors larger the reconstructions evaluated in this study show considerable disagreement during the 16th century the new 19 proxy reconstruction implies 21year mean temperatures close to 06k below the 1866 to 1970ad mean as this reconstruction only used data extending back to 1000ad there is considerable volume of 16th century data which has not been used this will be focus if future research bf acknowledgments this work was funded by the netherlands environment assessment agency rivm as part of the dutch scientific assessment and policy analysis wab programme additional funding was provided as follows from the uk natural environment research council for mn juckes from the swedish research council for moberg vfilleject defthesectiona bf appendix regression methods ideally the statistical analysis method would be determined by the known characteristics of the problem unfortunately the error characteristics of the proxy data are not sufficiently well quantified to make the choice clear this appendix describes two methods and the statistical models which can be used to motivate them subsectioninverse regression invr suppose x_ik i1n_pr k1l is set of n_pr standardised proxy records of length l and that we are trying to obtain an estimate haty_i of quantity y_i which is known only in calibration period iin c several optimal estimates of y_i can be obtained depending on the hypothesised relation between the proxies and inverse regression follows from the model beta_i y_k cal n x_ik where cal n is noise process independent between proxies it follows that optimal estimate for the coefficients beta_i are hatbeta_i sum_kin c x_ik y_k over sumkin c y_k2 given these coefficients the optimal estimate of the y_k outside the calibration period is haty_k sum_i hatbeta_i x_ik over sum_i hatbeta_i2 subsectioncomposite plus variance matching cvm this method is rather easier it starts out from the hypothesis that different proxies represent different parts of the globe proxy for the global mean is then obtained as simple average of the proxies overlinex_k n_pr1 sum_i x_ik suppose overlinex_k beta y_k cal n then an optimal estimate of beta is easily derived as hatbeta sum_kin c x_k y_ksum_kin c y_k2 however y_k hatbeta1 x_k is not an optimal estimate of y_k because of the added noise overlinex_k is generally an overestimate of beta y_k to correct for this we should use beta y_k overlinex_k sqrt left beta2 sigma2_y over beta2 sigma2_y sigma_cal n2 right where sigma2_y and sigma_cal n2 are the expected variance of and the respectively this leads to an estimate y_k overlinex_k left sigma_y over sigma_x right this is known as the variance matching method because it matches the variance of the reconstruction with that of observations over the calibration period defthesectionb setcountersubsection0 bf appendix b statistical tests subsectiontests for linear relationships the simplest test for linear relationship is the anomaly correlation also known as pearson correlation pearsons product moment correlation r2 product mean test be r overline yprime xprime over sqrt overline yprime2 overline xprime2 ee where the overbar represents mean over the data the test is being applied to and prime departure from the mean citeppearson1896 the significance of an anomaly correlation can be estimated using the t statistic be t r sqrtn2 over sqrt1r2 ee where n is the sample size for independent variables two gaussian variables will produce t statistics which obeys the students tdistribution of n2 degrees of freedom ideally if the noise affecting all the x and values is independent n is simply the number of measurements this is unlikely to be the case so an estimate of n is needed the montecarlo approach is more flexible large sample of random sequences with specified correlation structures is created and the frequency with which the specified r coefficient is exceeded can then be used to estimate its significance subsectionlag correlations following citethosking1984 random time series with specified lag correlation structure is obtained from the partial correlation coefficients which are generated using levinsondurbin regression it is however not possible to generate sequence matching an arbitrarily specified correlation structure and there is guarantee that an estimate of the correlation structure obtained from small sample will be realizable it is found that the levinsondurbin regression diverges when run with the lag correlation functions generated from the citetjones_etal1986 northern hemisphere temperature record and also that from the hca composite for the northern hemisphere temperature record this is resolved by truncating the regression after n50 the sample lagcorrelation coefficients are in any case unreliable beyind this point truncating the regression results in random sequence with lag correlation fitting that specified up to lag 50 and then decaying for the hca composite the sample lagcorrelation cn is scaled by exp 00001 n where n is the lag in years bf appendix c acronyms table 4 shows list of acronyms used in this paper begintable begintabularlp12cm hline abd age band decomposition tree ring standardisation method cr hline csm climate system model coupled oceanatmosphere climate model produced by ncar httpwwwcgducareducsm cr hline cfm climate field reconstruction method for reconstructing spatial structures of past climate variables using proxy data cr hline cvm composite plus variance matching reconstruction method cr hline echog hamburg coupled oceanatmosphere climate model cr hline eof empirical orthogonal component cr hline invr inverse regression reconstruction method cr hline ipcc the intergovernmental panel on climate change established by the world meteorological organization wmo and the united nations environment programme unep to assess scientific technical and socioeconomic information relevant for the understanding of climate change its potential impacts and options for adaptation and mitigation it is open to all members of the and of wmo cr hline itrdb international treering data bank maintained by the noaa paleoclimatology program and world data center for paleoclimatology wwwncdcnoaagovpaleo cr hline mwp medieval warm period cr hline pc principal component cr hline rcs regional curve standardisation tree ring standardisation method cr hline endtabular captionacronyms used in the text endtable bibliographystyleegu bibliographycitationsextras vfilleject beginfigureh produced by idlmitrieplot_reconpro centeringincludegraphicswidth12cmcpd2006xxxxf01 captionlabelfig1 various reconstructions with mean of 1900 to 1960 removed endfigure vfilleject beginfigureh produced by idlpaleombh_70pro centeringincludegraphicswidth12cmcpd2006xxxxf02 captionlabelfig2 data blocks for pc calculation by mbh1998 each of the 212 data series is shown as horizontal line over the time period covered the dashed blue rectangles indicate some of the blocks of data used by mbh1998 for their proxy principal component calculation using fewer series for longer time periods the red rectangle indicates the single block used by mm2003 neglecting all data prior to 1619 endfigure vfilleject beginfigureh produced by pylibdo_eofpy centeringincludegraphicswidth12cmcpd2006xxxxf03 captionlabelfig3 first principal component of the north american proxy record collection following mbh1998 the black line is the mbh1998 archived version the other lines differ only in the method of standardisation of series prior to calculation of the principal components red calculated following the mbh1998 method the individual series have the mean of the calibration period removed and are normalised by the variance of the detrended series over that period blue with the mean of the whole series removed and normalised with the variance of the whole series green mean removed but normalisation endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmcpd2006xxxxf13 captionlabelfig4 reconstruction back to 1000 calibrated on 1856 to 1980 northern hemisphere temperature using the mbh1999 proxy data collection the mbh1999 nh reconstruction and the jones et 1986 instrumental data are shown for comparison all data have been smoothed with 21year running mean endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmcpd2006xxxxf12 captionlabelfig5 as fig4 but using the mbh1998 data collection back to 1400ad endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmcpd2006xxxxf10 captionlabelfig6 reconstruction back to 1000ad calibrated on 1856 to 1980 northern hemisphere temperature using composite and variance matching for variety of different data collections the mbh1999 and hps2000 nh reconstructions and the jones et 1998 instrumental data are shown for comparison graphs have been smoothed with 21year running mean and centered on 1866 to 1970 the maximum of the union reconstruction in the preindustrial period 0227k 1091ad is shown by short cyan bar the maximum of the instrumental record 0841k 1998ad is shown as short purple bar endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmcpd2006xxxxf11 captionlabelfig7 as fig6 except using inverse regression endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmcpd2006xxxxf14 captionlabelfig8 lag correlations for proxy composites and instrumental record gray endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmcpd2006xxxxf09 captionlabelfig9 the union reconstruction using composite plus variance scaling for the calibration period also shown is the level of the maximum plus two standard errors the jones and mann instrumental data is plotted as dashed line endfigure enddocument diliberate bad speling vfilleject itsmall both these questions could be answered by detailed knowledge of the climate and its forcings over the past 1000 years but the detailed instrumental record only extends back to 1856 hence the motivation for the study of past climate variability is twofold current projections of future climate change are still burdened with some level of uncertainty even within particular scenario of future greenhouse concentrations although all climate models simulate an increase of global temperatures in this century the range of warming simulated by different models still covers wide range citepipcc2001 much pursued goal is to reduce this uncertainty range question is whether warming of magnitude similar to that observed in the 19th and 20th centuries very likely caused at least to large part by anthropogenic greenhouse gas has also occurred in the preindustrial recent past when to large extent only natural forcings of the climate system were active smallit reconstructions of the climate of the past millennium can help us to answer the second point by describing the magnitude of global temperature fluctuations in the past and can address the first point by helping to quantify the climate sensitivity the ratio of the response to the forcing progress in both questions can be achieved through the analysis of reconstructions and simulations of the climate of the past millennium firstly we wish to know whether current high global temperatures are within the range of natural variability secondly we wish to evaluate the skill and reliability of climate models the rise in global mean temperatures since then is therefore some form of empirical reconstruction based on earlyinstrumental records documentary evidence and proxy data is needed on the other hand the global warming observed in the past 2 centuries may be partly due to the recovery from an extended period of anomalously low temperatures which was reflected in large number of indirect european records omit above sentence am justify recovery je was it really gradual je gradual deleted jones and mann suggest that hemispheric mean cooling trend is relatively steady in contrast to more episodic cooling in europe but esper etal 2002 suggests that attributing this difference to hemisphere vs europe is wrong it might be whole hemisphere vs extratropical or it might be failure to resolve variability check copied from gabis email needs clearing up however some unsolved questions will remain for instance the climate sensitivity may depend on the nature of the external forcing greenhouse gas solar irradiance etc so that an estimation of past climate sensitivity has still to be considered with some care there are indeed indications that climate sensitivity to changes in solar forcing is lower than to changes to greenhouse gas forcing citeptett_etal2005 joshi_etal2003 be more precise ie in terms of k w1 m2 joshi etal show 020 difference between sensitivity to solar forcing compared to co2 forcing this is much less than variability in sensitivity among models this is not really relevant if the difference in climate sensitivity between forcings is much less than that between say models wide range of proxy data sources which have been exploited for this problem citepreviewed injones_mann2004 tree rings are particularly important source of information within the time frame of the last millennium the precise dating which is provided by the annual growth rings allows anomalous growth rates to be compared reliably with historical events however its not straightforward to retrieve the climate variability at timescales that exceed the typical life span of tree see sect25 below statistical regression against instrumental temperature data is often used because the majority of proxy records cannot be directly related to temperature by deterministic models two exceptions reconstructions obtained from borehole temperatures and those based on glacial advance and retreat are discussed below appendix gives mathematical details of some basic statistical measures the measures of skill used by mbh1998 mbh1999 are the r2 test which measures the degree of coherence between two data sets and the reduction of error re statistic which measures the effectiveness of one series typically model or prediction in explaining the total ie including the mean variance in another the verification data the statistical tests on these measures of skill are described in many text books and their application is straight forward when all sources of noise contaminating the data are well characterised the difficulty which arises in many applications including climate reconstructions is that the noise has significant but poorly characterised correlations is this true for tests of skill probably not for analytical tests of re vfilleject vfill eject the burger et analyses use collection of pseudoproxies created from pseudo observations of climate simulation with added white noise this is pragmatic approach there is little reliable information about the true nature of the noise spectrum it has been suggested that bristlecone pines in n america have an anomalous growth trend in the 20th century which is coherent among that species the inverse regression algorithm can give large weight to individual proxies and negative weight to others this may be correct in some circumstances but in others it could amplify the error the composite approach on the other hand is robust simply taking the mean of the available proxies does not rely on specific assumptions about the noise spectrum vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmfigzc_var_nh_reconc_10_1000_c centeringincludegraphicswidth12cmfigscpd2006xxxxf04 captionlabelfig1 as fig7 except using composite and variance matching endfigure vfilleject beginfigureh produced by pylibplot_regcpy centeringincludegraphicswidth12cmfigzc_var_nh_reconc_10_1000_c centeringincludegraphicswidth12cmfigscpd2006xxxxf04 captionlabelfig1 the union reconstruction using composite plus variance scaling for the calibration period also shown is the level of the maximum plus two standard errors the jones and mann instrumental data is plotted as dashed line endfigure willmott cj 1981 on the validation of models phys geog 2 184194 bf a2 principal components principal component analysis is standard technique for reducing the volume of data while attempting to retain as much of the variability of the original data as possible stage 2 establishes an empirical link between the proxy records and temperature in mbh1998 inverse least squares regression of the proxy network against the principal components of the measured temperature field over the period 1902 to 1980 is used stage 3 the verification stage determines how many if any of the reconstructed time series for the principal components can be considered to have some descriptive value this is done by evaluating the fit of the implied fields to the observations in the verification period 1856 to 1901 the northern hemisphere mean temperature is calculated from the the uncertainties are calculated from the residuals to the fit in the calibration period citetmcintyre_mckitrick2005c assert that the fact that omission of data led to different result demonstrates that the method is unreliable this would be true if the computation of time series were the end point of the analysis however the need to verify the computed series was recognised by mbh1998 this is discussed further below subsubsectionspurious metaphors the term hockeystick has become widely used particularly in the us media to refer to the temperature history implied by the mbh1999 temperature reconstruction it did not originally apply to the reconstruction itself which has relatively minor temperature increase in the early 20th century but rather to the combination of this series with the more recent observed temperature trends the combination shows dramatic increase in the 20th century substantially greater than anything that occurred in the past millennium the first attempt to attach any scientific meaning to the phrase was with the introduction of hockey stick index citetmcintyre_mckitrick2005a hereafter mm2005 this index is defined in terms of the ratio of the variance at the end of time series to the variance over the remainder of the series mm2005 argue that the way in which principal component analysis is carried out in mbh generates an artificial bias towards high hockeystick index and that the statistical significance of the mbh results may be lower that originally estimated and that this is responsible for the shape in the mbh temperature reconstruction martin i think that what mm05 indicate is that hockeystick may arise from random time series more easlily as previously thought when using the decentered pcs i am not sure if they make this decentering responsible for the final output in mbh subsectionvalidation as noted above mm2003 have shown that removing data degrades the result as might be expected among the adjustments which they characterize as corrections was the omission of the 3 principal components mentioned above in fact 70 of the 90 time series extending back to 1400 are omitted from their analysis in principle it would be possible to estimate the accuracy of reconstructions calculated by regression from the data in the calibration period however this calculation can easily be biased by unreliable assumptions about the noise covariances within the calibration period mbh1998 1999 follow more robust approach using independent data from validation period 1856 to 1901 to firstly determine whether reconstruction has any relation to temperature and secondly estimate the error variance mm2003 however omitted the validation phase citepwahl_ammann2005 have carried out detailed investigation of the robustness of the mbh1998 technique to address this and many other issues they find that the mm2003 series fails the validation tests used by mbh1998 as an illustration of the robustness of the reconstruction figures 5 and 6 shows reconstructions made using the mbh1999 and mbh1998 data respectively regression against northern hemispheric mean temperature is used instead of regression against principal components of temperature there are differences but key features remain more details in appendix andor supplementary materials mm2003 draw attention to the fact that one time series cana036 in the itrdb classification contributed by gaspe appears twice in the mbh1998 database this error is corrected in the red dashed curve of fig5 which is almost identical to the green curve which retains the duplication with our simplification of the method it is possible to use the entire instrumental record for calibration this leaves data for validation but the difference between this and reconstruction based on shorter period gives some idea of the robustness figure 4b shows the result finally mm question the calculation of uncertainty limits this depends on the number of degrees of freedom assigned to the data mm state that the standard method used by mbh is wrong and that lower number of degrees of freedom is appropriate because of long range correlations in the data mbh use the lagone autocorrelation to estimate the degrees of freedom in all such tests it is necessary to remember the distinction between the sample correlation which one is forced to deal with and the actual correlation we cannot know exactly for this reason it is generally unwise to use methods which rely on statistics which cannot be estimated robustly in small sample mm05 also confuse the autocorrelation structure of the treering data which are known to have an environmental signal with correlations on at least the decadal timescale with the autocorrelation of the residuals which should be used in estimating the noise structure vfilleject beginfigureh produced by idlpaleombh_70pro centeringincludegraphicswidth12cmcpd2006xxxxf03 captionlabelfig1 data blocks for pc calculation by mbh endfigure subsectionnatural variability and forcings global temperature can fluctuate through natural internal variability of the climate system as in the nino phenomenon through variability in natural forcings solar insolation volcanic aerosols natural changes to greenhouse gas concentrations and human changes analysis of the physical links between the estimated temperature changes of the past millennium and estimated variations in the different forcing mechanisms can give improve our understanding of those mechanisms and help to validate the estimated temperature and citetgoosse_etal2005 investigate the role of natural variability using an ensemble of 25 climate model simulations of the last millennium and forcing estimates from citetcrowley2000 they conclude that natural variability dominates local and regional scale temperature anomalies implying that most of the variations experienced by region such as europe over the last millennium could be caused by natural variability on the hemispheric and global scale however the external forcing dominates this reinforces similar statements made by jos1998 citetgoosse_etal2005 make the new point that noise can lead to regional temperature anomalies peaking at different times to the forcing so that disagreements in timing between proxy series should not necessarily be interpreted as meaning there is common forcing analysis of natural climate forcings citepcrowley2000 show that changes in atmospheric aerosol content due to changes in volcanic activity and changes in solar irradiance can explain this long term cooling through most of the millenium shown by paleoclimate reconstructions and the observed warming in the late 19th century citethegerl_etal2003 analyse the correlations between four reconstructions mbh1999 bos2001 ecs2002 and modified version of cl2000 and estimated forcings citepcrowley2000 they find that that natural forcing particularly by volcanism explains substantial fraction of decadal variance also in new highvariance reconstructions greenhouse gas forcing is detectable with high significance level in all analyzed reconstructions analyzed citetweber2005b carries out similar analysis with wider range of reconstructions it is shown that the correlation between reconstructed global temperatures and forcings are similar to those derived from the ecbilt climate model citepopsteegh_etal1998 the trend component over the period 1000 to 1850 is however larger in the reconstructions compared to the forcings the methods employed by citethegerl_etal2006 attribute about third of the early 20th century warming sometimes more in highvariance reconstructions to greenhouse gas forcing these results indicate that enhanced variability in the past does not make it more difficult to detect greenhouse warming since large fraction of the variability can be attributed to external forcing quantifying the influence of external forcing on the proxy records is therefore more relevant to understanding climate variability and its causes than determining if past periods were possibly as warm as the 20th century the dominance of volcanic forcing over solar variability found in some of the above studies is consistent with recent questioning of the magnitude of lowfrequency solar forcing citeplean_etal2002 foukal_etal2004 subsectiontests of skill in reconstructions re reduction of error be re 1 overline hat yprime2 over overline y2 ee anders moberg department of physical geography and quaternary geology stockholm university se106 91 stockholm sweden phone 46 08 6747814 fax 46 0 8 164818 wwwgeosuse andersmobergnatgeosuse xflowed attachment converted ceudoraattachmcintyre2003pdf